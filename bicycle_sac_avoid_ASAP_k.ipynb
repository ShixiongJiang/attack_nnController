{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4c660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import cos, sin\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "from typing import Optional\n",
    "from control.matlab import ss, lsim, linspace, c2d\n",
    "from functools import partial\n",
    "from state_estimation import Estimator\n",
    "import math\n",
    "import gym\n",
    "from stable_baselines3 import PPO, SAC, TD3, DDPG, DQN, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0c283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dbe14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CSTR model\n",
    "def bicycle(x,t,u, params={}):\n",
    "    lr = 1.105\n",
    "    lf = 1.738\n",
    "    psi = x[2]\n",
    "    v = x[3]\n",
    "    alpha = u[0]\n",
    "    sigma = u[1]\n",
    "    xdot =np.zeros(4)\n",
    "    beta = math.atan((lr/(lr+lf)*math.tan(sigma)))\n",
    "    xdot[0] = v*math.cos(psi+beta)\n",
    "    xdot[1] = v*math.sin(psi+beta)\n",
    "    xdot[2] = v/lr*math.sin(beta)\n",
    "    xdot[3] = alpha\n",
    "    return xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe861ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 20\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [1,1,0,math.sqrt(2)]\n",
    "        self.obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.8\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 20\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = np.linalg.norm(self.state - self.obstacle)\n",
    "        reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "        self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "        if self.steps < 10:\n",
    "            reach_reward = max(self.reward_cache)\n",
    "        else:\n",
    "            reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "        final_reward = min(reach_reward, avoid_reward)\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 10\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or max(np.absolute(self.state))>20 or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c0b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpsl/anaconda3/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "reached = []\n",
    "for k in [20]:\n",
    "    env = bicycleEnv()\n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    model.learn(total_timesteps=300000, progress_bar=False)\n",
    "    vec_env = model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    center = [1,1,0,math.sqrt(2)]\n",
    "    obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6ed894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[917]\n"
     ]
    }
   ],
   "source": [
    "print(reached)\n",
    "model.save(\"SAC_bicycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98271d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"SAC_bicycle.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87d6e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, root\n",
    "def fgsm_attack(state, model, epsilon, policy, norm, args):\n",
    "    state = torch.from_numpy(state)\n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    action = model.actor(state)\n",
    "    # target = torch.argmax(q_vals).unsqueeze(0)\n",
    "    # preds = torch.softmax(q_vals, 1)\n",
    "    # The loss is calcualted with cross entropy\n",
    "    # current_q = self.critic(state, action)\n",
    "    # cri = model.critic(state)\n",
    "    q_vals = (model.critic(state, action))\n",
    "    loss = (q_vals[0] + q_vals[1]) / 2 * (-1)\n",
    "    # print(target)\n",
    "    # loss_func = torch.nn.CrossEntropyLoss()\n",
    "    # loss = loss_func(preds, target)\n",
    "    model.actor.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "   \n",
    "    state_grad = state.grad.detach().squeeze()\n",
    "    \n",
    "    state = state.squeeze()\n",
    "    # Perturb only agent position and ball position\n",
    "    if norm == float('inf'):\n",
    "        perturbed_state = state + epsilon * state_grad.sign()\n",
    "    elif norm == 2:\n",
    "        perturbed_state = state + epsilon * state_grad / torch.norm(state_grad, norm)\n",
    "    elif norm == 1:\n",
    "        index = torch.argmax(state_grad)\n",
    "        per = torch.zeros_like(state_grad)\n",
    "        per[index] = 1\n",
    "        perturbed_state = state + epsilon * per\n",
    "    return perturbed_state.detach().cpu().numpy()\n",
    "\n",
    "def safe_attack(env, state, model, epsilon, policy, norm, args):\n",
    "    action = model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    def f(x):\n",
    "    # Objective function\n",
    "        return 1\n",
    "    def fun(x):\n",
    "        return np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) \n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "    x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    non_linear_eq= lambda x: np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) -\\\n",
    "                            np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center)\n",
    "    non_linear_constr = NonlinearConstraint(non_linear_eq, - np.inf, 0.0 )\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "    result = minimize(f, x_start, method='trust-constr', bounds=bounds)\n",
    "    # print(result.x)\n",
    "    op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = model.actor(state, deterministic=True)[0].requires_grad_(True)\n",
    "        action = action * 7\n",
    "        action = action.double()\n",
    "        mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        model.actor.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 10 * state_grad.sign()\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = model.actor(perturbed_state, deterministic=True)[0]\n",
    "        low, high = -7, 7\n",
    "        action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach(),))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist - env.safe_norm_radius and  > :\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack\n",
    "        \n",
    "    #     if np.minimum(env.target_norm_radius - pertub_dist, pertub_obs_dist - env.safe_norm_radius) >= \\\n",
    "    #         np.minimum(env.target_norm_radius - dist, obs_dist - env.safe_norm_radius):\n",
    "            \n",
    "    #         # print(_action)\n",
    "    #         # print(action.detach())\n",
    "    #         if next_obs_dist < next_origin_obs_dist:\n",
    "    #             # print('find solution')\n",
    "    #             if next_obs_dist < effect:\n",
    "    #                 effect = next_obs_dist\n",
    "    #                 # print(effect)\n",
    "    #                 attack = (state.detach().numpy() - _state)[0]\n",
    "                  \n",
    "    # # print('not find solution')\n",
    "    # if attack is None:\n",
    "    #     return np.zeros_like(_state)\n",
    "    # else:\n",
    "    #     # print('find solution')\n",
    "    #     return attack\n",
    "\n",
    "    \n",
    "# def safe_attack(env, state, model, epsilon, policy, norm, args):\n",
    "    \n",
    "#     action = model.predict(state, deterministic=True)[0]\n",
    "#     _action = action\n",
    "#     _state = state\n",
    "#     # state = np.reshape(state, (3,1))\n",
    "#     def f(x):\n",
    "#     # Objective function\n",
    "#         ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "        \n",
    "#         return np.linalg.norm(odeint(bicycle, env.state, ts, args=(x,))[-1] - env.obstacle )\n",
    "#     x_start = np.array(action)\n",
    "#     lim = [-7, 7]\n",
    "\n",
    "#     bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "#     ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "#     x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "#     non_linear_eq= lambda x: env.target_norm_radius - np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) +\\\n",
    "#     np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) - 0.3-\\\n",
    "#      (env.target_norm_radius - np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center) +\\\n",
    "#     np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.obstacle) - 0.3)\n",
    "    \n",
    "#     dist = np.linalg.norm(x_state - env.center)\n",
    "#     obs_dist = np.linalg.norm(x_state - env.obstacle)\n",
    "#     reward = env.target_norm_radius - dist + obs_dist - 0.3\n",
    "#     non_linear_constr = NonlinearConstraint(non_linear_eq, 0.0, np.inf)\n",
    "#     # result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds)\n",
    "   \n",
    "#     op_action = (result.x)\n",
    "    \n",
    "#     state = torch.from_numpy(state)\n",
    "    \n",
    "#     state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "#     # print(model.predict(state, deterministic=True)[0])\n",
    "#     for i in range(100):\n",
    "     \n",
    "#         action = model.actor(state, deterministic=True)[0].requires_grad_(True)\n",
    "#         action = action * 7\n",
    "#         action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "#         # compute the distance\n",
    "#         pdist = torch.nn.PairwiseDistance(p=2)\n",
    "#         loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "#         # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "#         model.actor.zero_grad()\n",
    "#         loss = loss.double()\n",
    "#         # print(action.dtype)\n",
    "#         loss.backward()\n",
    "       \n",
    "#         state_grad = state.grad.detach().squeeze()\n",
    "#         perturbed_state = state - epsilon / 40 * state_grad.sign()\n",
    "#         # print(state_grad)\n",
    "#         # project!\n",
    "#         # print(perturbed_state[0])\n",
    "#         torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "#         # print(perturbed_state[0])\n",
    "        \n",
    "#         scaled_action = model.actor(perturbed_state, deterministic=True)[0]\n",
    "#         low, high = -7, 7\n",
    "#         action_next = low + (0.5 * (scaled_action + 1.0) * (high - low))\n",
    "#         state = perturbed_state.detach().requires_grad_(True)\n",
    "#         # print(f'state:{perturbed_state}')\n",
    "#     # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "#     return  state.detach().numpy() - _state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdc3f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpsl/anaconda3/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/cpsl/anaconda3/lib/python3.10/site-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number reached = 41\n",
      "Total number violate = 0\n",
      "clean env for reference\n",
      "Total number reached = 91\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": [
    "# Test 50 traces for safe attack\n",
    "\n",
    "# norm = 2\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "clean_env = bicycleEnv()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "obs_dists = []\n",
    "obs_dists_list = []\n",
    "dist_list = []\n",
    "center = [1,1,0,math.sqrt(2)]\n",
    "obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "num_reached = 0\n",
    "action_list = []\n",
    "pertub_action_list = [] \n",
    "number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "for j in range(100):\n",
    "    dim0 = []\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    euclid = []\n",
    "    state = env.reset()\n",
    "    _ = clean_env.reset()\n",
    "    clean_env.state = state\n",
    "    clean_state = state\n",
    "    # print(f'state:{state}, clean_state:{clean_state}')\n",
    "    # Print initial state\n",
    "    for i in range(env.step_const):\n",
    "      \n",
    "        # action = model.predict(state, deterministic=True)\n",
    "        # pertub_action = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        attack = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        # print(attack)\n",
    "        pertub_state = state + attack\n",
    "        # print(pertub_state, state)\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        # print(pertub_action)\n",
    "        # new_state, reward, done, _ = env.step(pertub_action[0])\n",
    "        new_state, reward, done, _ = env.step(pertub_action)\n",
    "        state = new_state\n",
    "        # new_state, reward, done, _ = env.step(action[0])\n",
    "        \n",
    "        dist = np.linalg.norm(state - env.center)\n",
    "        obs_dist = np.linalg.norm(state - env.obstacle)\n",
    "        pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        obs_dists.append(obs_dist)\n",
    "        if obs_dist <= env.safe_norm_radius:\n",
    "            number_violate += 1\n",
    "            break\n",
    "        if dist <= env.target_norm_radius: # stop\n",
    "            num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    obs_dists_list.append(obs_dists)\n",
    "    obs_dists = []\n",
    "    \n",
    "    # print(env.final_reward_cache)\n",
    "    # print(\"dirty env\")\n",
    "    # print(obs_dist_list)\n",
    "    # print(dist_list)\n",
    "   \n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "    \n",
    "    # print(clean_env.final_reward_cache)\n",
    "    # print(\"clean env\")\n",
    "    # print(clean_obs_dist_list)\n",
    "    # print(clean_dist_list)\n",
    "   \n",
    "    # dims0.append(dim0)\n",
    "    # dims1.append(dim1)\n",
    "    # dims2.append(dim2)\n",
    "    euclids.append(euclid)\n",
    "ref= [math.pi/2]*30\n",
    "print(\"Total number reached = \" + str(num_reached))\n",
    "print(\"Total number violate = \" + str(number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "res_list.append(num_reached)\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(clean_obs_dist_list) / len(clean_obs_dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c7582f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print((obs_dists_list[0]))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ave_dist = []\n",
    "for i in range(10):\n",
    "    ave_dist.append(sum(obs_dists_list[i]) / len(obs_dists_list[i]))\n",
    "#     ave_dist.append(min(obs_dists_list[i]))\n",
    "    # print(obs_dists_list[i])\n",
    "    # plt.plot(np.arange(len(obs_dists_list[i])), obs_dists_list[i], color='red')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))   \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('distance to unsafe', fontsize = 15)\n",
    "plt.title('env being attacked')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ave_dist = []\n",
    "for i in range(10):\n",
    "    ave_dist.append(sum(clean_obs_dists_list[i]) / len(clean_obs_dists_list[i]))\n",
    "#     ave_dist.append(min(clean_obs_dists_list[i]))\n",
    "    # plt.plot(np.arange(len(clean_obs_dists_list[i])), clean_obs_dists_list[i], color='green')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))       \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "# plt.ylabel('obstacle distance')\n",
    "plt.title('clean env')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d195ff-ca0f-477a-807f-f78f8b659cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
