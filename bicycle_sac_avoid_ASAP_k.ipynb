{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4c660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import cos, sin\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "from typing import Optional\n",
    "from control.matlab import ss, lsim, linspace, c2d\n",
    "from functools import partial\n",
    "from state_estimation import Estimator\n",
    "import math\n",
    "import gym\n",
    "from stable_baselines3 import PPO, SAC, TD3, DDPG, DQN, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0c283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dbe14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CSTR model\n",
    "def bicycle(x,t,u, params={}):\n",
    "    lr = 1.105\n",
    "    lf = 1.738\n",
    "    psi = x[2]\n",
    "    v = x[3]\n",
    "    alpha = u[0]\n",
    "    sigma = u[1]\n",
    "    xdot =np.zeros(4)\n",
    "    beta = math.atan((lr/(lr+lf)*math.tan(sigma)))\n",
    "    xdot[0] = v*math.cos(psi+beta)\n",
    "    xdot[1] = v*math.sin(psi+beta)\n",
    "    xdot[2] = v/lr*math.sin(beta)\n",
    "    xdot[3] = alpha\n",
    "    return xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe861ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 20\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [1,1,0,math.sqrt(2)]\n",
    "        self.obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.8\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 20\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = np.linalg.norm(self.state - self.obstacle)\n",
    "        reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "        self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "        if self.steps < 10:\n",
    "            reach_reward = max(self.reward_cache)\n",
    "        else:\n",
    "            reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "        final_reward = min(reach_reward, avoid_reward)\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 10\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or max(np.absolute(self.state))>20 or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c0b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpsl/anaconda3/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "reached = []\n",
    "for k in [20]:\n",
    "    env = bicycleEnv()\n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    model.learn(total_timesteps=300000, progress_bar=False)\n",
    "    vec_env = model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    center = [1,1,0,math.sqrt(2)]\n",
    "    obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6ed894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[917]\n"
     ]
    }
   ],
   "source": [
    "print(reached)\n",
    "model.save(\"SAC_bicycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82553493",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"SAC_bicycle.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87d6e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, root\n",
    "def fgsm_attack(state, model, epsilon, policy, norm, args):\n",
    "    state = torch.from_numpy(state)\n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    action = model.actor(state)\n",
    "    # target = torch.argmax(q_vals).unsqueeze(0)\n",
    "    # preds = torch.softmax(q_vals, 1)\n",
    "    # The loss is calcualted with cross entropy\n",
    "    # current_q = self.critic(state, action)\n",
    "    # cri = model.critic(state)\n",
    "    q_vals = (model.critic(state, action))\n",
    "    loss = (q_vals[0] + q_vals[1]) / 2 * (-1)\n",
    "    # print(target)\n",
    "    # loss_func = torch.nn.CrossEntropyLoss()\n",
    "    # loss = loss_func(preds, target)\n",
    "    model.actor.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "   \n",
    "    state_grad = state.grad.detach().squeeze()\n",
    "    \n",
    "    state = state.squeeze()\n",
    "    # Perturb only agent position and ball position\n",
    "    if norm == float('inf'):\n",
    "        perturbed_state = state + epsilon * state_grad.sign()\n",
    "    elif norm == 2:\n",
    "        perturbed_state = state + epsilon * state_grad / torch.norm(state_grad, norm)\n",
    "    elif norm == 1:\n",
    "        index = torch.argmax(state_grad)\n",
    "        per = torch.zeros_like(state_grad)\n",
    "        per[index] = 1\n",
    "        perturbed_state = state + epsilon * per\n",
    "    return perturbed_state.detach().cpu().numpy()\n",
    "\n",
    "def safe_attack(env, state, model, epsilon, policy, norm, args):\n",
    "    action = model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    def f(x):\n",
    "    # Objective function\n",
    "        return 1\n",
    "    def fun(x):\n",
    "        return np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) \n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "    x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    non_linear_eq= lambda x: np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) -\\\n",
    "                            np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center)\n",
    "    non_linear_constr = NonlinearConstraint(non_linear_eq, - np.inf, 0.0 )\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "    result = minimize(f, x_start, method='trust-constr', bounds=bounds)\n",
    "    # print(result.x)\n",
    "    op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = model.actor(state, deterministic=True)[0].requires_grad_(True)\n",
    "        action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        model.actor.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 30 * state_grad.sign()\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = model.actor(perturbed_state, deterministic=True)[0]\n",
    "        low, high = -7, 7\n",
    "        action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach(),))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist > env.safe_norm_radius :\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack\n",
    "        \n",
    "    #     if np.minimum(env.target_norm_radius - pertub_dist, pertub_obs_dist - env.safe_norm_radius) >= \\\n",
    "    #         np.minimum(env.target_norm_radius - dist, obs_dist - env.safe_norm_radius):\n",
    "            \n",
    "    #         # print(_action)\n",
    "    #         # print(action.detach())\n",
    "    #         if next_obs_dist < next_origin_obs_dist:\n",
    "    #             # print('find solution')\n",
    "    #             if next_obs_dist < effect:\n",
    "    #                 effect = next_obs_dist\n",
    "    #                 # print(effect)\n",
    "    #                 attack = (state.detach().numpy() - _state)[0]\n",
    "                  \n",
    "    # # print('not find solution')\n",
    "    # if attack is None:\n",
    "    #     return np.zeros_like(_state)\n",
    "    # else:\n",
    "    #     # print('find solution')\n",
    "    #     return attack\n",
    "\n",
    "    \n",
    "# def safe_attack(env, state, model, epsilon, policy, norm, args):\n",
    "    \n",
    "#     action = model.predict(state, deterministic=True)[0]\n",
    "#     _action = action\n",
    "#     _state = state\n",
    "#     # state = np.reshape(state, (3,1))\n",
    "#     def f(x):\n",
    "#     # Objective function\n",
    "#         ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "        \n",
    "#         return np.linalg.norm(odeint(bicycle, env.state, ts, args=(x,))[-1] - env.obstacle )\n",
    "#     x_start = np.array(action)\n",
    "#     lim = [-7, 7]\n",
    "\n",
    "#     bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "#     ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "#     x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "#     non_linear_eq= lambda x: env.target_norm_radius - np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) +\\\n",
    "#     np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) - 0.3-\\\n",
    "#      (env.target_norm_radius - np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center) +\\\n",
    "#     np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.obstacle) - 0.3)\n",
    "    \n",
    "#     dist = np.linalg.norm(x_state - env.center)\n",
    "#     obs_dist = np.linalg.norm(x_state - env.obstacle)\n",
    "#     reward = env.target_norm_radius - dist + obs_dist - 0.3\n",
    "#     non_linear_constr = NonlinearConstraint(non_linear_eq, 0.0, np.inf)\n",
    "#     # result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds)\n",
    "   \n",
    "#     op_action = (result.x)\n",
    "    \n",
    "#     state = torch.from_numpy(state)\n",
    "    \n",
    "#     state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "#     # print(model.predict(state, deterministic=True)[0])\n",
    "#     for i in range(100):\n",
    "     \n",
    "#         action = model.actor(state, deterministic=True)[0].requires_grad_(True)\n",
    "#         action = action * 7\n",
    "#         action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "#         # compute the distance\n",
    "#         pdist = torch.nn.PairwiseDistance(p=2)\n",
    "#         loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "#         # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "#         model.actor.zero_grad()\n",
    "#         loss = loss.double()\n",
    "#         # print(action.dtype)\n",
    "#         loss.backward()\n",
    "       \n",
    "#         state_grad = state.grad.detach().squeeze()\n",
    "#         perturbed_state = state - epsilon / 40 * state_grad.sign()\n",
    "#         # print(state_grad)\n",
    "#         # project!\n",
    "#         # print(perturbed_state[0])\n",
    "#         torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "#         # print(perturbed_state[0])\n",
    "        \n",
    "#         scaled_action = model.actor(perturbed_state, deterministic=True)[0]\n",
    "#         low, high = -7, 7\n",
    "#         action_next = low + (0.5 * (scaled_action + 1.0) * (high - low))\n",
    "#         state = perturbed_state.detach().requires_grad_(True)\n",
    "#         # print(f'state:{perturbed_state}')\n",
    "#     # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "#     return  state.detach().numpy() - _state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdc3f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpsl/anaconda3/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/cpsl/anaconda3/lib/python3.10/site-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number reached = 35\n",
      "Total number violate = 0\n",
      "clean env for reference\n",
      "Total number reached = 89\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": [
    "# Test 50 traces for safe attack\n",
    "\n",
    "# norm = 2\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "clean_env = bicycleEnv()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "obs_dists = []\n",
    "obs_dists_list = []\n",
    "dist_list = []\n",
    "center = [1,1,0,math.sqrt(2)]\n",
    "obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "num_reached = 0\n",
    "action_list = []\n",
    "pertub_action_list = [] \n",
    "number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "for j in range(100):\n",
    "    dim0 = []\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    euclid = []\n",
    "    state = env.reset()\n",
    "    _ = clean_env.reset()\n",
    "    clean_env.state = state\n",
    "    clean_state = state\n",
    "    # print(f'state:{state}, clean_state:{clean_state}')\n",
    "    # Print initial state\n",
    "    for i in range(env.step_const):\n",
    "      \n",
    "        # action = model.predict(state, deterministic=True)\n",
    "        # pertub_action = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        attack = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        # print(attack)\n",
    "        pertub_state = state + attack\n",
    "        # print(pertub_state, state)\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        # print(pertub_action)\n",
    "        # new_state, reward, done, _ = env.step(pertub_action[0])\n",
    "        new_state, reward, done, _ = env.step(pertub_action)\n",
    "        state = new_state\n",
    "        # new_state, reward, done, _ = env.step(action[0])\n",
    "        \n",
    "        dist = np.linalg.norm(state - env.center)\n",
    "        obs_dist = np.linalg.norm(state - env.obstacle)\n",
    "        pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        obs_dists.append(obs_dist)\n",
    "        if obs_dist <= env.safe_norm_radius:\n",
    "            number_violate += 1\n",
    "            break\n",
    "        if dist <= env.target_norm_radius: # stop\n",
    "            num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    obs_dists_list.append(obs_dists)\n",
    "    obs_dists = []\n",
    "    \n",
    "    # print(env.final_reward_cache)\n",
    "    # print(\"dirty env\")\n",
    "    # print(obs_dist_list)\n",
    "    # print(dist_list)\n",
    "   \n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "    \n",
    "    # print(clean_env.final_reward_cache)\n",
    "    # print(\"clean env\")\n",
    "    # print(clean_obs_dist_list)\n",
    "    # print(clean_dist_list)\n",
    "   \n",
    "    # dims0.append(dim0)\n",
    "    # dims1.append(dim1)\n",
    "    # dims2.append(dim2)\n",
    "    euclids.append(euclid)\n",
    "ref= [math.pi/2]*30\n",
    "print(\"Total number reached = \" + str(num_reached))\n",
    "print(\"Total number violate = \" + str(number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "res_list.append(num_reached)\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(clean_obs_dist_list) / len(clean_obs_dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c7582f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print((obs_dists_list[0]))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(obs_dists_list[i]) / len(obs_dists_list[i]))\n",
    "    ave_dist.append(min(obs_dists_list[i]))\n",
    "    # print(obs_dists_list[i])\n",
    "    # plt.plot(np.arange(len(obs_dists_list[i])), obs_dists_list[i], color='red')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))   \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('distance to unsafe', fontsize = 15)\n",
    "plt.title('env being attacked')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(clean_obs_dists_list[i]) / len(clean_obs_dists_list[i]))\n",
    "    ave_dist.append(min(clean_obs_dists_list[i]))\n",
    "    # plt.plot(np.arange(len(clean_obs_dists_list[i])), clean_obs_dists_list[i], color='green')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))       \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "# plt.ylabel('obstacle distance')\n",
    "plt.title('clean env')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d195ff-ca0f-477a-807f-f78f8b659cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
