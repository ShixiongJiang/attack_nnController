{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d4c660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import cos, sin\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "from typing import Optional\n",
    "from control.matlab import ss, lsim, linspace, c2d\n",
    "from functools import partial\n",
    "from state_estimation import Estimator\n",
    "import math\n",
    "import gym\n",
    "from stable_baselines3 import PPO, SAC, TD3, DDPG, DQN, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0c283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53dbe14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CSTR model\n",
    "def bicycle(x,t,u, params={}):\n",
    "    lr = 1.105\n",
    "    lf = 1.738\n",
    "    psi = x[2]\n",
    "    v = x[3]\n",
    "    alpha = u[0]\n",
    "    sigma = u[1]\n",
    "    xdot =np.zeros(4)\n",
    "    beta = math.atan((lr/(lr+lf)*math.tan(sigma)))\n",
    "    xdot[0] = v*math.cos(psi+beta)\n",
    "    xdot[1] = v*math.sin(psi+beta)\n",
    "    xdot[2] = v/lr*math.sin(beta)\n",
    "    xdot[3] = alpha\n",
    "    return xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe861ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 20\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [1,1,0,math.sqrt(2)]\n",
    "        self.obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.8\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 20\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = np.linalg.norm(self.state - self.obstacle)\n",
    "        reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "        self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "        if self.steps < 10:\n",
    "            reach_reward = max(self.reward_cache)\n",
    "        else:\n",
    "            reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "        final_reward = min(reach_reward, avoid_reward)\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 10\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or max(np.absolute(self.state))>20 or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c0b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpsl/anaconda3/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "reached = []\n",
    "for k in [20]:\n",
    "    env = bicycleEnv()\n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    model.learn(total_timesteps=300000, progress_bar=False)\n",
    "    vec_env = model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    center = [1,1,0,math.sqrt(2)]\n",
    "    obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6ed894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[917]\n"
     ]
    }
   ],
   "source": [
    "# print(reached)\n",
    "# model.save(\"SAC_bicycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82553493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"SAC_bicycle.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "87d6e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, root\n",
    "def fgsm_attack(state, model, epsilon, policy, norm, args):\n",
    "    state = torch.from_numpy(state)\n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    action = model.actor(state)\n",
    "    # target = torch.argmax(q_vals).unsqueeze(0)\n",
    "    # preds = torch.softmax(q_vals, 1)\n",
    "    # The loss is calcualted with cross entropy\n",
    "    # current_q = self.critic(state, action)\n",
    "    # cri = model.critic(state)\n",
    "    q_vals = (model.critic(state, action))\n",
    "    loss = (q_vals[0] + q_vals[1]) / 2 * (-1)\n",
    "    # print(target)\n",
    "    # loss_func = torch.nn.CrossEntropyLoss()\n",
    "    # loss = loss_func(preds, target)\n",
    "    model.actor.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "   \n",
    "    state_grad = state.grad.detach().squeeze()\n",
    "    \n",
    "    state = state.squeeze()\n",
    "    # Perturb only agent position and ball position\n",
    "    if norm == float('inf'):\n",
    "        perturbed_state = state + epsilon * state_grad.sign()\n",
    "    elif norm == 2:\n",
    "        perturbed_state = state + epsilon * state_grad / torch.norm(state_grad, norm)\n",
    "    elif norm == 1:\n",
    "        index = torch.argmax(state_grad)\n",
    "        per = torch.zeros_like(state_grad)\n",
    "        per[index] = 1\n",
    "        perturbed_state = state + epsilon * per\n",
    "    return perturbed_state.detach().cpu().numpy()\n",
    "\n",
    "def safe_attack(env, state, model, epsilon, policy, norm, args):\n",
    "    action = model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    def f(x):\n",
    "    # Objective function\n",
    "        return 1\n",
    "    def fun(x):\n",
    "        return np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) \n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "    x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    non_linear_eq= lambda x: np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) -\\\n",
    "                            np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center)\n",
    "    non_linear_constr = NonlinearConstraint(non_linear_eq, - np.inf, 0.0 )\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "    result = minimize(fun, x_start, method='trust-constr', bounds=bounds)\n",
    "    # print(result.x)\n",
    "    op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = model.actor(state, deterministic=True)[0].requires_grad_(True)\n",
    "        action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        model.actor.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 30 * state_grad.sign()\n",
    "        perturbed_state = torch.clamp(perturbed_state, min=torch.from_numpy(_state - 0.5), max=torch.from_numpy(_state + 0.5))\n",
    "\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = model.actor(perturbed_state, deterministic=True)[0]\n",
    "        low, high = -7, 7\n",
    "        action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "#         print(action_next)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach(),))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist > env.safe_norm_radius and pertub_dist < obs_dist:\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdc3f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.0668, -4.8954], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.8593, -4.8640], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.3548, -4.8719], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7385, -4.8831], grad_fn=<AddBackward0>)\n",
      "tensor([-2.3005, -4.8612], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3226, -4.8642], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5967,  3.0898], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5439,  2.8920], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1639,  2.5719], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5181,  2.8831], grad_fn=<AddBackward0>)\n",
      "tensor([0.8430, 4.7367], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6331, -4.8274], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4803,  2.3841], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2806, -4.8040], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5688,  4.7596], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5742, -4.8023], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9271,  4.8118], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4467, -4.8078], grad_fn=<AddBackward0>)\n",
      "tensor([-2.2059,  4.9144], grad_fn=<AddBackward0>)\n",
      "tensor([1.6951, 3.6788], grad_fn=<AddBackward0>)\n",
      "tensor([0.3038, 2.9335], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9328, -4.7861], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0369,  4.7662], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3832, -4.8035], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1056,  2.5679], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1543, -4.7452], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3781,  4.6522], grad_fn=<AddBackward0>)\n",
      "tensor([0.5548, 4.8186], grad_fn=<AddBackward0>)\n",
      "tensor([1.4426, 1.4962], grad_fn=<AddBackward0>)\n",
      "tensor([1.1908, 2.9206], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0245,  4.6783], grad_fn=<AddBackward0>)\n",
      "tensor([0.7073, 4.9905], grad_fn=<AddBackward0>)\n",
      "tensor([1.1218, 1.4036], grad_fn=<AddBackward0>)\n",
      "tensor([0.8922, 3.2395], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1898,  4.6955], grad_fn=<AddBackward0>)\n",
      "tensor([0.8806, 5.0001], grad_fn=<AddBackward0>)\n",
      "tensor([1.0775, 1.6205], grad_fn=<AddBackward0>)\n",
      "tensor([0.6080, 0.1685], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5149, -3.4402], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1495, -2.6022], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3303, -4.0690], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3224, -4.4533], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4987, -4.5767], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6783, -4.7645], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6170, -4.7506], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6491, -4.3788], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9655, -4.7496], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8804, -4.6893], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3973, -4.7649], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8735, -4.6922], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4246, -4.7645], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1478, -2.0287], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0332, -4.1211], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3843, -3.9908], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7900, -2.9390], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5548, -4.1537], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8023, -4.6442], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2099, -4.7904], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2888, -3.8706], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6127, -4.6669], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3339, -4.7692], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7365, -4.7464], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3686, -4.7111], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8686, -4.7456], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4203, -4.7129], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4593, -4.6274], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9907, -4.7639], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5521, -4.7495], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2504, -4.5484], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1808, -4.7825], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0851, -4.5603], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0987, -4.7929], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8476, -4.7814], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2445, -4.5632], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1195, -4.7823], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0993, -4.5553], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3101, -4.7837], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0146, -4.5562], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1744, -4.7930], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8527, -4.7773], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6404, -4.7577], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0897, -4.5759], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9704, -4.7962], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8035, -4.7842], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3316, -4.5780], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0557, -4.7856], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1665, -4.5705], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2448, -4.7867], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0916, -4.5734], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1070, -4.7970], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8335, -4.7811], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1602, -4.5624], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1896, -4.7814], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0208, -4.5412], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3966, -4.7819], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0442, -4.5375], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2082, -4.7901], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8920, -4.7716], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6025, -4.7507], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2392, -4.7148], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.9638, -4.8491], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.8689, -4.8567], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.4338, -4.8718], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6953, -4.8875], grad_fn=<AddBackward0>)\n",
      "tensor([-3.4351, -4.8487], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2670, -4.8224], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1951, -4.8098], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6779, -4.8021], grad_fn=<AddBackward0>)\n",
      "tensor([-2.3546,  4.9434], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0428, -4.8205], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8683,  4.3023], grad_fn=<AddBackward0>)\n",
      "tensor([0.1058, 4.8013], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9295, -4.7966], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0942, -4.8105], grad_fn=<AddBackward0>)\n",
      "tensor([-2.2778,  4.7785], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9180, -4.8126], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1940,  2.1663], grad_fn=<AddBackward0>)\n",
      "tensor([0.2606, 2.2197], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6222, -4.7948], grad_fn=<AddBackward0>)\n",
      "tensor([-1.9880,  4.8724], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9225, -4.7911], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4981,  4.8512], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4988, -4.8273], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5410, -4.8215], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4850,  4.6905], grad_fn=<AddBackward0>)\n",
      "tensor([0.5873, 4.8344], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6648, -3.6236], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7033, -4.8145], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2278,  3.8034], grad_fn=<AddBackward0>)\n",
      "tensor([0.1003, 3.4807], grad_fn=<AddBackward0>)\n",
      "tensor([0.2154, 4.7203], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0081, -4.8092], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1982,  4.8033], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5418, -4.8084], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4521,  4.8038], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.8075, -4.8070], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1905,  4.7617], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6856, -4.8040], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4665,  4.7990], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6132, -4.8071], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0359,  4.7799], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4288, -4.8071], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9346,  4.8278], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3660, -4.8099], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1338,  4.7941], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4516, -4.8089], grad_fn=<AddBackward0>)\n",
      "tensor([-2.1877,  4.9084], grad_fn=<AddBackward0>)\n",
      "tensor([1.6597, 3.4996], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0649,  4.7354], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4565, -4.8131], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0550,  2.8218], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0541,  1.3000], grad_fn=<AddBackward0>)\n",
      "tensor([0.7576, 4.7198], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5350, -4.7883], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7369,  4.7549], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3693, -4.7947], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1658,  4.7295], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4222, -4.7993], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1935,  4.7183], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4274, -4.8042], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6918,  4.7833], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2765, -4.8141], grad_fn=<AddBackward0>)\n",
      "tensor([-2.1781,  4.9039], grad_fn=<AddBackward0>)\n",
      "tensor([1.6732, 2.5539], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.8298, -4.8047], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4117,  3.3671], grad_fn=<AddBackward0>)\n",
      "tensor([0.0355, 4.7293], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9764, -4.8164], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5404, -4.7950], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6968,  2.5274], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5700, -4.8075], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6531,  4.7547], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7734, -4.8238], grad_fn=<AddBackward0>)\n",
      "tensor([0.2321, 1.6558], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5503, -4.8457], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4396, -4.8214], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1568, -0.3501], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0946, -4.8132], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2337, -4.7840], grad_fn=<AddBackward0>)\n",
      "tensor([-1.8185,  4.8244], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5392, -4.8067], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7543,  2.8696], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3689, -4.8158], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5776, -3.8034], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3997,  4.5483], grad_fn=<AddBackward0>)\n",
      "tensor([0.2904, 4.7149], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.8267, -4.8250], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4735, -4.8194], grad_fn=<AddBackward0>)\n",
      "tensor([-1.7218,  4.7425], grad_fn=<AddBackward0>)\n",
      "tensor([0.7422, 2.0622], grad_fn=<AddBackward0>)\n",
      "tensor([0.4328, 1.9026], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6184, -4.8123], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2547, -4.8003], grad_fn=<AddBackward0>)\n",
      "tensor([-1.9421,  4.7860], grad_fn=<AddBackward0>)\n",
      "tensor([1.3112, 1.3158], grad_fn=<AddBackward0>)\n",
      "tensor([0.5324, 1.6861], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5042, -4.8185], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4686, -4.8071], grad_fn=<AddBackward0>)\n",
      "tensor([-1.8933,  4.8398], grad_fn=<AddBackward0>)\n",
      "tensor([1.5612, 1.6363], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.0421, -4.8488], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.1230, -4.8560], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.6360, -4.8657], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6119, -4.8732], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9996, -4.8653], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3484, -4.8356], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9967,  3.0212], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8530,  3.8487], grad_fn=<AddBackward0>)\n",
      "tensor([0.5403, 2.9874], grad_fn=<AddBackward0>)\n",
      "tensor([0.8958, 2.8635], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2845, -4.7692], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0439,  2.6332], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0951, -4.8293], grad_fn=<AddBackward0>)\n",
      "tensor([0.4096, 1.7343], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3762, -4.8488], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4232, -4.8224], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4000,  4.1048], grad_fn=<AddBackward0>)\n",
      "tensor([0.5095, 3.6749], grad_fn=<AddBackward0>)\n",
      "tensor([0.1592, 2.0328], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.8503, -4.7605], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3711,  4.3698], grad_fn=<AddBackward0>)\n",
      "tensor([0.2949, 4.6677], grad_fn=<AddBackward0>)\n",
      "tensor([0.7022, 4.7333], grad_fn=<AddBackward0>)\n",
      "tensor([1.4828, 1.3959], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8658, 1.7577], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5566, -4.8312], grad_fn=<AddBackward0>)\n",
      "tensor([0.1340, 1.9957], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7013, -4.8310], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9769, -4.7722], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4246,  4.7953], grad_fn=<AddBackward0>)\n",
      "tensor([0.8949, 1.2488], grad_fn=<AddBackward0>)\n",
      "tensor([0.4698, 1.4296], grad_fn=<AddBackward0>)\n",
      "tensor([0.8599, 1.5030], grad_fn=<AddBackward0>)\n",
      "tensor([0.8760, 3.8507], grad_fn=<AddBackward0>)\n",
      "tensor([0.3796, 3.3623], grad_fn=<AddBackward0>)\n",
      "tensor([0.0883, 1.1298], grad_fn=<AddBackward0>)\n",
      "tensor([0.3389, 1.5309], grad_fn=<AddBackward0>)\n",
      "tensor([0.9424, 3.7276], grad_fn=<AddBackward0>)\n",
      "tensor([0.1730, 3.4020], grad_fn=<AddBackward0>)\n",
      "tensor([0.2049, 4.6399], grad_fn=<AddBackward0>)\n",
      "tensor([0.8557, 4.7222], grad_fn=<AddBackward0>)\n",
      "tensor([1.5423, 0.7719], grad_fn=<AddBackward0>)\n",
      "tensor([0.2659, 0.7067], grad_fn=<AddBackward0>)\n",
      "tensor([0.2522, 0.2338], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0303, -4.7377], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9804, -4.5895], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5726, -4.8052], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5671, -4.7919], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1507, -0.9288], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5261, -0.9432], grad_fn=<AddBackward0>)\n",
      "tensor([0.6606, 1.0202], grad_fn=<AddBackward0>)\n",
      "tensor([0.7743, 4.7578], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2911, -4.3149], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7242, -4.7800], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3028, -4.7480], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2772,  4.7290], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3723, -4.7579], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0689, -3.8405], grad_fn=<AddBackward0>)\n",
      "tensor([0.0465, 0.9431], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2242, -4.5754], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4926, -4.5405], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6074, -4.8045], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9166, -3.4772], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3358, -0.1166], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0495, -0.8012], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2480, -4.0591], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5890, -4.7034], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6917, -4.9500], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0462, -0.4713], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5325, -4.5771], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3769, -4.8768], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7224, -4.6431], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4992, -4.8439], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1523, -4.7070], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2270, -4.9142], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9368, -4.8751], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7365, -4.8066], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2539,  4.2827], grad_fn=<AddBackward0>)\n",
      "tensor([5.0969e-03, 5.1428e+00], grad_fn=<AddBackward0>)\n",
      "tensor([1.3540, 5.0148], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8041, -3.4935], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2400, -4.7525], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6788, -4.5840], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0627, -1.8514], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6665, -4.2625], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6076, -4.6666], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9905, -3.3742], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7376, -4.0310], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7297, -3.0858], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3097, -3.1892], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9248, -2.6675], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.1933, -2.9005], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9359, -2.8694], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5891, -2.9455], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.1457, -3.1711], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5284, -3.8050], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.1597, -3.8125], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9890, -3.8183], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9242, -3.7083], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5525, -3.7108], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.1442, -4.8508], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.1413, -4.8653], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.5589, -4.8760], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2801, -4.8944], grad_fn=<AddBackward0>)\n",
      "tensor([-2.5871, -4.8730], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8064, -4.8528], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3976, -4.9325], grad_fn=<AddBackward0>)\n",
      "tensor([-1.7185,  2.8630], grad_fn=<AddBackward0>)\n",
      "tensor([0.5562, 3.3718], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2276,  2.8421], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6269,  2.5546], grad_fn=<AddBackward0>)\n",
      "tensor([1.2344, 2.7108], grad_fn=<AddBackward0>)\n",
      "tensor([0.2835, 4.7940], grad_fn=<AddBackward0>)\n",
      "tensor([1.8874, 1.9937], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4056, -4.8311], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5341, -4.8107], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3909,  2.3767], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0224,  0.9516], grad_fn=<AddBackward0>)\n",
      "tensor([0.0765, 0.5947], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3171, -0.1844], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0081,  0.0051], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0805, -3.3758], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5725, -4.6969], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4868, -4.7665], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7967, -4.7494], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3785, -4.7263], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2747, -4.6302], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9782, -4.7460], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7413, -4.7403], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1862, -4.3443], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9766, -4.7258], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6865, -4.6599], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2275, -4.7703], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6857, -4.7513], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4013, -4.7131], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5144, -4.6324], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9751, -4.7966], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8684, -4.7877], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7723, -4.7702], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5544, -4.7484], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3122, -4.7005], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8229, -4.7469], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4137, -4.7038], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8786, -4.7473], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4167, -4.7075], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9000, -4.7480], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4073, -4.7107], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9161, -4.7486], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0662, -4.5471], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1922, -4.7909], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8464, -4.7763], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5970, -4.7576], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2087, -4.5704], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0998, -4.7855], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8394, -4.7775], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2023, -4.4993], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2336, -4.7836], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3776, -4.5747], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1587, -4.7863], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1666, -4.5724], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2608, -4.7866], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8939, -4.7728], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4049, -4.7598], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1638, -4.5803], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0830, -4.7877], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8453, -4.7779], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1403, -4.5097], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3031, -4.7771], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4701, -4.6996], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0169, -4.7841], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0279, -4.5583], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2718, -4.7849], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4227, -4.7349], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4941, -4.6591], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1483, -4.7696], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5253, -4.7576], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1575, -4.5753], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1439, -4.7867], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8487, -4.7757], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5953, -4.7569], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2752, -4.7212], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5236, -4.6505], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9402, -4.8008], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8468, -4.7944], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7649, -4.7794], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1015, -4.5415], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1961, -4.7793], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0706, -4.5329], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3410, -4.7799], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0351, -4.5220], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2122, -4.7875], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8759, -4.7701], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5900, -4.7480], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2670, -4.7043], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9957, -4.7852], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1255, -4.5674], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2539, -4.7860], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0632, -4.5698], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1297, -4.7964], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8404, -4.7805], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.1577, -4.8389], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.1982, -4.8653], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.3788, -4.8802], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7653, -4.8971], grad_fn=<AddBackward0>)\n",
      "tensor([-2.4313, -4.8751], grad_fn=<AddBackward0>)\n",
      "tensor([-1.6731, -4.8560], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5556, -4.9188], grad_fn=<AddBackward0>)\n",
      "tensor([-2.0082,  3.1070], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2249,  3.5080], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9446,  2.8327], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5239,  2.5573], grad_fn=<AddBackward0>)\n",
      "tensor([1.1752, 2.7361], grad_fn=<AddBackward0>)\n",
      "tensor([0.2776, 4.7944], grad_fn=<AddBackward0>)\n",
      "tensor([1.9428, 1.9916], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2371, -4.8089], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8728,  4.7549], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2611, -4.8149], grad_fn=<AddBackward0>)\n",
      "tensor([-2.1297,  4.8953], grad_fn=<AddBackward0>)\n",
      "tensor([1.6231, 2.2464], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7634, -4.8077], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6406,  4.7834], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7009, -4.7957], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0524,  3.2085], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5504, -4.7950], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3887,  4.2459], grad_fn=<AddBackward0>)\n",
      "tensor([0.5529, 4.7279], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.1260, -4.8101], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5357, -4.7974], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4040,  4.8009], grad_fn=<AddBackward0>)\n",
      "tensor([1.2192, 1.5125], grad_fn=<AddBackward0>)\n",
      "tensor([0.5678, 3.8887], grad_fn=<AddBackward0>)\n",
      "tensor([0.5429, 3.3856], grad_fn=<AddBackward0>)\n",
      "tensor([1.2016e-03, 1.5294e+00], grad_fn=<AddBackward0>)\n",
      "tensor([0.9425, 3.9901], grad_fn=<AddBackward0>)\n",
      "tensor([0.2686, 3.9338], grad_fn=<AddBackward0>)\n",
      "tensor([0.2405, 3.2828], grad_fn=<AddBackward0>)\n",
      "tensor([0.2161, 4.6673], grad_fn=<AddBackward0>)\n",
      "tensor([0.9078, 4.6811], grad_fn=<AddBackward0>)\n",
      "tensor([0.8408, 4.8132], grad_fn=<AddBackward0>)\n",
      "tensor([1.5122, 1.0672], grad_fn=<AddBackward0>)\n",
      "tensor([0.5166, 1.3310], grad_fn=<AddBackward0>)\n",
      "tensor([0.5582, 3.4403], grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 1.1238], grad_fn=<AddBackward0>)\n",
      "tensor([0.4767, 1.4654], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8182, 3.7810], grad_fn=<AddBackward0>)\n",
      "tensor([0.0358, 4.7134], grad_fn=<AddBackward0>)\n",
      "tensor([1.4563, 0.5486], grad_fn=<AddBackward0>)\n",
      "tensor([0.2088, 0.4962], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0957, -2.5334], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4441, -4.6328], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1360, -4.7550], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6785, -4.7490], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2592, -4.6997], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2465, -4.7742], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7937, -4.7548], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2341, -4.7327], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4133, -4.6502], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1604, -4.7671], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7019, -4.7466], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4315, -4.6999], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8212, -4.7470], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4540, -4.7037], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8611, -4.7483], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4418, -4.7074], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8803, -4.7492], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4283, -4.7107], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8947, -4.7499], grad_fn=<AddBackward0>)\n",
      "tensor([-3.3627e-03, -4.5454e+00], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2149, -4.7905], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8612, -4.7777], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6044, -4.7595], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3194, -4.6100], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1029, -4.7939], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8652, -4.7770], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2894e-03, -4.4897e+00], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2897, -4.7741], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0253, -4.4618], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4283, -4.7702], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1929, -4.6302], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1691, -4.7797], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0060, -4.4857], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3796, -4.7784], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1709, -4.2902], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7170, -4.6821], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3217, -4.7937], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7721, -4.7837], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5107, -4.7559], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0315, -4.4344], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6017, -4.6168], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4286, -4.7922], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9367, -4.7771], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1231, -4.4770], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3848, -4.7734], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1545, -4.6411], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2060, -4.7831], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0421, -4.5068], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9394, -4.7458], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4016, -4.7099], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0444, -4.7860], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1103, -4.5698], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.1997, -4.8214], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.1118, -4.8704], grad_fn=<AddBackward0>)\n",
      "tensor([ 4.4141, -4.8895], grad_fn=<AddBackward0>)\n",
      "tensor([-2.5778, -4.8970], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5448, -4.8753], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4924, -4.8587], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2472, -4.9090], grad_fn=<AddBackward0>)\n",
      "tensor([-1.8788,  2.9760], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1152,  2.5657], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5007,  2.4659], grad_fn=<AddBackward0>)\n",
      "tensor([0.5494, 2.6406], grad_fn=<AddBackward0>)\n",
      "tensor([0.8075, 3.1762], grad_fn=<AddBackward0>)\n",
      "tensor([1.0057, 4.2297], grad_fn=<AddBackward0>)\n",
      "tensor([0.4744, 4.8724], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5061, -4.8189], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0114,  1.6185], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6825, -4.8344], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0607, -4.7728], grad_fn=<AddBackward0>)\n",
      "tensor([-1.8409,  4.8405], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9175, -4.7928], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3253,  4.3174], grad_fn=<AddBackward0>)\n",
      "tensor([0.0265, 4.8429], grad_fn=<AddBackward0>)\n",
      "tensor([1.0876, 3.6790], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5958, -4.8049], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4449,  4.7878], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6192, -4.8080], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9545,  4.7613], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3757, -4.8132], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8875,  4.8124], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3277, -4.8178], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0844,  4.7745], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2927, -4.8129], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8484,  4.8124], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2675, -4.8181], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9556,  4.7798], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3513, -4.8166], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1249,  4.7372], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3070, -4.8199], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7742,  4.7942], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3004, -4.8209], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0711,  4.7486], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.1757, -4.8235], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6490,  3.0584], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.0252, -4.8253], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6436,  4.6243], grad_fn=<AddBackward0>)\n",
      "tensor([0.3966, 4.8172], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7395, -4.7815], grad_fn=<AddBackward0>)\n",
      "tensor([0.3302, 2.0852], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6714, -4.7921], grad_fn=<AddBackward0>)\n",
      "tensor([0.2263, 1.3320], grad_fn=<AddBackward0>)\n",
      "tensor([0.6494, 1.5347], grad_fn=<AddBackward0>)\n",
      "tensor([0.9879, 2.5002], grad_fn=<AddBackward0>)\n",
      "tensor([0.2561, 1.2719], grad_fn=<AddBackward0>)\n",
      "tensor([0.4852, 1.3150], grad_fn=<AddBackward0>)\n",
      "tensor([0.5163, 2.4828], grad_fn=<AddBackward0>)\n",
      "tensor([0.2215, 0.3568], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0775, -1.4182], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0789, -4.7911], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1252, -3.7346], grad_fn=<AddBackward0>)\n",
      "tensor([ 4.3297e-04, -4.7855e+00], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2914, -2.5130], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2231, -4.2049], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2459, -4.2943], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6448, -4.5269], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4720, -4.7819], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8113, -4.7856], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5404, -4.7594], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0403, -4.2090], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4191, -4.1580], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5830, -4.0545], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8222, -4.7253], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6870, -4.6610], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1333, -4.7683], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4909, -4.6209], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1331, -4.7971], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8860, -4.7824], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0443, -4.5539], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3026, -4.7818], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0296, -4.5400], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1434, -4.7910], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8423, -4.7724], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6265, -4.7530], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2211, -4.7190], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4306, -4.6378], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1393, -4.7599], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6655, -4.7315], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4724, -4.6794], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7806, -4.7319], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4989, -4.6827], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8179, -4.7341], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3004, -4.6132], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0249, -4.7875], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3039, -4.5950], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2384, -4.7894], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1909, -4.5776], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3529, -4.7907], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7699, -4.7799], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4906, -4.7500], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3773, -4.7059], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1475, -4.7758], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.7410, -4.8276], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.6098, -4.8703], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6077, -4.8969], grad_fn=<AddBackward0>)\n",
      "tensor([-2.2529, -4.8777], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1700, -4.8603], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7872, -4.8330], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3601, -4.8236], grad_fn=<AddBackward0>)\n",
      "tensor([-2.2777,  4.9664], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.4660, -4.7943], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0234, -4.8076], grad_fn=<AddBackward0>)\n",
      "tensor([-2.5616,  4.7520], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.2702, -4.7986], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4064, -4.8161], grad_fn=<AddBackward0>)\n",
      "tensor([-1.9002,  4.7483], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0601, -4.8102], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1745, -4.7678], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2827,  4.8182], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3824, -4.8183], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3978,  2.4423], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1238,  4.6859], grad_fn=<AddBackward0>)\n",
      "tensor([0.5950, 4.8213], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6064, -4.8097], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5848,  4.7914], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7123, -4.7860], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2348,  4.8831], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5844, -4.8148], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1781, -4.7822], grad_fn=<AddBackward0>)\n",
      "tensor([-1.9493,  4.8422], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9052, -4.7962], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1734,  4.1195], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0340,  4.7267], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7818, -4.8079], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0667,  4.8174], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6467, -4.7995], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5122,  4.8261], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5988, -4.8091], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0500,  4.7801], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4251, -4.8086], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9358,  4.8270], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3672, -4.8117], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1348,  4.7929], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4558, -4.8110], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2587,  4.7412], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4660, -4.8087], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8202,  4.8141], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3451, -4.8135], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1956,  4.7637], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3897, -4.8096], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8685,  4.8131], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7481, -4.8287], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5619, -4.8096], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8408,  3.7801], grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 2.1105], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0561, -4.7993], grad_fn=<AddBackward0>)\n",
      "tensor([7.3624e-04, 1.2552e+00], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4180, 1.2026], grad_fn=<AddBackward0>)\n",
      "tensor([0.4453, 0.9944], grad_fn=<AddBackward0>)\n",
      "tensor([0.4723, 4.7062], grad_fn=<AddBackward0>)\n",
      "tensor([0.7476, 4.6860], grad_fn=<AddBackward0>)\n",
      "tensor([0.6773, 4.8237], grad_fn=<AddBackward0>)\n",
      "tensor([1.6163, 1.9257], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2236, -4.8178], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6174,  2.7225], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5304, -4.8066], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5171,  4.7993], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5217, -4.7997], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6795,  4.2445], grad_fn=<AddBackward0>)\n",
      "tensor([0.3402, 4.4978], grad_fn=<AddBackward0>)\n",
      "tensor([0.5009, 4.6807], grad_fn=<AddBackward0>)\n",
      "tensor([0.6932, 4.7268], grad_fn=<AddBackward0>)\n",
      "tensor([1.5786, 1.2942], grad_fn=<AddBackward0>)\n",
      "tensor([0.1185, 4.8352], grad_fn=<AddBackward0>)\n",
      "tensor([1.2727, 1.4717], grad_fn=<AddBackward0>)\n",
      "tensor([1.0873, 1.8009], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2841, -4.7929], grad_fn=<AddBackward0>)\n",
      "tensor([0.4197, 0.5959], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0062, -1.1721], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1195, -4.7394], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1461, -4.3540], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5068, -4.7346], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7683, -4.5374], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2576, -4.7865], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5018, -4.7196], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3962, -4.6602], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1021, -4.7692], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5361, -4.7560], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1003, -4.5696], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1903, -4.7854], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1038, -4.5755], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0878, -4.7958], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8377, -4.7837], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2022, -4.5710], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1630, -4.7850], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0913, -4.5655], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3143, -4.7860], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0056, -4.5689], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1829, -4.7961], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8765, -4.7794], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0388, -4.5227], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2851, -4.7783], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.0098, -4.8350], grad_fn=<AddBackward0>)\n",
      "tensor([ 4.6869, -4.8716], grad_fn=<AddBackward0>)\n",
      "tensor([-2.7825, -4.8501], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7971, -4.8426], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3682, -4.8122], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0120, -4.1029], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2510, -4.8357], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4371, -4.8069], grad_fn=<AddBackward0>)\n",
      "tensor([-2.6115,  4.8667], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.3518, -4.8005], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3580,  4.6684], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1779,  4.8557], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.5322, -4.7905], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0153, -4.8076], grad_fn=<AddBackward0>)\n",
      "tensor([-2.4942,  4.7121], grad_fn=<AddBackward0>)\n",
      "tensor([0.3544, 4.8311], grad_fn=<AddBackward0>)\n",
      "tensor([1.8810, 3.4661], grad_fn=<AddBackward0>)\n",
      "tensor([0.2666, 2.2988], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4794, -4.7924], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0629,  4.7184], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5075, -4.7900], grad_fn=<AddBackward0>)\n",
      "tensor([-1.7397,  4.8890], grad_fn=<AddBackward0>)\n",
      "tensor([1.7371, 2.0914], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6299, -4.8199], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3582, -4.7550], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6644,  3.0052], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2376, -2.7565], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5445, -4.7945], grad_fn=<AddBackward0>)\n",
      "tensor([-1.6377,  4.7828], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.4928, -4.7959], grad_fn=<AddBackward0>)\n",
      "tensor([-1.6305,  4.8182], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0841, -4.8010], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4088,  4.8296], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6279, -4.8057], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5926,  4.8068], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9359, -4.8087], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2804,  4.7965], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2938, -4.8312], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6174, -4.8167], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2508,  4.4520], grad_fn=<AddBackward0>)\n",
      "tensor([0.5176, 4.7572], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4620, -4.8093], grad_fn=<AddBackward0>)\n",
      "tensor([0.6039, 1.7460], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3597, -4.8513], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4286, -4.8181], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2895,  4.0428], grad_fn=<AddBackward0>)\n",
      "tensor([0.4271, 3.4436], grad_fn=<AddBackward0>)\n",
      "tensor([0.0215, 1.2780], grad_fn=<AddBackward0>)\n",
      "tensor([0.5348, 2.6604], grad_fn=<AddBackward0>)\n",
      "tensor([0.2168, 0.9438], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2568, -4.6841], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6170, -4.8105], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1985, -4.8073], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7885,  4.7370], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9792, -4.8216], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5407, -4.7849], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6883,  2.7846], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6861, -4.8054], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1072,  4.7897], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.0980, -4.7864], grad_fn=<AddBackward0>)\n",
      "tensor([0.3407, 1.9079], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2943, -4.8080], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1244,  4.3618], grad_fn=<AddBackward0>)\n",
      "tensor([0.3209, 4.6579], grad_fn=<AddBackward0>)\n",
      "tensor([0.8467, 4.6915], grad_fn=<AddBackward0>)\n",
      "tensor([0.8069, 4.8876], grad_fn=<AddBackward0>)\n",
      "tensor([1.4931, 1.3027], grad_fn=<AddBackward0>)\n",
      "tensor([0.7142, 2.2444], grad_fn=<AddBackward0>)\n",
      "tensor([0.3342, 0.7749], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0637,  0.3333], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1025, -1.7504], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5300, -1.4596], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0677, -1.1107], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6683, -1.3487], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2516, -4.6343], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4653, -4.7822], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6153, -4.7132], grad_fn=<AddBackward0>)\n",
      "tensor([0.2741, 4.7147], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0449, -4.8038], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0473,  4.7915], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5840, -4.8125], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8968,  4.7392], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2873, -4.8216], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7946,  4.7954], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3229, -4.8188], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0915,  4.4119], grad_fn=<AddBackward0>)\n",
      "tensor([0.4194, 4.7660], grad_fn=<AddBackward0>)\n",
      "tensor([0.4889, 4.0166], grad_fn=<AddBackward0>)\n",
      "tensor([0.4987, 4.7344], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7379, -4.8036], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6024,  3.3993], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.1525, -4.8128], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0766,  4.7115], grad_fn=<AddBackward0>)\n",
      "tensor([0.5026, 4.7892], grad_fn=<AddBackward0>)\n",
      "tensor([1.3540, 1.5506], grad_fn=<AddBackward0>)\n",
      "tensor([1.1277, 2.0724], grad_fn=<AddBackward0>)\n",
      "tensor([0.4488, 0.6414], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0263,  0.0751], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2013, -2.3579], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0641, -4.2266], grad_fn=<AddBackward0>)\n",
      "tensor([ 5.1118, -4.8397], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6013, -4.8457], grad_fn=<AddBackward0>)\n",
      "tensor([-1.6447, -4.8209], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7485, -4.8219], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5890, -4.8366], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4383, -4.8235], grad_fn=<AddBackward0>)\n",
      "tensor([-2.0111,  4.4606], grad_fn=<AddBackward0>)\n",
      "tensor([0.3869, 4.7216], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6149, -4.8305], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4165, -4.8230], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5635,  4.7300], grad_fn=<AddBackward0>)\n",
      "tensor([1.4362, 2.4716], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2887, -4.8205], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1459, -4.7644], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0201,  3.7925], grad_fn=<AddBackward0>)\n",
      "tensor([0.1704, 2.1192], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3490, -4.8093], grad_fn=<AddBackward0>)\n",
      "tensor([-1.9461,  4.8375], grad_fn=<AddBackward0>)\n",
      "tensor([1.5451, 1.6363], grad_fn=<AddBackward0>)\n",
      "tensor([1.2348, 1.6116], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7824, -4.8453], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4032, -4.8218], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0905, -1.6481], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0550,  4.8710], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7353, -4.7953], grad_fn=<AddBackward0>)\n",
      "tensor([-1.6250,  4.8389], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6089, -4.8083], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5052,  4.8068], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.8583, -4.8080], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2632,  4.7785], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2369, -4.8336], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6188, -4.8194], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1353,  4.1666], grad_fn=<AddBackward0>)\n",
      "tensor([0.4211, 4.6530], grad_fn=<AddBackward0>)\n",
      "tensor([0.6200, 4.8704], grad_fn=<AddBackward0>)\n",
      "tensor([1.2534, 1.6108], grad_fn=<AddBackward0>)\n",
      "tensor([0.8932, 0.9611], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3636, -0.6601], grad_fn=<AddBackward0>)\n",
      "tensor([0.3423, 1.0076], grad_fn=<AddBackward0>)\n",
      "tensor([0.3203, 0.8981], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8569, -4.6974], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4804, -4.7990], grad_fn=<AddBackward0>)\n",
      "tensor([0.9592, 0.8222], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2160, -0.3026], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1673, -2.5279], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0244, -4.2288], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2495, -4.4739], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3895, -4.7865], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1420, -4.5324], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9613, -4.7489], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3175, -4.7201], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5021, -4.6450], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1256, -4.7642], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7057, -4.7416], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4548, -4.6904], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8047, -4.7422], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0229, -4.5252], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2729, -4.7867], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3153, -4.5753], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1933, -4.7873], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8553, -4.7749], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5981, -4.7559], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5217, -4.7003], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3896, -4.7409], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7791, -4.7017], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4936, -4.7403], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8221, -4.7043], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5228, -4.7411], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8216, -4.7069], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5354, -4.7422], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8046, -4.7093], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5480, -4.7431], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7868, -4.7114], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5606, -4.7439], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7730, -4.7132], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4595, -4.6656], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8216, -4.7144], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4756, -4.6686], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8273, -4.7165], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4803, -4.6715], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8248, -4.7187], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4843, -4.6744], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8217, -4.7210], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7362, -4.6525], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5587, -4.7035], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2135, -4.7916], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9051, -4.7754], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1242, -4.4662], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3750, -4.7716], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1949, -4.6327], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1372, -4.7788], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0164, -4.4966], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3904, -4.7779], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1102, -4.4248], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3162, -4.7728], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1011, -4.2540], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1561, -4.7774], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4343, -4.6364], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8443, -4.7574], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7329, -4.7495], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.4394, -4.8382], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.7844, -4.8730], grad_fn=<AddBackward0>)\n",
      "tensor([-2.9161, -4.8524], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8646, -4.8308], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7879, -4.8111], grad_fn=<AddBackward0>)\n",
      "tensor([-2.3489,  4.7790], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.8659, -4.8228], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4858, -4.8078], grad_fn=<AddBackward0>)\n",
      "tensor([-2.2076,  4.7180], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.8510, -4.8251], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5482, -4.7843], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1841,  3.0241], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0119,  0.8443], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0045,  0.4168], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0051,  0.0730], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0269, -3.5193], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5267, -2.2744], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5073, -4.6786], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8944, -4.8151], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6918, -4.8094], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7444, -4.6996], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1926, -4.7729], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0378, -4.4965], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9978, -4.7432], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4830, -4.7061], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0440, -4.7853], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0570, -4.5641], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2572, -4.7856], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4413, -4.7389], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4992, -4.6660], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1593, -4.7713], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5200, -4.7591], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1638, -4.5810], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1148, -4.7876], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8630, -4.7773], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1798, -4.4943], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3189, -4.7761], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4793, -4.6977], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0187, -4.7830], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0132, -4.5524], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2997, -4.7845], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4069, -4.7351], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4693, -4.6546], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1704, -4.7676], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5371, -4.7550], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1219, -4.5667], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1936, -4.7852], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1133, -4.5731], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0817, -4.7956], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8312, -4.7828], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2404, -4.5705], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1332, -4.7840], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0934, -4.5620], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3147, -4.7862], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0069, -4.5651], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1769, -4.7955], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8678, -4.7780], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0394, -4.5048], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2660, -4.7762], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0077, -4.4789], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4217, -4.7731], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0910, -4.4531], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1898, -4.7792], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2406, -4.5297], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2747, -4.7810], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1200, -4.5074], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3561, -4.7825], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0118, -4.4848], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9329, -4.7406], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4606, -4.6996], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0498, -4.7830], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0403, -4.5555], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3293, -4.7845], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0264, -4.5570], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2062, -4.7934], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8689, -4.7768], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6633, -4.7564], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0117, -4.5692], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0215, -4.7952], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8127, -4.7816], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2446, -4.5675], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1216, -4.7826], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0787, -4.5561], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3258, -4.7840], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0092, -4.5583], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1939, -4.7926], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8660, -4.7758], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6566, -4.7550], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0106, -4.5649], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0371, -4.7949], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8096, -4.7798], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6274, -4.7613], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1896, -4.5895], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1025, -4.7881], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8954, -4.7808], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1229, -4.5358], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1234, -4.7883], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7960, -4.7732], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5748, -4.7539], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2073, -4.5545], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4822, -4.8473], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0541, -4.8501], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3645, -4.8369], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7305, -4.8140], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8567, -4.8080], grad_fn=<AddBackward0>)\n",
      "tensor([-2.7328,  4.8399], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.1304, -4.8186], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5413,  4.8110], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9141, -4.8143], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4908, -4.8127], grad_fn=<AddBackward0>)\n",
      "tensor([-2.6255,  4.9500], grad_fn=<AddBackward0>)\n",
      "tensor([1.5972, 2.7185], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6786, -4.7544], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2058,  2.9448], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6074, -4.7821], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0108,  4.7385], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2389, -4.2876], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4584, -4.8137], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7548,  2.6451], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0043,  0.7431], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9715, -4.7497], grad_fn=<AddBackward0>)\n",
      "tensor([0.1252, 1.0781], grad_fn=<AddBackward0>)\n",
      "tensor([0.2859, 0.8679], grad_fn=<AddBackward0>)\n",
      "tensor([0.2342, 0.6685], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1880, -4.6740], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6605, -4.8032], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1363, -4.8025], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3189, -4.7872], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4542,  4.7139], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7381, -0.0229], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2331, -4.8128], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3897, -4.7949], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3879,  4.7601], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.1590, -3.7065], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7617, -4.8159], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9880,  3.4396], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9584, -4.8134], grad_fn=<AddBackward0>)\n",
      "tensor([-2.2322,  4.8228], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2847, -0.7243], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0351,  2.8140], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9255, -4.7916], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4112, -4.7895], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4247,  4.8623], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9055, -4.8032], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0936, -0.0307], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6965, -4.8010], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3764,  4.1922], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0035,  4.7757], grad_fn=<AddBackward0>)\n",
      "tensor([1.7295, 2.5572], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.9119, -4.7878], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8921,  4.7592], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3025, -4.8060], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0789,  2.1463], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0357, -4.7987], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0210,  1.2569], grad_fn=<AddBackward0>)\n",
      "tensor([0.4196, 1.2006], grad_fn=<AddBackward0>)\n",
      "tensor([0.4321, 0.9803], grad_fn=<AddBackward0>)\n",
      "tensor([0.4720, 4.7047], grad_fn=<AddBackward0>)\n",
      "tensor([0.7587, 4.6847], grad_fn=<AddBackward0>)\n",
      "tensor([0.6698, 4.8211], grad_fn=<AddBackward0>)\n",
      "tensor([1.6157, 1.9110], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2272, -4.8187], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5836,  2.5439], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.8761, -4.8240], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3619, -4.7874], grad_fn=<AddBackward0>)\n",
      "tensor([-1.7833,  4.8299], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7601, -4.8058], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2597, -2.6748], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4487, -4.8056], grad_fn=<AddBackward0>)\n",
      "tensor([-2.8280,  4.9082], grad_fn=<AddBackward0>)\n",
      "tensor([1.4991, 4.3060], grad_fn=<AddBackward0>)\n",
      "tensor([0.6382, 4.6960], grad_fn=<AddBackward0>)\n",
      "tensor([0.5476, 4.7346], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.1440, -4.8217], grad_fn=<AddBackward0>)\n",
      "tensor([0.2829, 1.9510], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5791, -4.6396], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0794, -4.8522], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8626, -4.7751], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9465,  3.8700], grad_fn=<AddBackward0>)\n",
      "tensor([0.8077, 3.3767], grad_fn=<AddBackward0>)\n",
      "tensor([0.1191, 1.5515], grad_fn=<AddBackward0>)\n",
      "tensor([1.0350, 3.6660], grad_fn=<AddBackward0>)\n",
      "tensor([0.1913, 2.4555], grad_fn=<AddBackward0>)\n",
      "tensor([0.1049, 0.6298], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1145, -0.9071], grad_fn=<AddBackward0>)\n",
      "tensor([-2.1973e-03, -4.2360e+00], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2578, -4.4909], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4135, -4.7865], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0760, -4.5452], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0191, -4.7514], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3492, -4.7280], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4756, -4.6502], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1459, -4.7675], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7173, -4.7489], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4022, -4.7022], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8404, -4.7488], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0194, -4.5388], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2313, -4.7890], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8386, -4.7768], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5991, -4.7589], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9160, -4.8364], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.8996, -4.8398], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3183, -4.8420], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0043, -4.8174], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2527, -4.8066], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7389, -4.8029], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.9257, -4.8177], grad_fn=<AddBackward0>)\n",
      "tensor([-2.6690,  4.7143], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3324, -4.7915], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1382, -4.7794], grad_fn=<AddBackward0>)\n",
      "tensor([-1.4051,  4.8387], grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0801, -4.7959], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3965,  4.8566], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7261, -4.7999], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3204,  4.8319], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.7483, -4.7920], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5535,  4.8525], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.6628, -4.8074], grad_fn=<AddBackward0>)\n",
      "tensor([-1.7228,  4.8158], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.9462, -4.8075], grad_fn=<AddBackward0>)\n",
      "tensor([-1.1859,  4.8120], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.5400, -4.8143], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5541,  4.8027], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.8307, -4.8096], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0858,  4.7709], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4431, -4.8146], grad_fn=<AddBackward0>)\n",
      "tensor([-1.8429,  4.9012], grad_fn=<AddBackward0>)\n",
      "tensor([1.7474, 2.3320], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.8791, -4.8193], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0970,  1.9181], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.7850, -4.8104], grad_fn=<AddBackward0>)\n",
      "tensor([-1.6478,  4.8511], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.4598, -4.2031], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.6004, -4.8064], grad_fn=<AddBackward0>)\n",
      "tensor([-2.1562,  4.8667], grad_fn=<AddBackward0>)\n",
      "tensor([1.7455, 1.2043], grad_fn=<AddBackward0>)\n",
      "tensor([0.3944, 1.9595], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.8759, -4.7680], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3877,  3.9014], grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 2.8107], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.8481, -4.7932], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9272,  4.7643], grad_fn=<AddBackward0>)\n",
      "tensor([ 2.2397, -4.8088], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0664,  2.0308], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8439, -4.8041], grad_fn=<AddBackward0>)\n",
      "tensor([0.2331, 1.0084], grad_fn=<AddBackward0>)\n",
      "tensor([0.0873, 0.6766], grad_fn=<AddBackward0>)\n",
      "tensor([0.2385, 0.2427], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0891, -3.2537], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4141, -4.7232], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4023, -4.4521], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3195, -4.7621], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4136, -4.7496], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4731, -4.6793], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2826, -4.7712], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7611, -4.7504], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2779, -4.7202], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4358, -4.6350], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1020, -4.7643], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5132, -4.7525], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3271, -4.5585], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1085, -4.7846], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1327, -4.5686], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0360, -4.7950], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8225, -4.7828], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3355, -4.5750], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0540, -4.7840], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1634, -4.5660], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2492, -4.7856], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0760, -4.5667], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1162, -4.7950], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8344, -4.7793], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1446, -4.5393], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1895, -4.7792], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0843, -4.5288], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3434, -4.7792], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0339, -4.5128], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.4385, -4.7736], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2997, -4.7362], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3948, -3.4460], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2919, -4.7160], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4097, -4.4966], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7048, -4.5405], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.3007, -4.7842], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8349, -4.7644], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2316, -4.4230], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8229, -4.7547], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4723, -4.7188], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4788, -4.6885], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1433, -4.7582], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5244, -4.6000], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.1832, -4.7932], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.8674, -4.7758], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6610, -4.7550], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5229, -4.7051], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5440, -4.7351], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6815, -4.7049], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6070, -4.7344], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7049, -4.7056], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6246, -4.7346], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1435, -4.8435], grad_fn=<AddBackward0>)\n",
      "tensor([-2.0318, -4.8266], grad_fn=<AddBackward0>)\n",
      "tensor([-2.0140, -4.8137], grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0408, -4.8344], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5190, -4.8281], grad_fn=<AddBackward0>)\n",
      "tensor([-1.6392, -4.8397], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1850, -4.8812], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0013, -4.8879], grad_fn=<AddBackward0>)\n",
      "tensor([-1.5867,  3.6492], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6512,  4.8447], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7173,  4.7719], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8186,  4.1907], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2777, -0.2152], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3563, -4.7989], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9459, -4.5579], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3157, -4.7604], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0286, -4.6601], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6354, -4.8740], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1203,  0.4616], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0802, -4.6466], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8323, -4.7320], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6337, -4.5132], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7942, -4.8503], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6426, -4.6147], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6223, -4.9171], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7912, -4.6792], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7783, -4.9335], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5366, -4.9363], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5217, -4.6638], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7643, -4.7910], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7495, -4.5966], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6356, -4.7210], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5773, -4.6505], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8475, -4.8226], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4655, -4.7144], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6526, -4.5684], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7194, -4.8417], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4538, -4.4537], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8093, -4.7735], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5904, -3.3232], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7779, -4.6575], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6875, -4.9273], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7611, -4.7135], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5728, -4.6606], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7459, -4.7947], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6819, -4.5731], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6197, -4.9267], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5515, -4.6546], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8993, -4.9250], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5377, -4.6658], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8787, -4.8280], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4304, -4.7235], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6261, -4.5811], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7259, -4.8608], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6766, -4.6239], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6804, -4.9662], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5651, -4.8551], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8417, -4.5935], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6430, -4.9179], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5713, -4.5760], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6360, -4.6626], grad_fn=<AddBackward0>)\n",
      "tensor([-1.0026, -4.8426], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3845, -4.7353], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5571, -4.5299], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6531, -4.6144], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9679, -4.8344], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6698, -4.8433], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6131, -4.8668], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4264, -4.5938], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8674, -4.8799], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6137, -4.8236], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4345, -4.5432], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8196, -4.7547], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6409, -4.7448], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4547, -4.5103], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8404, -4.6853], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7154, -4.7241], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7238, -4.6424], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5843, -4.6959], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7482, -4.7641], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7646, -4.5358], grad_fn=<AddBackward0>)\n",
      "tensor([-0.4358, -4.7971], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7150, -4.6313], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7310, -4.6766], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6435, -4.7322], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8725, -4.4838], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3825, -4.7973], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8440, -4.5276], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3435, -4.8182], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8053, -4.5772], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3669, -4.8335], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8148, -4.7295], grad_fn=<AddBackward0>)\n",
      "tensor([-0.9200, -4.5900], grad_fn=<AddBackward0>)\n",
      "tensor([-0.5660, -4.6920], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6166, -4.7918], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7451, -4.6085], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3894, -4.8272], grad_fn=<AddBackward0>)\n",
      "tensor([-0.6380, -4.8354], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8068, -4.6110], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 47\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# print(f'state:{state}, clean_state:{clean_state}')\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Print initial state\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(env\u001b[38;5;241m.\u001b[39mstep_const):\n\u001b[0;32m     44\u001b[0m   \n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# action = model.predict(state, deterministic=True)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# pertub_action = safe_attack(env, state, model, epsilon, policy, norm, args)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     attack \u001b[38;5;241m=\u001b[39m \u001b[43msafe_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# print(attack)\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     pertub_state \u001b[38;5;241m=\u001b[39m state \u001b[38;5;241m+\u001b[39m attack\n",
      "Cell \u001b[1;32mIn[52], line 102\u001b[0m, in \u001b[0;36msafe_attack\u001b[1;34m(env, state, model, epsilon, policy, norm, args)\u001b[0m\n\u001b[0;32m    100\u001b[0m     action_next \u001b[38;5;241m=\u001b[39m (low \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (scaled_action \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m (high \u001b[38;5;241m-\u001b[39m low)))\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# print(action_next.detach().numpy()\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mperturbed_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# print(f'state:{perturbed_state}')\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(_state \u001b[38;5;241m-\u001b[39m env\u001b[38;5;241m.\u001b[39mcenter)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test 50 traces for safe attack\n",
    "\n",
    "# norm = 2\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "clean_env = bicycleEnv()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "obs_dists = []\n",
    "obs_dists_list = []\n",
    "dist_list = []\n",
    "center = [1,1,0,math.sqrt(2)]\n",
    "obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "num_reached = 0\n",
    "action_list = []\n",
    "pertub_action_list = [] \n",
    "number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "for j in range(100):\n",
    "    dim0 = []\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    euclid = []\n",
    "    state = env.reset()\n",
    "    _ = clean_env.reset()\n",
    "    clean_env.state = state\n",
    "    clean_state = state\n",
    "    # print(f'state:{state}, clean_state:{clean_state}')\n",
    "    # Print initial state\n",
    "    for i in range(env.step_const):\n",
    "      \n",
    "        # action = model.predict(state, deterministic=True)\n",
    "        # pertub_action = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        attack = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        # print(attack)\n",
    "        pertub_state = state + attack\n",
    "        # print(pertub_state, state)\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        # print(pertub_action)\n",
    "        # new_state, reward, done, _ = env.step(pertub_action[0])\n",
    "        new_state, reward, done, _ = env.step(pertub_action)\n",
    "        state = new_state\n",
    "        # new_state, reward, done, _ = env.step(action[0])\n",
    "        \n",
    "        dist = np.linalg.norm(state - env.center)\n",
    "        obs_dist = np.linalg.norm(state - env.obstacle)\n",
    "        pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        obs_dists.append(obs_dist)\n",
    "        if obs_dist <= env.safe_norm_radius:\n",
    "            number_violate += 1\n",
    "            break\n",
    "        if dist <= env.target_norm_radius: # stop\n",
    "            num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    obs_dists_list.append(obs_dists)\n",
    "    obs_dists = []\n",
    "    \n",
    "    # print(env.final_reward_cache)\n",
    "    # print(\"dirty env\")\n",
    "    # print(obs_dist_list)\n",
    "    # print(dist_list)\n",
    "   \n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "    \n",
    "    # print(clean_env.final_reward_cache)\n",
    "    # print(\"clean env\")\n",
    "    # print(clean_obs_dist_list)\n",
    "    # print(clean_dist_list)\n",
    "   \n",
    "    # dims0.append(dim0)\n",
    "    # dims1.append(dim1)\n",
    "    # dims2.append(dim2)\n",
    "    euclids.append(euclid)\n",
    "ref= [math.pi/2]*30\n",
    "print(\"Total number reached = \" + str(num_reached))\n",
    "print(\"Total number violate = \" + str(number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "res_list.append(num_reached)\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(clean_obs_dist_list) / len(clean_obs_dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c7582f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print((obs_dists_list[0]))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(obs_dists_list[i]) / len(obs_dists_list[i]))\n",
    "    ave_dist.append(min(obs_dists_list[i]))\n",
    "    # print(obs_dists_list[i])\n",
    "    # plt.plot(np.arange(len(obs_dists_list[i])), obs_dists_list[i], color='red')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))   \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('distance to unsafe', fontsize = 15)\n",
    "plt.title('env being attacked')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(clean_obs_dists_list[i]) / len(clean_obs_dists_list[i]))\n",
    "    ave_dist.append(min(clean_obs_dists_list[i]))\n",
    "    # plt.plot(np.arange(len(clean_obs_dists_list[i])), clean_obs_dists_list[i], color='green')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))       \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "# plt.ylabel('obstacle distance')\n",
    "plt.title('clean env')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92d195ff-ca0f-477a-807f-f78f8b659cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with A2C ...\n"
     ]
    }
   ],
   "source": [
    "#  train surrogate policy\n",
    "reached = []\n",
    "env = bicycleEnv()\n",
    "# surro_model = A2C.load('A2C_bicycle.zip', env=env)\n",
    "for k in [30]:\n",
    "    \n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    surro_model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "    surro_model.learn(total_timesteps=1000000, progress_bar=False)\n",
    "    vec_env = surro_model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    center = [1,1,0,math.sqrt(2)]\n",
    "    obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = surro_model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40379497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[960]\n"
     ]
    }
   ],
   "source": [
    "# surro_model.save('PPO_bicycle.zip')\n",
    "# print(reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b478ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, root\n",
    "\n",
    "def grey_attack(env, state, model, surro_model, epsilon, policy, norm, args):\n",
    "    action = surro_model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    def f(x):\n",
    "    # Objective function\n",
    "        return 1\n",
    "    def fun(x):\n",
    "        return np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) \n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "    x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    non_linear_eq= lambda x: np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) -\\\n",
    "                            np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center)\n",
    "    non_linear_constr = NonlinearConstraint(non_linear_eq, - np.inf, 0.0 )\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "    result = minimize(fun, x_start, method='trust-constr', bounds=bounds)\n",
    "    # print(result.x)\n",
    "    op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = surro_model.policy(state, deterministic=True)[0].requires_grad_(True)\n",
    "#         print(action)\n",
    "#         action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        surro_model.policy.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 30 * state_grad.sign()\n",
    "        perturbed_state = torch.clamp(perturbed_state, min=torch.from_numpy(_state - 0.5), max=torch.from_numpy(_state + 0.5))\n",
    "\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = surro_model.policy(perturbed_state, deterministic=True)[0]\n",
    "#         low, high = -7, 7\n",
    "#         action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        action_next = scaled_action\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "#         print(action_next)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach()[0],))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist > env.safe_norm_radius and pertub_dist < obs_dist:\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c05d904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number reached = 34\n",
      "Total number violate = 0\n",
      "clean env for reference\n",
      "Total number reached = 91\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": [
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "surro_model = PPO.load('PPO_bicycle.zip', env=env)\n",
    "clean_env = bicycleEnv()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "obs_dists = []\n",
    "obs_dists_list = []\n",
    "dist_list = []\n",
    "center = [1,1,0,math.sqrt(2)]\n",
    "obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "num_reached = 0\n",
    "action_list = []\n",
    "pertub_action_list = [] \n",
    "number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "for j in range(100):\n",
    "    dim0 = []\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    euclid = []\n",
    "    state = env.reset()\n",
    "    _ = clean_env.reset()\n",
    "    clean_env.state = state\n",
    "    clean_state = state\n",
    "    # print(f'state:{state}, clean_state:{clean_state}')\n",
    "    # Print initial state\n",
    "    for i in range(env.step_const):\n",
    "      \n",
    "        # action = model.predict(state, deterministic=True)\n",
    "        # pertub_action = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        attack = grey_attack(env, state, model, surro_model, epsilon, policy, norm, args)\n",
    "        # print(attack)\n",
    "        pertub_state = state + attack\n",
    "        # print(pertub_state, state)\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        # print(pertub_action)\n",
    "        # new_state, reward, done, _ = env.step(pertub_action[0])\n",
    "        new_state, reward, done, _ = env.step(pertub_action)\n",
    "        state = new_state\n",
    "        # new_state, reward, done, _ = env.step(action[0])\n",
    "        \n",
    "        dist = np.linalg.norm(state - env.center)\n",
    "        obs_dist = np.linalg.norm(state - env.obstacle)\n",
    "        pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        obs_dists.append(obs_dist)\n",
    "        if obs_dist <= env.safe_norm_radius:\n",
    "            number_violate += 1\n",
    "            break\n",
    "        if dist <= env.target_norm_radius: # stop\n",
    "            num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    obs_dists_list.append(obs_dists)\n",
    "    obs_dists = []\n",
    "    \n",
    "    # print(env.final_reward_cache)\n",
    "    # print(\"dirty env\")\n",
    "    # print(obs_dist_list)\n",
    "    # print(dist_list)\n",
    "   \n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "    \n",
    "    # print(clean_env.final_reward_cache)\n",
    "    # print(\"clean env\")\n",
    "    # print(clean_obs_dist_list)\n",
    "    # print(clean_dist_list)\n",
    "   \n",
    "    # dims0.append(dim0)\n",
    "    # dims1.append(dim1)\n",
    "    # dims2.append(dim2)\n",
    "    euclids.append(euclid)\n",
    "ref= [math.pi/2]*30\n",
    "print(\"Total number reached = \" + str(num_reached))\n",
    "print(\"Total number violate = \" + str(number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "res_list.append(num_reached)\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e3574e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class adv_bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 20\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [1,1,0,math.sqrt(2)]\n",
    "        self.obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.8\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 20\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = np.linalg.norm(self.state - self.obstacle)\n",
    "#         reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        obs_reward = -obs_reward\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "#         self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "#         if self.steps < 10:\n",
    "#             reach_reward = max(self.reward_cache)\n",
    "#         else:\n",
    "#             reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "#         final_reward = min(reach_reward, avoid_reward)\n",
    "        final_reward =  avoid_reward\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 10\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or max(np.absolute(self.state))>20 or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f980b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with SAC ...\n"
     ]
    }
   ],
   "source": [
    "#  train adv policy\n",
    "reached = []\n",
    "env = adv_bicycleEnv()\n",
    "# adv_model = SAC.load('adv_SAC_bicycle.zip', env=env)\n",
    "for k in [30]:\n",
    "    \n",
    "    env.k = k\n",
    "    print('Start training with SAC ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    adv_model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    adv_model.learn(total_timesteps=300000, progress_bar=False)\n",
    "    vec_env = adv_model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "#     env = adv_bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "#     dims0 = []\n",
    "#     dims1 = []\n",
    "#     dims2 = []\n",
    "#     dims3 = []\n",
    "#     euclids = []\n",
    "    center = [1,1,0,math.sqrt(2)]\n",
    "    obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "#         dim0 = []\n",
    "#         dim1 = []\n",
    "#         dim2 = []\n",
    "#         dim3 = []\n",
    "#         euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = adv_model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "#             dim0.append(state[0])\n",
    "#             dim1.append(state[1])\n",
    "#             dim2.append(state[2])\n",
    "#             dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "#             euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "#             if dist <= env.target_norm_radius: # stop\n",
    "#                 num_reached += 1\n",
    "#                 break\n",
    "#         dims0.append(dim0)\n",
    "#         dims1.append(dim1)\n",
    "#         dims2.append(dim2)\n",
    "#         dims3.append(dim3)\n",
    "#         euclids.append(euclid)\n",
    "    reached.append(num_reached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65f012d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_model.save('adv_SAC_bicycle.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54f3924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885\n"
     ]
    }
   ],
   "source": [
    "print(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ac0ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def black_attack(env, state, model, surro_model,adv_model, epsilon, policy, norm, args):\n",
    "    action = surro_model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "#     x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    \n",
    "    # print(result.x)\n",
    "    op_action = adv_model.predict(state)[0]\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = surro_model.policy(state, deterministic=True)[0].requires_grad_(True)\n",
    "#         print(action)\n",
    "#         action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        surro_model.policy.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 30 * state_grad.sign()\n",
    "        perturbed_state = torch.clamp(perturbed_state, min=torch.from_numpy(_state - 0.5), max=torch.from_numpy(_state + 0.5))\n",
    "\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = surro_model.policy(perturbed_state, deterministic=True)[0]\n",
    "#         low, high = -7, 7\n",
    "#         action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        action_next = scaled_action\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "#         print(action_next)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach()[0],))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist > env.safe_norm_radius and pertub_dist < obs_dist:\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa9ea35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black env for reference\n",
      "Total number reached = 71\n",
      "Total number violate = 0\n",
      "grey env for reference\n",
      "Total number reached = 61\n",
      "Total number violate = 1\n",
      "white env for reference\n",
      "Total number reached = 24\n",
      "Total number violate = 0\n",
      "clean env for reference\n",
      "Total number reached = 92\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test white, grey, black box attack\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "adv_env = adv_bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "surro_model = PPO.load('PPO_bicycle.zip', env=env)\n",
    "adv_model = SAC.load('adv_SAC_bicycle.zip', env=adv_env)\n",
    "clean_env = bicycleEnv()\n",
    "black_env = bicycleEnv()\n",
    "white_env = bicycleEnv()\n",
    "grey_env = bicycleEnv()\n",
    "all_envs = [clean_env, white_env, grey_env, black_env]\n",
    "state = env.reset()\n",
    "\n",
    "# obs_dists = []\n",
    "# obs_dists_list = []\n",
    "# dist_list = []\n",
    "center = env.center\n",
    "obstacle =  env.obstacle\n",
    "# num_reached = 0\n",
    "# action_list = []\n",
    "# pertub_action_list = [] \n",
    "# number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "black_obs_dists = []\n",
    "black_obs_dists_list = []\n",
    "black_num_reached = 0\n",
    "black_number_violate = 0\n",
    "black_obs_dist_list = []\n",
    "black_dist_list = []\n",
    "grey_obs_dists = []\n",
    "grey_obs_dist_list = []\n",
    "grey_num_reached = 0\n",
    "grey_number_violate = 0\n",
    "grey_obs_dists_list = []\n",
    "grey_dist_list = []\n",
    "white_obs_dists = []\n",
    "white_obs_dists_list = []\n",
    "white_num_reached = 0\n",
    "white_number_violate = 0\n",
    "white_obs_dist_list = []\n",
    "white_dist_list = []\n",
    "\n",
    "\n",
    "for j in range(100):\n",
    "    _ = [env.reset() for env in all_envs]\n",
    "    for env in all_envs:\n",
    "        env.state = clean_env.state\n",
    "    \n",
    "# black-box\n",
    "    state = black_env.state\n",
    "    for i in range(env.step_const):\n",
    "        \n",
    "        attack = black_attack(black_env, state, model, surro_model,adv_model, epsilon, policy, norm, args)\n",
    "#         print(f'black_attack:{attack}')\n",
    "        pertub_state = state + attack\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        new_state, reward, done, _ = black_env.step(pertub_action)\n",
    "        state = new_state        \n",
    "        dist = np.linalg.norm(state - black_env.center)\n",
    "        obs_dist = np.linalg.norm(state - black_env.obstacle)\n",
    "#         pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        black_obs_dists.append(obs_dist)\n",
    "        if obs_dist <= black_env.safe_norm_radius:\n",
    "            black_number_violate += 1\n",
    "            break\n",
    "        if dist <= black_env.target_norm_radius: # stop\n",
    "            black_num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    black_obs_dists_list.append(black_obs_dists)\n",
    "    black_obs_dists = []\n",
    "    \n",
    "# grey-box\n",
    "    state = grey_env.state\n",
    "    for i in range(env.step_const):\n",
    "        \n",
    "        attack = grey_attack(grey_env, state, model, surro_model, epsilon, policy, norm, args)\n",
    "#         print(f'grey_attack:{attack}')\n",
    "        pertub_state = state + attack\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        new_state, reward, done, _ = grey_env.step(pertub_action)\n",
    "        state = new_state        \n",
    "        dist = np.linalg.norm(state - grey_env.center)\n",
    "        obs_dist = np.linalg.norm(state - grey_env.obstacle)\n",
    "        \n",
    "        grey_obs_dists.append(obs_dist)\n",
    "        if obs_dist <= grey_env.safe_norm_radius:\n",
    "            grey_number_violate += 1\n",
    "            break\n",
    "        if dist <= grey_env.target_norm_radius: # stop\n",
    "            grey_num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    grey_obs_dists_list.append(grey_obs_dists)\n",
    "    grey_obs_dists = []\n",
    "    \n",
    "    \n",
    "# white\n",
    "    state = white_env.state\n",
    "    for i in range(env.step_const):\n",
    "        \n",
    "        attack = safe_attack(white_env, state, model, epsilon, policy, norm, args)\n",
    "#         print(attack)\n",
    "        pertub_state = state + attack\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        new_state, reward, done, _ = white_env.step(pertub_action)\n",
    "        state = new_state        \n",
    "        dist = np.linalg.norm(state - white_env.center)\n",
    "        obs_dist = np.linalg.norm(state - white_env.obstacle)\n",
    "        \n",
    "        white_obs_dists.append(obs_dist)\n",
    "        if obs_dist <= white_env.safe_norm_radius:\n",
    "            white_number_violate += 1\n",
    "            break\n",
    "        if dist <= white_env.target_norm_radius: # stop\n",
    "            white_num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    white_obs_dists_list.append(white_obs_dists)\n",
    "    white_obs_dists = []\n",
    "\n",
    "#    clean env\n",
    "    clean_state = clean_env.state\n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "\n",
    "ref= [math.pi/2]*30\n",
    "print(\"black env for reference\")\n",
    "print(\"Total number reached = \" + str(black_num_reached))\n",
    "print(\"Total number violate = \" + str(black_number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "\n",
    "\n",
    "# print(\"average of obs dist= \" + str(sum(clean_obs_dist_list) / len(clean_obs_dist_list)))\n",
    "print(\"grey env for reference\")\n",
    "print(\"Total number reached = \" + str(grey_num_reached))\n",
    "print(\"Total number violate = \" + str(grey_number_violate))\n",
    "print(\"white env for reference\")\n",
    "print(\"Total number reached = \" + str(white_num_reached))\n",
    "print(\"Total number violate = \" + str(white_number_violate))\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ab2c172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x20980b722c0>,\n",
       "  <matplotlib.axis.XTick at 0x20980b70b20>,\n",
       "  <matplotlib.axis.XTick at 0x209d3250a00>,\n",
       "  <matplotlib.axis.XTick at 0x209d329de10>],\n",
       " [Text(1, 0, 'white'),\n",
       "  Text(2, 0, 'grey'),\n",
       "  Text(3, 0, 'black'),\n",
       "  Text(4, 0, 'clean')])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = ['white', 'grey', 'black', 'clean']\n",
    "black = []\n",
    "white = []\n",
    "grey = []\n",
    "clean = []\n",
    "for i in range(100):\n",
    "    black.append(sum(black_obs_dists_list[i]) / len(black_obs_dists_list[i]))\n",
    "    white.append(sum(white_obs_dists_list[i]) / len(white_obs_dists_list[i]))\n",
    "    grey.append(sum(grey_obs_dists_list[i]) / len(grey_obs_dists_list[i]))\n",
    "    clean.append(sum(clean_obs_dists_list[i]) / len(clean_obs_dists_list[i]))\n",
    "#     black.append(min(black_obs_dists_list[i]) )\n",
    "#     white.append(min(white_obs_dists_list[i]))\n",
    "#     grey.append(min(grey_obs_dists_list[i]))\n",
    "#     clean.append(min(clean_obs_dists_list[i]))\n",
    "data = [white, grey, black, clean]\n",
    "ax = plt.boxplot(data)    \n",
    "plt.ylim((-1, 8))   \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Attacker knowledge')\n",
    "plt.ylabel('Average distance to unsafe', fontsize = 15)\n",
    "# plt.title('Average distance to unsafe')\n",
    "plt.xticks([1, 2, 3, 4], label)\n",
    "# plt.legend([ax[\"boxes\"][0], ax[\"boxes\"][1]], ['white', 'grey'], loc='upper right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae105e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
