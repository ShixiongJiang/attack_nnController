{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4c660d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T02:01:45.848969200Z",
     "start_time": "2023-10-12T02:01:45.537417Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import cos, sin\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "from typing import Optional\n",
    "from control.matlab import ss, lsim, linspace, c2d\n",
    "from functools import partial\n",
    "# from state_estimation import Estimator\n",
    "import math\n",
    "import gym\n",
    "from stable_baselines3 import PPO, SAC, TD3, DDPG, DQN, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e0c283b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T02:01:48.015216500Z",
     "start_time": "2023-10-12T02:01:48.003218600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53dbe14d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:25:16.850550400Z",
     "start_time": "2023-10-12T04:25:16.827550800Z"
    }
   },
   "outputs": [],
   "source": [
    "# define CSTR model\n",
    "def bicycle(x,t,u, params={}):\n",
    "    lr = 1.105\n",
    "    lf = 1.738\n",
    "    psi = x[2]\n",
    "    v = x[3]\n",
    "    alpha = u[0]\n",
    "    sigma = u[1]\n",
    "    xdot =np.zeros(4)\n",
    "    beta = math.atan((lr/(lr+lf)*math.tan(sigma)))\n",
    "    xdot[0] = v*math.cos(psi+beta)\n",
    "    xdot[1] = v*math.sin(psi+beta)\n",
    "    xdot[2] = v/lr*math.sin(beta)\n",
    "    xdot[3] = alpha\n",
    "    return xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fe861ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:26:09.941032800Z",
     "start_time": "2023-10-12T04:26:09.924523200Z"
    }
   },
   "outputs": [],
   "source": [
    "class bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 20\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [2,2,0,2 * math.sqrt(2)]\n",
    "        self.obstacle =  np.array(([0.5,0.5,0,math.sqrt(2)/2], [1,1,0,math.sqrt(2)]))\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.8\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 20\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = min( np.linalg.norm(self.state - self.obstacle[0]), np.linalg.norm(self.state - self.obstacle[1]))\n",
    "        reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "        self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "        if self.steps < 10:\n",
    "            reach_reward = max(self.reward_cache)\n",
    "        else:\n",
    "            reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "        final_reward = min(reach_reward, avoid_reward)\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 10\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or max(np.absolute(self.state))>20 or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c0b6ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T05:57:28.653377700Z",
     "start_time": "2023-10-12T04:26:13.486856400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "reached = []\n",
    "for k in [20]:\n",
    "    env = bicycleEnv()\n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    model.learn(total_timesteps=300000, progress_bar=False)\n",
    "    vec_env = model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    # center = [1,1,0,math.sqrt(2)]\n",
    "    # obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-env.center)\n",
    "            obs_dist = min( np.linalg.norm(env.state - env.obstacle[0]), np.linalg.norm(env.state - env.obstacle[1]))\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea6ed894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T05:57:28.668382700Z",
     "start_time": "2023-10-12T05:57:28.655377400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[997]\n"
     ]
    }
   ],
   "source": [
    "print(reached)\n",
    "model.save(\"SAC_bicycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82553493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"SAC_bicycle.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87d6e06d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T02:02:33.029382700Z",
     "start_time": "2023-10-12T02:02:32.877866900Z"
    }
   },
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, root\n",
    "def fgsm_attack(state, model, epsilon, policy, norm, args):\n",
    "    state = torch.from_numpy(state)\n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    action = model.actor(state)\n",
    "    # target = torch.argmax(q_vals).unsqueeze(0)\n",
    "    # preds = torch.softmax(q_vals, 1)\n",
    "    # The loss is calcualted with cross entropy\n",
    "    # current_q = self.critic(state, action)\n",
    "    # cri = model.critic(state)\n",
    "    q_vals = (model.critic(state, action))\n",
    "    loss = (q_vals[0] + q_vals[1]) / 2 * (-1)\n",
    "    # print(target)\n",
    "    # loss_func = torch.nn.CrossEntropyLoss()\n",
    "    # loss = loss_func(preds, target)\n",
    "    model.actor.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "   \n",
    "    state_grad = state.grad.detach().squeeze()\n",
    "    \n",
    "    state = state.squeeze()\n",
    "    # Perturb only agent position and ball position\n",
    "    if norm == float('inf'):\n",
    "        perturbed_state = state + epsilon * state_grad.sign()\n",
    "    elif norm == 2:\n",
    "        perturbed_state = state + epsilon * state_grad / torch.norm(state_grad, norm)\n",
    "    elif norm == 1:\n",
    "        index = torch.argmax(state_grad)\n",
    "        per = torch.zeros_like(state_grad)\n",
    "        per[index] = 1\n",
    "        perturbed_state = state + epsilon * per\n",
    "    return perturbed_state.detach().cpu().numpy()\n",
    "\n",
    "def safe_attack(env, state, model, epsilon, policy, norm, args):\n",
    "    action = model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    def fun(x):\n",
    "        return np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) \n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "    x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    non_linear_eq= lambda x: np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) -\\\n",
    "                            np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center)\n",
    "    non_linear_constr = NonlinearConstraint(non_linear_eq, - np.inf, 0.0 )\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "    result = minimize(fun, x_start, method='trust-constr', bounds=bounds)\n",
    "    # print(result.x)\n",
    "    op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = model.actor(state, deterministic=True)[0].requires_grad_(True)\n",
    "        action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        model.actor.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 30 * state_grad.sign()\n",
    "        perturbed_state = torch.clamp(perturbed_state, min=torch.from_numpy(_state - 0.5), max=torch.from_numpy(_state + 0.5))\n",
    "\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = model.actor(perturbed_state, deterministic=True)[0]\n",
    "        low, high = -7, 7\n",
    "        action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "#         print(action_next)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach(),))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist > env.safe_norm_radius and pertub_dist < obs_dist:\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc3f27e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T02:09:29.027665600Z",
     "start_time": "2023-10-12T02:03:32.284871200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjiang5\\anaconda3\\envs\\example\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjiang5\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\sjiang5\\AppData\\Local\\Temp\\ipykernel_47052\\2639682732.py:82: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  loss = pdist(torch.tensor([op_action]), action)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number reached = 26\n",
      "Total number violate = 0\n",
      "clean env for reference\n",
      "Total number reached = 91\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": [
    "# Test 50 traces for safe attack\n",
    "\n",
    "# norm = 2\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "clean_env = bicycleEnv()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "obs_dists = []\n",
    "obs_dists_list = []\n",
    "dist_list = []\n",
    "center = [1,1,0,math.sqrt(2)]\n",
    "obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "num_reached = 0\n",
    "action_list = []\n",
    "pertub_action_list = [] \n",
    "number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "for j in range(100):\n",
    "    dim0 = []\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    euclid = []\n",
    "    state = env.reset()\n",
    "    _ = clean_env.reset()\n",
    "    clean_env.state = state\n",
    "    clean_state = state\n",
    "    # print(f'state:{state}, clean_state:{clean_state}')\n",
    "    # Print initial state\n",
    "    for i in range(env.step_const):\n",
    "      \n",
    "        # action = model.predict(state, deterministic=True)\n",
    "        # pertub_action = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        attack = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        # print(attack)\n",
    "        pertub_state = state + attack\n",
    "        # print(pertub_state, state)\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        # print(pertub_action)\n",
    "        # new_state, reward, done, _ = env.step(pertub_action[0])\n",
    "        new_state, reward, done, _ = env.step(pertub_action)\n",
    "        state = new_state\n",
    "        # new_state, reward, done, _ = env.step(action[0])\n",
    "        \n",
    "        dist = np.linalg.norm(state - env.center)\n",
    "        obs_dist = np.linalg.norm(state - env.obstacle)\n",
    "        pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        obs_dists.append(obs_dist)\n",
    "        if obs_dist <= env.safe_norm_radius:\n",
    "            number_violate += 1\n",
    "            break\n",
    "        if dist <= env.target_norm_radius: # stop\n",
    "            num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    obs_dists_list.append(obs_dists)\n",
    "    obs_dists = []\n",
    "    \n",
    "    # print(env.final_reward_cache)\n",
    "    # print(\"dirty env\")\n",
    "    # print(obs_dist_list)\n",
    "    # print(dist_list)\n",
    "   \n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "    \n",
    "    # print(clean_env.final_reward_cache)\n",
    "    # print(\"clean env\")\n",
    "    # print(clean_obs_dist_list)\n",
    "    # print(clean_dist_list)\n",
    "   \n",
    "    # dims0.append(dim0)\n",
    "    # dims1.append(dim1)\n",
    "    # dims2.append(dim2)\n",
    "    euclids.append(euclid)\n",
    "ref= [math.pi/2]*30\n",
    "print(\"Total number reached = \" + str(num_reached))\n",
    "print(\"Total number violate = \" + str(number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "res_list.append(num_reached)\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(clean_obs_dist_list) / len(clean_obs_dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c7582f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print((obs_dists_list[0]))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(obs_dists_list[i]) / len(obs_dists_list[i]))\n",
    "    ave_dist.append(min(obs_dists_list[i]))\n",
    "    # print(obs_dists_list[i])\n",
    "    # plt.plot(np.arange(len(obs_dists_list[i])), obs_dists_list[i], color='red')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))   \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('distance to unsafe', fontsize = 15)\n",
    "plt.title('env being attacked')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(clean_obs_dists_list[i]) / len(clean_obs_dists_list[i]))\n",
    "    ave_dist.append(min(clean_obs_dists_list[i]))\n",
    "    # plt.plot(np.arange(len(clean_obs_dists_list[i])), clean_obs_dists_list[i], color='green')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))       \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "# plt.ylabel('obstacle distance')\n",
    "plt.title('clean env')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d195ff-ca0f-477a-807f-f78f8b659cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T03:08:56.275020500Z",
     "start_time": "2023-10-12T02:11:31.546192600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    }
   ],
   "source": [
    "#  train surrogate policy\n",
    "reached = []\n",
    "env = bicycleEnv()\n",
    "# surro_model = A2C.load('A2C_bicycle.zip', env=env)\n",
    "for k in [30]:\n",
    "    \n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    surro_model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "    surro_model.learn(total_timesteps=1000000, progress_bar=False)\n",
    "    vec_env = surro_model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    center = [1,1,0,math.sqrt(2)]\n",
    "    obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = surro_model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40379497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T03:08:56.314535400Z",
     "start_time": "2023-10-12T03:08:56.281021300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[963]\n"
     ]
    }
   ],
   "source": [
    "# surro_model.save('PPO_bicycle.zip')\n",
    "# print(reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b478ae77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:12:57.708067300Z",
     "start_time": "2023-10-12T04:12:57.691066400Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, root\n",
    "\n",
    "def grey_attack(env, state, model, surro_model, epsilon, policy, norm, args):\n",
    "    action = surro_model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    def f(x):\n",
    "    # Objective function\n",
    "        return 1\n",
    "    def fun(x):\n",
    "        return np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle) \n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "    x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    non_linear_eq= lambda x: np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) -\\\n",
    "                            np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center)\n",
    "    non_linear_constr = NonlinearConstraint(non_linear_eq, - np.inf, 0.0 )\n",
    "#     result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\n",
    "    result = minimize(fun, x_start, method='trust-constr', bounds=bounds)\n",
    "    # print(result.x)\n",
    "    op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = surro_model.policy(state, deterministic=True)[0].requires_grad_(True)\n",
    "#         print(action)\n",
    "#         action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        surro_model.policy.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 30 * state_grad.sign()\n",
    "        perturbed_state = torch.clamp(perturbed_state, min=torch.from_numpy(_state - 0.5), max=torch.from_numpy(_state + 0.5))\n",
    "\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = surro_model.policy(perturbed_state, deterministic=True)[0]\n",
    "#         low, high = -7, 7\n",
    "#         action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        action_next = scaled_action\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "#         print(action_next)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach()[0],))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist > env.safe_norm_radius and pertub_dist < obs_dist:\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c05d904b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:20:05.731866100Z",
     "start_time": "2023-10-12T04:13:00.521270100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number reached = 14\n",
      "Total number violate = 1\n",
      "clean env for reference\n",
      "Total number reached = 89\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": [
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "surro_model = PPO.load('PPO_bicycle.zip', env=env)\n",
    "clean_env = bicycleEnv()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "obs_dists = []\n",
    "obs_dists_list = []\n",
    "dist_list = []\n",
    "center = [1,1,0,math.sqrt(2)]\n",
    "obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "num_reached = 0\n",
    "action_list = []\n",
    "pertub_action_list = [] \n",
    "number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "for j in range(100):\n",
    "    dim0 = []\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    euclid = []\n",
    "    state = env.reset()\n",
    "    _ = clean_env.reset()\n",
    "    clean_env.state = state\n",
    "    clean_state = state\n",
    "    # print(f'state:{state}, clean_state:{clean_state}')\n",
    "    # Print initial state\n",
    "    for i in range(env.step_const):\n",
    "      \n",
    "        # action = model.predict(state, deterministic=True)\n",
    "        # pertub_action = safe_attack(env, state, model, epsilon, policy, norm, args)\n",
    "        attack = grey_attack(env, state, model, surro_model, epsilon, policy, norm, args)\n",
    "        # print(attack)\n",
    "        pertub_state = state + attack\n",
    "        # print(pertub_state, state)\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        # print(pertub_action)\n",
    "        # new_state, reward, done, _ = env.step(pertub_action[0])\n",
    "        new_state, reward, done, _ = env.step(pertub_action)\n",
    "        state = new_state\n",
    "        # new_state, reward, done, _ = env.step(action[0])\n",
    "        \n",
    "        dist = np.linalg.norm(state - env.center)\n",
    "        obs_dist = np.linalg.norm(state - env.obstacle)\n",
    "        pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        obs_dists.append(obs_dist)\n",
    "        if obs_dist <= env.safe_norm_radius:\n",
    "            number_violate += 1\n",
    "            break\n",
    "        if dist <= env.target_norm_radius: # stop\n",
    "            num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    obs_dists_list.append(obs_dists)\n",
    "    obs_dists = []\n",
    "    \n",
    "    # print(env.final_reward_cache)\n",
    "    # print(\"dirty env\")\n",
    "    # print(obs_dist_list)\n",
    "    # print(dist_list)\n",
    "   \n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "    \n",
    "    # print(clean_env.final_reward_cache)\n",
    "    # print(\"clean env\")\n",
    "    # print(clean_obs_dist_list)\n",
    "    # print(clean_dist_list)\n",
    "   \n",
    "    # dims0.append(dim0)\n",
    "    # dims1.append(dim1)\n",
    "    # dims2.append(dim2)\n",
    "    euclids.append(euclid)\n",
    "ref= [math.pi/2]*30\n",
    "print(\"Total number reached = \" + str(num_reached))\n",
    "print(\"Total number violate = \" + str(number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "res_list.append(num_reached)\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e3574e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:20:05.762373100Z",
     "start_time": "2023-10-12T04:20:05.734865600Z"
    }
   },
   "outputs": [],
   "source": [
    "class adv_bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 20\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [1,1,0,math.sqrt(2)]\n",
    "        self.obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.8\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 20\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = np.linalg.norm(self.state - self.obstacle)\n",
    "#         reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        obs_reward = -obs_reward\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "#         self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "#         if self.steps < 10:\n",
    "#             reach_reward = max(self.reward_cache)\n",
    "#         else:\n",
    "#             reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "#         final_reward = min(reach_reward, avoid_reward)\n",
    "        final_reward =  avoid_reward\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 10\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or max(np.absolute(self.state))>20 or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f980b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with SAC ...\n"
     ]
    }
   ],
   "source": [
    "#  train adv policy\n",
    "reached = []\n",
    "env = adv_bicycleEnv()\n",
    "# adv_model = SAC.load('adv_SAC_bicycle.zip', env=env)\n",
    "for k in [30]:\n",
    "    \n",
    "    env.k = k\n",
    "    print('Start training with SAC ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    adv_model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    adv_model.learn(total_timesteps=300000, progress_bar=False)\n",
    "    vec_env = adv_model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "#     env = adv_bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "#     dims0 = []\n",
    "#     dims1 = []\n",
    "#     dims2 = []\n",
    "#     dims3 = []\n",
    "#     euclids = []\n",
    "    center = [1,1,0,math.sqrt(2)]\n",
    "    obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "#         dim0 = []\n",
    "#         dim1 = []\n",
    "#         dim2 = []\n",
    "#         dim3 = []\n",
    "#         euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(30):\n",
    "            action, _states = adv_model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "#             dim0.append(state[0])\n",
    "#             dim1.append(state[1])\n",
    "#             dim2.append(state[2])\n",
    "#             dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "#             euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "#             if dist <= env.target_norm_radius: # stop\n",
    "#                 num_reached += 1\n",
    "#                 break\n",
    "#         dims0.append(dim0)\n",
    "#         dims1.append(dim1)\n",
    "#         dims2.append(dim2)\n",
    "#         dims3.append(dim3)\n",
    "#         euclids.append(euclid)\n",
    "    reached.append(num_reached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65f012d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_model.save('adv_SAC_bicycle.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54f3924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885\n"
     ]
    }
   ],
   "source": [
    "print(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ac0ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def black_attack(env, state, model, surro_model,adv_model, epsilon, policy, norm, args):\n",
    "    action = surro_model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "#     x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "    \n",
    "    # print(result.x)\n",
    "    op_action = adv_model.predict(state)[0]\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    # print(model.predict(state, deterministic=True)[0])\n",
    "    next_origin_obs_dist =  np.linalg.norm(odeint(bicycle, _state, ts, args=(_action,))[-1] - env.obstacle)\n",
    "#     effect = next_origin_obs_dist\n",
    "    effect = np.linalg.norm(_state - env.obstacle)\n",
    "    for i in range(100):\n",
    "     \n",
    "        action = surro_model.policy(state, deterministic=True)[0].requires_grad_(True)\n",
    "#         print(action)\n",
    "#         action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        pdist = torch.nn.PairwiseDistance(p=2)\n",
    "        loss = pdist(torch.tensor([op_action]), action)\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        surro_model.policy.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "       \n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - epsilon / 30 * state_grad.sign()\n",
    "        perturbed_state = torch.clamp(perturbed_state, min=torch.from_numpy(_state - 0.5), max=torch.from_numpy(_state + 0.5))\n",
    "\n",
    "        # print(state_grad)\n",
    "        # project!\n",
    "        # print(perturbed_state[0])\n",
    "        # torch.clamp(perturbed_state, min=(state - epsilon), max=(state + epsilon))\n",
    "        # print(perturbed_state[0])\n",
    "        \n",
    "        scaled_action = surro_model.policy(perturbed_state, deterministic=True)[0]\n",
    "#         low, high = -7, 7\n",
    "#         action_next = (low + (0.5 * (scaled_action + 1.0) * (high - low)))\n",
    "        action_next = scaled_action\n",
    "        # print(action_next.detach().numpy()\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "    # print(f'action:{_action}, action_pertubed:{action_next}, op_action:{op_action}')\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        obs_dist = np.linalg.norm(_state - env.obstacle)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        pertub_obs_dist = np.linalg.norm(state.detach().numpy() - env.obstacle)\n",
    "#         print(action_next)\n",
    "        next_obs_dist =  np.linalg.norm(odeint(bicycle, state.detach()[0], ts, args=(action_next.detach()[0],))[-1] - env.obstacle)\n",
    "        if pertub_obs_dist > env.safe_norm_radius and pertub_dist < obs_dist:\n",
    "            \n",
    "            if next_obs_dist < effect:\n",
    "                effect = next_obs_dist\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa9ea35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjian\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black env for reference\n",
      "Total number reached = 71\n",
      "Total number violate = 0\n",
      "grey env for reference\n",
      "Total number reached = 61\n",
      "Total number violate = 1\n",
      "white env for reference\n",
      "Total number reached = 24\n",
      "Total number violate = 0\n",
      "clean env for reference\n",
      "Total number reached = 92\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test white, grey, black box attack\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 2\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "adv_env = adv_bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "surro_model = PPO.load('PPO_bicycle.zip', env=env)\n",
    "adv_model = SAC.load('adv_SAC_bicycle.zip', env=adv_env)\n",
    "clean_env = bicycleEnv()\n",
    "black_env = bicycleEnv()\n",
    "white_env = bicycleEnv()\n",
    "grey_env = bicycleEnv()\n",
    "all_envs = [clean_env, white_env, grey_env, black_env]\n",
    "state = env.reset()\n",
    "\n",
    "# obs_dists = []\n",
    "# obs_dists_list = []\n",
    "# dist_list = []\n",
    "center = env.center\n",
    "obstacle =  env.obstacle\n",
    "# num_reached = 0\n",
    "# action_list = []\n",
    "# pertub_action_list = [] \n",
    "# number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "black_obs_dists = []\n",
    "black_obs_dists_list = []\n",
    "black_num_reached = 0\n",
    "black_number_violate = 0\n",
    "black_obs_dist_list = []\n",
    "black_dist_list = []\n",
    "grey_obs_dists = []\n",
    "grey_obs_dist_list = []\n",
    "grey_num_reached = 0\n",
    "grey_number_violate = 0\n",
    "grey_obs_dists_list = []\n",
    "grey_dist_list = []\n",
    "white_obs_dists = []\n",
    "white_obs_dists_list = []\n",
    "white_num_reached = 0\n",
    "white_number_violate = 0\n",
    "white_obs_dist_list = []\n",
    "white_dist_list = []\n",
    "\n",
    "\n",
    "for j in range(100):\n",
    "    _ = [env.reset() for env in all_envs]\n",
    "    for env in all_envs:\n",
    "        env.state = clean_env.state\n",
    "    \n",
    "# black-box\n",
    "    state = black_env.state\n",
    "    for i in range(env.step_const):\n",
    "        \n",
    "        attack = black_attack(black_env, state, model, surro_model,adv_model, epsilon, policy, norm, args)\n",
    "#         print(f'black_attack:{attack}')\n",
    "        pertub_state = state + attack\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        new_state, reward, done, _ = black_env.step(pertub_action)\n",
    "        state = new_state        \n",
    "        dist = np.linalg.norm(state - black_env.center)\n",
    "        obs_dist = np.linalg.norm(state - black_env.obstacle)\n",
    "#         pertub_action_list.append(pertub_action[0])\n",
    "        # action_list.append(action)\n",
    "        \n",
    "        black_obs_dists.append(obs_dist)\n",
    "        if obs_dist <= black_env.safe_norm_radius:\n",
    "            black_number_violate += 1\n",
    "            break\n",
    "        if dist <= black_env.target_norm_radius: # stop\n",
    "            black_num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    black_obs_dists_list.append(black_obs_dists)\n",
    "    black_obs_dists = []\n",
    "    \n",
    "# grey-box\n",
    "    state = grey_env.state\n",
    "    for i in range(env.step_const):\n",
    "        \n",
    "        attack = grey_attack(grey_env, state, model, surro_model, epsilon, policy, norm, args)\n",
    "#         print(f'grey_attack:{attack}')\n",
    "        pertub_state = state + attack\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        new_state, reward, done, _ = grey_env.step(pertub_action)\n",
    "        state = new_state        \n",
    "        dist = np.linalg.norm(state - grey_env.center)\n",
    "        obs_dist = np.linalg.norm(state - grey_env.obstacle)\n",
    "        \n",
    "        grey_obs_dists.append(obs_dist)\n",
    "        if obs_dist <= grey_env.safe_norm_radius:\n",
    "            grey_number_violate += 1\n",
    "            break\n",
    "        if dist <= grey_env.target_norm_radius: # stop\n",
    "            grey_num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    grey_obs_dists_list.append(grey_obs_dists)\n",
    "    grey_obs_dists = []\n",
    "    \n",
    "    \n",
    "# white\n",
    "    state = white_env.state\n",
    "    for i in range(env.step_const):\n",
    "        \n",
    "        attack = safe_attack(white_env, state, model, epsilon, policy, norm, args)\n",
    "#         print(attack)\n",
    "        pertub_state = state + attack\n",
    "        pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "        new_state, reward, done, _ = white_env.step(pertub_action)\n",
    "        state = new_state        \n",
    "        dist = np.linalg.norm(state - white_env.center)\n",
    "        obs_dist = np.linalg.norm(state - white_env.obstacle)\n",
    "        \n",
    "        white_obs_dists.append(obs_dist)\n",
    "        if obs_dist <= white_env.safe_norm_radius:\n",
    "            white_number_violate += 1\n",
    "            break\n",
    "        if dist <= white_env.target_norm_radius: # stop\n",
    "            white_num_reached += 1\n",
    "            break\n",
    "        \n",
    "    # print(obs_dists)\n",
    "    # print('++++++++++++++++')\n",
    "    white_obs_dists_list.append(white_obs_dists)\n",
    "    white_obs_dists = []\n",
    "\n",
    "#    clean env\n",
    "    clean_state = clean_env.state\n",
    "    for i in range(env.step_const):\n",
    "        clean_action = model.predict(clean_state, deterministic=True)\n",
    "        clean_new_state, reward, done, _ = clean_env.step(clean_action[0])\n",
    "        clean_state = clean_new_state\n",
    "        clean_dist = np.linalg.norm(clean_state - clean_env.center)\n",
    "        clean_obs_dist = np.linalg.norm(clean_state - clean_env.obstacle)\n",
    "        # euclid.append(dist)\n",
    "        \n",
    "        # clean_obs_dist_list.append(clean_obs_dist)\n",
    "        clean_dist_list.append(clean_dist)\n",
    "        clean_obs_dists.append(clean_obs_dist)\n",
    "        if clean_obs_dist <= env.safe_norm_radius:\n",
    "            clean_number_violate += 1\n",
    "            break\n",
    "        if clean_dist <=  env.target_norm_radius: # stop\n",
    "            clean_num_reached += 1\n",
    "            break\n",
    "    # print(clean_obs_dists)\n",
    "    # print('-------------------')\n",
    "    clean_obs_dists_list.append(clean_obs_dists)\n",
    "    clean_obs_dists = []\n",
    "\n",
    "ref= [math.pi/2]*30\n",
    "print(\"black env for reference\")\n",
    "print(\"Total number reached = \" + str(black_num_reached))\n",
    "print(\"Total number violate = \" + str(black_number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "\n",
    "\n",
    "# print(\"average of obs dist= \" + str(sum(clean_obs_dist_list) / len(clean_obs_dist_list)))\n",
    "print(\"grey env for reference\")\n",
    "print(\"Total number reached = \" + str(grey_num_reached))\n",
    "print(\"Total number violate = \" + str(grey_number_violate))\n",
    "print(\"white env for reference\")\n",
    "print(\"Total number reached = \" + str(white_num_reached))\n",
    "print(\"Total number violate = \" + str(white_number_violate))\n",
    "print(\"clean env for reference\")\n",
    "print(\"Total number reached = \" + str(clean_num_reached))\n",
    "print(\"Total number violate = \" + str(clean_number_violate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ab2c172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x20980b722c0>,\n",
       "  <matplotlib.axis.XTick at 0x20980b70b20>,\n",
       "  <matplotlib.axis.XTick at 0x209d3250a00>,\n",
       "  <matplotlib.axis.XTick at 0x209d329de10>],\n",
       " [Text(1, 0, 'white'),\n",
       "  Text(2, 0, 'grey'),\n",
       "  Text(3, 0, 'black'),\n",
       "  Text(4, 0, 'clean')])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = ['white', 'grey', 'black', 'clean']\n",
    "black = []\n",
    "white = []\n",
    "grey = []\n",
    "clean = []\n",
    "for i in range(100):\n",
    "    black.append(sum(black_obs_dists_list[i]) / len(black_obs_dists_list[i]))\n",
    "    white.append(sum(white_obs_dists_list[i]) / len(white_obs_dists_list[i]))\n",
    "    grey.append(sum(grey_obs_dists_list[i]) / len(grey_obs_dists_list[i]))\n",
    "    clean.append(sum(clean_obs_dists_list[i]) / len(clean_obs_dists_list[i]))\n",
    "#     black.append(min(black_obs_dists_list[i]) )\n",
    "#     white.append(min(white_obs_dists_list[i]))\n",
    "#     grey.append(min(grey_obs_dists_list[i]))\n",
    "#     clean.append(min(clean_obs_dists_list[i]))\n",
    "data = [white, grey, black, clean]\n",
    "ax = plt.boxplot(data)    \n",
    "plt.ylim((-1, 8))   \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Attacker knowledge')\n",
    "plt.ylabel('Average distance to unsafe', fontsize = 15)\n",
    "# plt.title('Average distance to unsafe')\n",
    "plt.xticks([1, 2, 3, 4], label)\n",
    "# plt.legend([ax[\"boxes\"][0], ax[\"boxes\"][1]], ['white', 'grey'], loc='upper right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae105e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
