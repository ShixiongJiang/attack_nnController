{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4c660d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T20:33:16.087698100Z",
     "start_time": "2023-10-30T20:33:13.987553300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import cos, sin\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "from typing import Optional\n",
    "from control.matlab import ss, lsim, linspace, c2d\n",
    "from functools import partial\n",
    "# from state_estimation import Estimator\n",
    "import math\n",
    "import gym\n",
    "from stable_baselines3 import PPO, SAC, TD3, DDPG, DQN, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0c283b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T20:33:11.200489200Z",
     "start_time": "2023-10-30T20:33:11.180501500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53dbe14d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T20:33:17.567421Z",
     "start_time": "2023-10-30T20:33:17.556417900Z"
    }
   },
   "outputs": [],
   "source": [
    "# define CSTR model\n",
    "def bicycle(x,t,u, params={}):\n",
    "    lr = 1.105\n",
    "    lf = 1.738\n",
    "    psi = x[2]\n",
    "    v = x[3]\n",
    "    alpha = u[0]\n",
    "    sigma = u[1]\n",
    "    xdot =np.zeros(4)\n",
    "    beta = math.atan((lr/(lr+lf)*math.tan(sigma)))\n",
    "    xdot[0] = v*math.cos(psi+beta)\n",
    "    xdot[1] = v*math.sin(psi+beta)\n",
    "    xdot[2] = v/lr*math.sin(beta)\n",
    "    xdot[3] = alpha\n",
    "    return xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fe861ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T20:24:39.606005600Z",
     "start_time": "2023-10-31T20:24:39.594887400Z"
    }
   },
   "outputs": [],
   "source": [
    "class bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 50\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [2,2,0,2 * math.sqrt(2)]\n",
    "        # self.obstacle =  np.array(([0.5,0.5,0,math.sqrt(2)/2], [1,1,0,math.sqrt(2)/2]))\n",
    "        self.obstacle =  np.array(([-0.88615284, -1.00078591, -1.5150387, 2.41190424], [-1.06931684,  0.66430412, -2.53652435,4.46120764]))\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.6\n",
    "        self.safe_norm_radius = 0.6\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 30\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = min( np.linalg.norm(self.state - self.obstacle[0]), np.linalg.norm(self.state - self.obstacle[1]))\n",
    "        reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "        self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "        if self.steps < 10:\n",
    "            reach_reward = max(self.reward_cache)\n",
    "        else:\n",
    "            reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "        final_reward = min(reach_reward, avoid_reward)\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 100\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or obs_dist<=self.safe_norm_radius:\n",
    "            final_reward = -10\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            # self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-2.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98c0b6ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T19:09:41.032698Z",
     "start_time": "2023-10-31T18:25:24.749905500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "reached = []\n",
    "for k in [20]:\n",
    "    env = bicycleEnv()\n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    # model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "    model.learn(total_timesteps=100000, progress_bar=False)\n",
    "    vec_env = model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    # center = [1,1,0,math.sqrt(2)]\n",
    "    # obstacle = [0.5,0.5,0,math.sqrt(2)/2]\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(2 * env.step_const):\n",
    "            action, _states = model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-env.center)\n",
    "            obs_dist = min( np.linalg.norm(env.state - env.obstacle[0]), np.linalg.norm(env.state - env.obstacle[1]))\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "            if done:\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea6ed894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T19:09:41.061463300Z",
     "start_time": "2023-10-31T19:09:41.040252700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n"
     ]
    }
   ],
   "source": [
    "print(num_reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82553493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T19:09:41.128713500Z",
     "start_time": "2023-10-31T19:09:41.057954Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"SAC_bicycle.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87d6e06d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T15:28:56.091761300Z",
     "start_time": "2023-10-31T15:28:54.917413Z"
    }
   },
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, root\n",
    "def fgsm_attack(state, model, epsilon, policy, norm, args):\n",
    "    state = torch.from_numpy(state)\n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    action = model.actor(state)\n",
    "    # target = torch.argmax(q_vals).unsqueeze(0)\n",
    "    # preds = torch.softmax(q_vals, 1)\n",
    "    # The loss is calcualted with cross entropy\n",
    "    # current_q = self.critic(state, action)\n",
    "    # cri = model.critic(state)\n",
    "    q_vals = (model.critic(state, action))\n",
    "    loss = (q_vals[0] + q_vals[1]) / 2 * (-1)\n",
    "    # print(target)\n",
    "    # loss_func = torch.nn.CrossEntropyLoss()\n",
    "    # loss = loss_func(preds, target)\n",
    "    model.actor.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "   \n",
    "    state_grad = state.grad.detach().squeeze()\n",
    "    \n",
    "    state = state.squeeze()\n",
    "    # Perturb only agent position and ball position\n",
    "    if norm == float('inf'):\n",
    "        perturbed_state = state + epsilon * state_grad.sign()\n",
    "    elif norm == 2:\n",
    "        perturbed_state = state + epsilon * state_grad / torch.norm(state_grad, norm)\n",
    "    elif norm == 1:\n",
    "        index = torch.argmax(state_grad)\n",
    "        per = torch.zeros_like(state_grad)\n",
    "        per[index] = 1\n",
    "        perturbed_state = state + epsilon * per\n",
    "    return perturbed_state.detach().cpu().numpy()\n",
    "\n",
    "def white_attack(env, state, model, surro_model, adv_model, epsilon):\n",
    "    action = model.predict(state, deterministic=True)[0]\n",
    "    # print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    state_range =  np.array([epsilon])\n",
    "\n",
    "    def fun(x):\n",
    "        return min(np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle[0]),np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.obstacle[1]) )\n",
    "    \n",
    "    x_start = np.array(action)\n",
    "    lim = [-7, 7]\n",
    "\n",
    "    bounds = Bounds([lim[0], lim[0]], [lim[1], lim[1]])  \n",
    "\n",
    "    ts = [env.horizon[env.steps], env.horizon[env.steps+1] ]\n",
    "    x_state = odeint(bicycle, state, ts, args=(action,))[-1]\n",
    "\n",
    "    result = minimize(fun, x_start, method='trust-constr', bounds=bounds)\n",
    "    # print(result.x)\n",
    "    op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "    \n",
    "    effect = 1000\n",
    "    for i in range(40):\n",
    "\n",
    "        action = model.policy._predict(state, deterministic=True)[0].requires_grad_(True)\n",
    "        action = action * 7\n",
    "        action = action.double()\n",
    "#         mse = nn.MSELoss()\n",
    "        \n",
    "        # compute the distance\n",
    "        loss = (torch.tensor([op_action]) - action).pow(2).sum().sqrt()\n",
    "        # print(loss)\n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        model.actor.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        perturbed_state = state - state_grad.sign() * epsilon * 0.1\n",
    "        l =  torch.from_numpy(_state) - torch.from_numpy(state_range)\n",
    "        u = torch.from_numpy(_state) +  torch.from_numpy(state_range)\n",
    "        perturbed_state = torch.max(torch.min(perturbed_state, u), l)\n",
    "            \n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "\n",
    "        if pertub_dist <= dist:\n",
    "            # \n",
    "            if loss <= effect:\n",
    "                effect = loss\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy()  - _state)[0]\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "  \n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print('find solution')\n",
    "        return attack\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fdc3f27e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:27:21.494037200Z",
     "start_time": "2023-10-22T14:36:41.918971100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsion:0.2\n",
      "Total number reached = 681\n",
      "Total number violate = 247\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "epsion:0.5\n",
      "Total number reached = 370\n",
      "Total number violate = 228\n",
      "+++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[222], line 50\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# print(f'state:{state}')\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Print initial state\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(env\u001B[38;5;241m.\u001B[39mstep_const):\n\u001B[0;32m     48\u001B[0m   \n\u001B[0;32m     49\u001B[0m     \u001B[38;5;66;03m# print(state)\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m     attack \u001B[38;5;241m=\u001B[39m \u001B[43msafe_attack\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;66;03m# print(attack)\u001B[39;00m\n\u001B[0;32m     52\u001B[0m     pertub_state \u001B[38;5;241m=\u001B[39m state \u001B[38;5;241m+\u001B[39m attack\n",
      "Cell \u001B[1;32mIn[204], line 61\u001B[0m, in \u001B[0;36msafe_attack\u001B[1;34m(env, state, model, epsilon)\u001B[0m\n\u001B[0;32m     56\u001B[0m     x_state \u001B[38;5;241m=\u001B[39m odeint(bicycle, state, ts, args\u001B[38;5;241m=\u001B[39m(action,))[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;66;03m# non_linear_eq= lambda x: np.linalg.norm(odeint(bicycle, state, ts, args=(x,))[-1] - env.center) -\\\u001B[39;00m\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;66;03m#                         np.linalg.norm(odeint(bicycle, state, ts, args=(action,))[-1] - env.center)\u001B[39;00m\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# non_linear_constr = NonlinearConstraint(non_linear_eq, - np.inf, 0.0 )\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m#     result = minimize(f, x_start, method='trust-constr', bounds=bounds, constraints=non_linear_constr)\u001B[39;00m\n\u001B[1;32m---> 61\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_start\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrust-constr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;66;03m# print(result.x)\u001B[39;00m\n\u001B[0;32m     63\u001B[0m     op_action \u001B[38;5;241m=\u001B[39m (result\u001B[38;5;241m.\u001B[39mx)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_minimize.py:634\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001B[0;32m    632\u001B[0m                            constraints, callback\u001B[38;5;241m=\u001B[39mcallback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrust-constr\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 634\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_minimize_trustregion_constr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhess\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhessp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdogleg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    638\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _minimize_dogleg(fun, x0, args, jac, hess,\n\u001B[0;32m    639\u001B[0m                             callback\u001B[38;5;241m=\u001B[39mcallback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\minimize_trustregion_constr.py:509\u001B[0m, in \u001B[0;36m_minimize_trustregion_constr\u001B[1;34m(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)\u001B[0m\n\u001B[0;32m    500\u001B[0m     _, result \u001B[38;5;241m=\u001B[39m equality_constrained_sqp(\n\u001B[0;32m    501\u001B[0m         fun_and_constr, grad_and_jac, lagrangian_hess,\n\u001B[0;32m    502\u001B[0m         x0, objective\u001B[38;5;241m.\u001B[39mf, objective\u001B[38;5;241m.\u001B[39mg,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    505\u001B[0m         initial_constr_penalty, initial_tr_radius,\n\u001B[0;32m    506\u001B[0m         factorization_method)\n\u001B[0;32m    508\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtr_interior_point\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 509\u001B[0m     _, result \u001B[38;5;241m=\u001B[39m \u001B[43mtr_interior_point\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobjective\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlagrangian_hess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_vars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcanonical\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_ineq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcanonical\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_eq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcanonical\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcanonical\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    513\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43mc_ineq0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mJ_ineq0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc_eq0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mJ_eq0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcanonical\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeep_feasible\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mxtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_barrier_parameter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43minitial_barrier_tolerance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43minitial_constr_penalty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_tr_radius\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfactorization_method\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;66;03m# Status 3 occurs when the callback function requests termination,\u001B[39;00m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;66;03m# this is assumed to not be a success.\u001B[39;00m\n\u001B[0;32m    524\u001B[0m result\u001B[38;5;241m.\u001B[39msuccess \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\tr_interior_point.py:321\u001B[0m, in \u001B[0;36mtr_interior_point\u001B[1;34m(fun, grad, lagr_hess, n_vars, n_ineq, n_eq, constr, jac, x0, fun0, grad0, constr_ineq0, jac_ineq0, constr_eq0, jac_eq0, stop_criteria, enforce_feasibility, xtol, state, initial_barrier_parameter, initial_tolerance, initial_penalty, initial_trust_radius, factorization_method)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;66;03m# Solves a sequence of barrier problems\u001B[39;00m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;66;03m# Solve SQP subproblem\u001B[39;00m\n\u001B[1;32m--> 321\u001B[0m     z, state \u001B[38;5;241m=\u001B[39m \u001B[43mequality_constrained_sqp\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubprob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_and_constraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    323\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubprob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient_and_jacobian\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubprob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlagrangian_hessian\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[43m        \u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfun0_subprob\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad0_subprob\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    326\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconstr0_subprob\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac0_subprob\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubprob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    327\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_penalty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_radius\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfactorization_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_lb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_ub\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubprob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaling\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m subprob\u001B[38;5;241m.\u001B[39mterminate:\n\u001B[0;32m    330\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:101\u001B[0m, in \u001B[0;36mequality_constrained_sqp\u001B[1;34m(fun_and_constr, grad_and_jac, lagr_hess, x0, fun0, grad0, constr0, jac0, stop_criteria, state, initial_penalty, initial_trust_radius, factorization_method, trust_lb, trust_ub, scaling)\u001B[0m\n\u001B[0;32m     92\u001B[0m last_iteration_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stop_criteria(state, x, last_iteration_failed,\n\u001B[0;32m     94\u001B[0m                         optimality, constr_violation,\n\u001B[0;32m     95\u001B[0m                         trust_radius, penalty, cg_info):\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;66;03m# ||dn|| <= TR_FACTOR * trust_radius\u001B[39;00m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;66;03m# BOX_FACTOR * lb <= dn <= BOX_FACTOR * ub.\u001B[39;00m\n\u001B[1;32m--> 101\u001B[0m     dn \u001B[38;5;241m=\u001B[39m \u001B[43mmodified_dogleg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mTR_FACTOR\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrust_radius\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mBOX_FACTOR\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrust_lb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mBOX_FACTOR\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrust_ub\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;66;03m# Tangential Step - `dt`\u001B[39;00m\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;66;03m# Solve the QP problem:\u001B[39;00m\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;66;03m# minimize 1/2 dt.T H dt + dt.T (H dn + c)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;66;03m# ||dt|| <= sqrt(trust_radius**2 - ||dn||**2)\u001B[39;00m\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;66;03m# lb - dn <= dt <= ub - dn\u001B[39;00m\n\u001B[0;32m    113\u001B[0m     c_t \u001B[38;5;241m=\u001B[39m H\u001B[38;5;241m.\u001B[39mdot(dn) \u001B[38;5;241m+\u001B[39m c\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\qp_subproblem.py:363\u001B[0m, in \u001B[0;36mmodified_dogleg\u001B[1;34m(A, Y, b, trust_radius, lb, ub)\u001B[0m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Approximately  minimize ``1/2*|| A x + b ||^2`` inside trust-region.\u001B[39;00m\n\u001B[0;32m    317\u001B[0m \n\u001B[0;32m    318\u001B[0m \u001B[38;5;124;03mApproximately solve the problem of minimizing ``1/2*|| A x + b ||^2``\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;124;03m       programming.\" SIAM Journal on Optimization 9.4 (1999): 877-900.\u001B[39;00m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;66;03m# Compute minimum norm minimizer of 1/2*|| A x + b ||^2.\u001B[39;00m\n\u001B[1;32m--> 363\u001B[0m newton_point \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[43mY\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    364\u001B[0m \u001B[38;5;66;03m# Check for interior point\u001B[39;00m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inside_box_boundaries(newton_point, lb, ub)  \\\n\u001B[0;32m    366\u001B[0m    \u001B[38;5;129;01mand\u001B[39;00m norm(newton_point) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m trust_radius:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\sparse\\linalg\\interface.py:418\u001B[0m, in \u001B[0;36mLinearOperator.dot\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    415\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\n\u001B[0;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatvec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmatmat(x)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\sparse\\linalg\\interface.py:232\u001B[0m, in \u001B[0;36mLinearOperator.matvec\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (N,) \u001B[38;5;129;01mand\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (N,\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdimension mismatch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 232\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_matvec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, np\u001B[38;5;241m.\u001B[39mmatrix):\n\u001B[0;32m    235\u001B[0m     y \u001B[38;5;241m=\u001B[39m asmatrix(y)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\sparse\\linalg\\interface.py:530\u001B[0m, in \u001B[0;36m_CustomLinearOperator._matvec\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    529\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_matvec\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m--> 530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__matvec_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\projections.py:167\u001B[0m, in \u001B[0;36maugmented_system_projections.<locals>.row_space\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    164\u001B[0m v \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack([np\u001B[38;5;241m.\u001B[39mzeros(n), x])\n\u001B[0;32m    165\u001B[0m \u001B[38;5;66;03m# lu_sol = [ z ]\u001B[39;00m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;66;03m#          [aux]\u001B[39;00m\n\u001B[1;32m--> 167\u001B[0m lu_sol \u001B[38;5;241m=\u001B[39m \u001B[43msolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;66;03m# return z = A.T inv(A A.T) x\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m lu_sol[:n]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Test 50 traces for safe attack\n",
    "\n",
    "# norm = 2\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 0.5\n",
    "policy = None\n",
    "args = None\n",
    "env = bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "clean_env = bicycleEnv()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "obs_dists = []\n",
    "obs_dists_list = []\n",
    "dist_list = []\n",
    "center = [1,1,0,math.sqrt(2)]\n",
    "obstacle = env.obstacle\n",
    "num_reached = 0\n",
    "action_list = []\n",
    "pertub_action_list = [] \n",
    "number_violate = 0\n",
    "clean_obs_dists = []\n",
    "clean_obs_dists_list = []\n",
    "clean_num_reached = 0\n",
    "clean_number_violate = 0\n",
    "clean_obs_dist_list = []\n",
    "clean_dist_list = []\n",
    "for epsilon in [ 0.2, 0.5, 0.7]:\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        _ = clean_env.reset()\n",
    "        clean_env.state = state\n",
    "        clean_state = state\n",
    "        # print(f'state:{state}')\n",
    "        # Print initial state\n",
    "        for i in range(env.step_const):\n",
    "          \n",
    "            # print(state)\n",
    "            attack = safe_attack(env, state, model, epsilon)\n",
    "            # print(attack)\n",
    "            pertub_state = state + attack\n",
    "            # pertub_state = state\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "            # print(pertub_action)\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            state = new_state\n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                # print('vio')\n",
    "                env.reset()\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                # print('reach')\n",
    "                env.reset()\n",
    "                break\n",
    "        # print('+++++++++++')   \n",
    "        # print(obs_dists)\n",
    "        # print('++++++++++++++++')\n",
    "        obs_dists_list.append(obs_dists)\n",
    "        obs_dists = []\n",
    "        \n",
    "       \n",
    "    print(f'epsion:{epsilon}')\n",
    "    print(\"Total number reached = \" + str(num_reached))\n",
    "    print(\"Total number violate = \" + str(number_violate))\n",
    "    print(\"+++++++++++++++++++++++++++++++++++\")\n",
    "# print(\"average of obs dist= \" + str(sum(obs_dist_list) / len(obs_dist_list)))\n",
    "res_list.append(num_reached)\n",
    "# print(\"clean env for reference\")\n",
    "# print(\"Total number reached = \" + str(clean_num_reached))\n",
    "# print(\"Total number violate = \" + str(clean_number_violate))\n",
    "# print(\"average of obs dist= \" + str(sum(clean_obs_dist_list) / len(clean_obs_dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c7582f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI0UlEQVR4nO3deZzNdf//8eeZfTPD2McMowjZSYylZtAyIRJddamGXNclKXzR4uoqS0ouWnWRuopKUWoQ0YLsXNnLThFlzTJjHWbm/fujn1PHLM585owz5zOP++12bvl8zvvz+bxmcl6e57M6jDFGAAAANuXn7QIAAACKEmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHeerZs6ciIiI8vs74+HiPrtPTVq5cqeHDh+vkyZM53pswYYKmTJlS5DXEx8erY8eORbqN4cOHy+FwFOk2AHctXrxYDodDixcv9nYpsCHCDq6qZ555RjNnzvR2GflauXKlRowY4dWwAwDwnABvF4CS5dprr/V2CQCAEoY9O8XMrl279Ne//lUVKlRQcHCw6tSpo//85z8uYy7t7p02bZqefvppxcTEKDIyUu3bt9eOHTuc4wYOHKjw8HClp6fn2M5f/vIXVaxYURcvXrxiTVu2bFG7du0UHh6u8uXL69FHH9XZs2ddxhhjNGHCBDVq1EihoaEqU6aMunXrpp9++sllXG6HsRwOhx599FF98MEHqlOnjsLCwtSwYUPNnTs3Ry2zZ89WgwYNFBwcrGuuuUavvfaa24djvvnmG3Xu3FmxsbEKCQlRjRo11KdPH/3222/OMcOHD9fjjz8uSapevbocDodz13p8fLy2bNmiJUuWOOdf+lnOnz+vwYMHq1GjRoqKilJ0dLQSEhI0e/bsHHVkZ2dr/Pjxzt9V6dKl1aJFC33++ef51j9hwgQFBARo2LBhznkLFixQu3btFBkZqbCwMLVq1UoLFy7MsewXX3yhRo0aKTg4WNWrV9e4ceOu+PsCPGn79u267777VLFiRQUHB6tq1ap68MEHlZGRke9ya9eu1Z133qno6GiFhISocePG+uSTT1zGHD16VI888oiuv/56RUREqEKFCmrbtq2WLVvmMm7v3r1yOBwaN26cXn75ZVWvXl0RERFKSEjQ6tWr3fo5Dh06pD59+ig2NlZBQUGqXr26RowYoczMzAJv59VXX5XD4dDu3btzbOfJJ59UUFCQS39CIRgUG1u2bDFRUVGmfv365v333zdff/21GTx4sPHz8zPDhw93jvv222+NJBMfH2969OhhvvjiCzNt2jRTtWpVU7NmTZOZmWmMMWbTpk1Gknn77bddtnPixAkTHBxsBg0alG89KSkpJigoyFStWtU8//zz5uuvvzbDhw83AQEBpmPHji5j//73v5vAwEAzePBg8+WXX5qPPvrI1K5d21SsWNEcOnTIZZ3VqlVzWfbSz3LjjTeaTz75xMybN88kJiaagIAA8+OPPzrHzZ8/3/j5+ZnExEQzc+ZMM2PGDNO8eXMTHx9v3PmrPHHiRDN69Gjz+eefmyVLlpj33nvPNGzY0NSqVctcuHDBGGPM/v37zWOPPWYkmdTUVLNq1SqzatUqk5aWZtavX2+uueYa07hxY+f89evXG2OMOXnypOnZs6f54IMPzKJFi8yXX35phgwZYvz8/Mx7773nUscDDzxgHA6H+dvf/mZmz55t5s+fb55//nnz2muvOcdUq1bNdOjQwRhjTHZ2thk8eLAJDAw0kydPdo754IMPjMPhMF26dDGpqalmzpw5pmPHjsbf398sWLDAOW7BggXG39/ftG7d2qSmppoZM2aYZs2amapVq7r1ewMKa+PGjSYiIsLEx8ebN9980yxcuNBMnTrV3HPPPSY9Pd0Y80df+/bbb53LLVq0yAQFBZk2bdqYjz/+2Hz55ZemZ8+eRpLLZ2H79u2mb9++Zvr06Wbx4sVm7ty5pnfv3sbPz89lfXv27HH2m9tvv93MmjXLzJo1y9SvX9+UKVPGnDx5Mt+f4+DBgyYuLs5Uq1bNTJo0ySxYsMA899xzJjg42PTs2bPA2zl69KgJCgoyTz/9tMt2MjMzTUxMjOnatavF3zguR6crRm677TYTGxtr0tLSXOY/+uijJiQkxBw/ftwY80dTuOOOO1zGffLJJ0aSWbVqlXNekyZNTMuWLV3GTZgwwUgyP/zwQ771pKSkGEku/wgbY8zzzz9vJJnly5cbY4xZtWqVkWReeukll3H79+83oaGh5oknnnBZZ25hp2LFis6mZ4wxhw4dMn5+fmb06NHOec2aNTNxcXEmIyPDOe/UqVOmbNmyBf5HOzs721y8eNH8/PPPRpKZPXu2872xY8caSWbPnj05lqtbt665+eabr7j+zMxMc/HiRdO7d2/TuHFj5/ylS5caSTma2+UuhZ2zZ8+au+++20RFRbkEmDNnzpjo6GjTqVMnl+WysrJMw4YNzY033uic17x5cxMTE2POnTvnnJeenm6io6MJO7gq2rZta0qXLm2OHDmS55jcwk7t2rVN48aNzcWLF13GduzY0VSuXNlkZWXluq5Ln7927dqZu+66yzn/UgipX7++80uhMcZ89913RpKZNm1avj9Hnz59TEREhPn5559d5o8bN85IMlu2bCnwdrp27WpiY2NdfpZ58+YZSWbOnDn51gP3cRirmDh//rwWLlyou+66S2FhYcrMzHS+7rjjDp0/fz7HbtY777zTZbpBgwaSpJ9//tk5r1evXlq5cqXL4a3JkyerWbNmqlevnlu19ejRw2X6r3/9qyTp22+/lSTNnTtXDodD999/v0vdlSpVUsOGDd26uiIpKUmlSpVyTlesWFEVKlRw/ixnzpzR2rVr1aVLFwUFBTnHRUREqFOnTm79HEeOHNHDDz+suLg4BQQEKDAwUNWqVZMkbdu2za115GfGjBlq1aqVIiIinOt/5513XNY9f/58SVK/fv2uuL5jx46pbdu2+u6777R8+XK1a9fO+d7KlSt1/PhxpaSkuPzOs7Ozdfvtt2vNmjU6c+aMzpw5ozVr1qhr164KCQlxLl+qVCm3f29AYZw9e1ZLlizRPffco/Lly7u93O7du7V9+3Zn/7m8Jx48eNClr7355ptq0qSJQkJCnJ+/hQsX5vrZ7tChg/z9/Z3TufXO3MydO1dJSUmKiYlxqSc5OVmStGTJkgJvp1evXvrll1+0YMEC57zJkyerUqVKzvWi8Ag7xcSxY8eUmZmp8ePHKzAw0OV1xx13SFKOY7dly5Z1mQ4ODpYknTt3zjmvR48eCg4Odl5BtHXrVq1Zs0a9evVyq66AgIAc26lUqZKzZkk6fPiwjDGqWLFijtpXr17t1jHny7dx6ee59LOcOHHCuY3L5TbvctnZ2br11luVmpqqJ554QgsXLtR3333nDJB//p1ZkZqaqnvuuUdVqlTR1KlTtWrVKq1Zs0YPPfSQzp8/7xx39OhR+fv7O3+H+dm5c6f+97//KTk5OUcwPXz4sCSpW7duOX7nY8aMkTFGx48f14kTJ5SdnZ3r9typASisEydOKCsrS7GxsQVa7tLf8SFDhuT4O/7II49I+qMnvvzyy+rbt6+aN2+uzz77TKtXr9aaNWt0++235/rZdqd35lXTnDlzctRTt25dl3oKsp3k5GRVrlxZkydPlvT77+vzzz/Xgw8+6BKUUDhcjVVMlClTRv7+/nrggQfy/NZfvXp1S+vt3Lmz3n//fY0aNUqTJ09WSEiI7rvvPreWz8zM1LFjx1w+tIcOHZL0xwe5XLlycjgcWrZsmfPD/Ge5zbPyczgcDmcD/LNL9eRn8+bN2rRpk6ZMmaKUlBTn/NxODLRi6tSpql69uj7++GOXk6UvP/myfPnyysrK0qFDh1S5cuV815mQkKDu3burd+/ekqSJEyfKz+/37yflypWTJI0fP14tWrTIdflLJ6A7HI5cf0fu/N6AwoqOjpa/v79++eWXAi136e/40KFD1bVr11zH1KpVS9Lvn7/ExERNnDjR5f1Tp05ZqDj/mho0aKDnn38+1/djYmIKvM5Lff/111/XyZMn9dFHHykjI8PtL6RwD2GnmAgLC1NSUpI2bNigBg0auByqKaxevXrpk08+0bx58zR16lTdddddKl26tNvLf/jhh+rfv79z+qOPPpIkJSYmSpI6duyoF198Ub/++qvuuecej9X9Z+Hh4brhhhs0a9YsjRs3zvn7OX36dK5XbV3uUgC5PHhNmjQpx9j8vuX9eW/T5esPCgpyCTqHDh3KcTVWcnKyRo8erYkTJ2rkyJFXrDslJUXh4eH661//qjNnzui9996Tv7+/WrVqpdKlS2vr1q169NFH81w+KChIN954o1JTUzV27FjnoaxTp05pzpw5V9w+UFihoaG6+eabNWPGDD3//PPOEHMltWrVUs2aNbVp0ya98MIL+Y51OBw5Ptvff/+9Vq1apbi4OMu1X65jx46aN2+err32WpUpU8Zj6+3Vq5f+/e9/a9q0aZoyZYoSEhJUu3Ztj60fhJ1i5bXXXlPr1q3Vpk0b9e3bV/Hx8Tp16pR2796tOXPmaNGiRZbWe+uttyo2NlaPPPKIDh06VKBvDEFBQXrppZd0+vRpNWvWTCtXrtSoUaOUnJys1q1bS5JatWqlf/zjH+rVq5fWrl2rm266SeHh4Tp48KCWL1+u+vXrq2/fvpZq/7ORI0eqQ4cOuu222zRgwABlZWVp7NixioiI0PHjx/Ndtnbt2rr22mv11FNPyRij6OhozZkzR998802OsfXr15f0+/+PlJQUBQYGqlatWipVqpTq16+v6dOn6+OPP9Y111yjkJAQ1a9fXx07dlRqaqoeeeQRdevWTfv379dzzz2nypUra9euXc51t2nTRg888IBGjRqlw4cPq2PHjgoODtaGDRsUFhamxx57LEc93bp1U1hYmLp166Zz585p2rRpioiI0Pjx45WSkqLjx4+rW7duqlChgo4ePapNmzbp6NGjzm+5zz33nG6//XbdcsstGjx4sLKysjRmzBiFh4df8fcGeMLLL7+s1q1bq3nz5nrqqadUo0YNHT58WJ9//rkmTZrkcr7en02aNEnJycm67bbb1LNnT1WpUkXHjx/Xtm3btH79es2YMUPS7yHkueee07Bhw3TzzTdrx44dGjlypKpXr+5ySXhhjRw5Ut98841atmyp/v37q1atWjp//rz27t2refPm6c033yzw4Trp9/6UkJCg0aNHa//+/Xrrrbc8VjP+P++eH43L7dmzxzz00EOmSpUqJjAw0JQvX960bNnSjBo1yjnm0lULM2bMyLGsLrsk85J//vOfRpKJi4vL8wqGy6WkpJjw8HDz/fffm8TERBMaGmqio6NN3759zenTp3OMf/fdd03z5s1NeHi4CQ0NNddee6158MEHzdq1a13WmdvVWP369cuxvmrVqpmUlBSXeTNnzjT169d3XhL/4osvmv79+5syZcpc8efZunWrueWWW0ypUqVMmTJlTPfu3c2+ffuMJDNs2DCXsUOHDjUxMTHGz8/P5QqRvXv3mltvvdWUKlXKSHL5WV588UUTHx9vgoODTZ06dczbb79thg0bluOKp6ysLPPKK6+YevXqmaCgIBMVFWUSEhJcrrz486Xnl3z77bcmIiLC3H777ebs2bPGGGOWLFliOnToYKKjo01gYKCpUqWK6dChQ46/G59//rlp0KCBy+8tt9qAorJ161bTvXt3U7ZsWeffw549e5rz588bY3K/GsuY32+hcc8995gKFSqYwMBAU6lSJdO2bVvz5ptvOsdkZGSYIUOGmCpVqpiQkBDTpEkTM2vWrBz95lKPHDt2bI76cusDuTl69Kjp37+/qV69ugkMDDTR0dGmadOm5umnn3b2RSvbeeutt4wkExoamuOKXBSewxhjvJCxAI+4ePGiGjVqpCpVqujrr7/2djkAgGKIw1jwKb1799Ytt9yiypUr69ChQ3rzzTe1bds2vfbaa94uDQBQTBF24FNOnTqlIUOG6OjRowoMDFSTJk00b948tW/f3tulAQCKKQ5jAQAAW/P5mwpmZmbqX//6l6pXr67Q0FBdc801GjlypLKzs71dGoBijN4BlBw+fxhrzJgxevPNN/Xee++pbt26Wrt2rXr16qWoqCgNGDDA2+UBKKboHUDJ4fNhZ9WqVercubM6dOggSYqPj9e0adO0du1aL1cGoDijdwAlh8+HndatW+vNN9/Uzp07dd1112nTpk1avny5Xn311TyXycjIcLmNf3Z2to4fP66yZcu63AEXwNVhjNGpU6cUExPjfCRGUSto76BvAMWP273Dmzf58YTs7Gzz1FNPGYfDYQICAozD4TAvvPBCvstcupkaL168itdr//79V6lzFLx30Dd48Sq+ryv1Dp+/Gmv69Ol6/PHHNXbsWNWtW1cbN27UwIED9fLLL7s88PHPLv+GlpaWpqpVq2r//v2KjIy8WqUD+P/S09MVFxenkydPKioq6qpss6C9g74BFD/u9g6fDztxcXF66qmnXJ4UPmrUKE2dOlXbt293ax3p6emKiopSWloaTQvwAm98BgvbO+gbgPe5+zn0+UvPz549m+M4nb+/P5ePAsgXvQMoOXz+BOVOnTrp+eefV9WqVVW3bl1t2LBBL7/8sh566CFvlwagGKN3ACWHzx/GOnXqlJ555hnNnDlTR44cUUxMjO677z49++yzCgoKcmsd7I4GvMsbn8HC9g76BuB97n4OfT7seAJNC/AuX/wM+mLNgN2UmHN2AAAA8kPYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtkbYAQAAtubzYSc+Pl4OhyPHq1+/ft4uDUAxRu8ASo4AbxdQWGvWrFFWVpZzevPmzbrlllvUvXt3L1YFoLijdwAlh8+HnfLly7tMv/jii7r22mt18803e6kiAL6A3gGUHD4fdv7swoULmjp1qgYNGiSHw5HnuIyMDGVkZDin09PTr0Z5AIopd3oHfQPwXT5/zs6fzZo1SydPnlTPnj3zHTd69GhFRUU5X3FxcVenQADFkju9g74B+C6HMcZ4uwhPue222xQUFKQ5c+bkOy63b2hxcXFKS0tTZGRkUZcJ4DLp6emKiory2mfQnd5B3wCKH3d7h20OY/38889asGCBUlNTrzg2ODhYwcHBV6EqAMWdu72DvgH4Ltscxpo8ebIqVKigDh06eLsUAD6E3gHYny3CTnZ2tiZPnqyUlBQFBNhmZxWAIkbvAEoGW4SdBQsWaN++fXrooYe8XQoAH0LvAEoGW3yVufXWW2Wj86wBXCX0DqBksMWeHQAAgLwQdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK3ZIuz8+uuvuv/++1W2bFmFhYWpUaNGWrdunbfLAlDM0TuAkiHA2wUU1okTJ9SqVSslJSVp/vz5qlChgn788UeVLl3a26UBKMboHUDJ4fNhZ8yYMYqLi9PkyZOd8+Lj471XEACfQO8ASg6fP4z1+eef64YbblD37t1VoUIFNW7cWG+//Xa+y2RkZCg9Pd3lBaBkKWjvoG8Avsvnw85PP/2kiRMnqmbNmvrqq6/08MMPq3///nr//ffzXGb06NGKiopyvuLi4q5ixQCKg4L2DvoG4Lscxhjj7SIKIygoSDfccINWrlzpnNe/f3+tWbNGq1atynWZjIwMZWRkOKfT09MVFxentLQ0RUZGFnnNAFylp6crKirqqn4GC9o76BtA8eNu7/D5PTuVK1fW9ddf7zKvTp062rdvX57LBAcHKzIy0uUFoGQpaO+gbwC+y+fDTqtWrbRjxw6XeTt37lS1atW8VBEAX0DvAEoOnw87//d//6fVq1frhRde0O7du/XRRx/prbfeUr9+/bxdGoBijN4BlBw+H3aaNWummTNnatq0aapXr56ee+45vfrqq+rRo4e3SwNQjNE7gJLD509Q9gRvnBwJ4A+++Bn0xZoBuykxJygDAADkh7ADAABsrVBhZ/78+erSpYuqVKmi4OBg9e7d2+W9QYMG6cCBA4UuEgAAwCrLYeeRRx5Rx44d9fnnn+v06dO6ePGi/nz6T+nSpfXqq69q+vTpHikUAADACkth591339Wbb76pG2+8URs3blRaWlqOMQkJCapSpYrmzJlT6CIBAACssvTU80mTJik6Olpz585V2bJl8xxXo0YN/fTTT5aLAwAAKCxLe3a2bNmihISEfIOOJFWqVElHjhyxVBgAAIAnWAo7fn5+ys7OvuK4AwcOKDw83MomAAAAPMJS2Kldu7bWrl2rs2fP5jnm2LFj2rhxoxo0aGC5OAAAgMKyFHZ69Oiho0ePql+/fsrMzMzxvjFG/fv31+nTp/XAAw8UukgAAACrLJ2g/Mgjj+izzz7Te++9p+XLl+u2226TJH3//fcaMmSI5s6dq507d6pt27ZKSUnxaMEAAAAFYfnZWGfPntWQIUP0zjvv6OLFiy7v+fv7q2fPnnr99dcVGhrqkUKLEs+4AbzLFz+DvlgzYDfufg4t7dmRpLCwME2YMEEjRozQkiVLtHfvXmVlZSk2NlZJSUmKiYmxumoAAACPcSvstG3bVrfffrueeOIJSdLSpUtVqVIlXXfddSpfvry6detWpEUCAABY5dYJyosXL9b27dud04mJiRozZkyRFQUAAOApboWdoKAgnTlzxmWexVN9AAAAriq3DmPVqFFDCxcu1JIlS1S9enVJ0unTp7Vv3z63NlK1alXrFQIAABSCW2HnH//4hwYOHKi2bds653322Wf67LPPrrisw+HI9V48AAAAV4NbYad///6KjY3V7Nmz9csvv+jbb79VhQoVVLt27aKuDwAAoFDcvvS8a9eu6tq1q6Tfn42VnJysd999t8gKAwAA8ARL99kZNmyYGjdu7OlaAAAAPM5y2AEAAPAFlu+g/GcnT57UqVOn8rwcnauxAACAt1gOO4cOHdK//vUvzZ49W8ePH89zHFdjAQAAb7IUdg4ePKhmzZrpwIEDqlKlisqXL68jR44oISFBP/30kw4fPiyHw6GEhAQFBgZ6umYAAAC3uXUH5cuNGjVKBw4c0MiRI7V//34lJyfL4XBoxYoVOnjwoBYvXqzatWvL4XBo/vz5nq4ZAADAbZbCzpdffqnq1avrX//6V67v33TTTfr666+1YcMGPffcc4UqEAAAoDAshZ1ff/1VjRo1ck77+/tLkjIyMpzzqlSpoqSkJH3yySeFqxAAAKAQLIWdyMhIlyuvSpcuLen3EPRnISEhOeYBAABcTZbCTtWqVbV3717ndL169SRJ8+bNc847e/asVqxYocqVKxeuQgAAgEKwFHbatm2rzZs36/Dhw5KkO++8U+Hh4RoyZIiefPJJjR8/XklJSTp8+LCSk5M9WvDlhg8fLofD4fKqVKlSkW4TgO+jdwAlh6VLz3v06KH9+/dr27ZtqlixoqKjozVp0iT16tVLY8eOlcPhkDFGdevW1fPPP+/pmnOoW7euFixY4Jy+dA4RAOSH3gGUDJbCTsOGDTVt2jSXeffdd59atWqlefPm6cSJE7ruuut05513XpX77AQEBPCNDECB0TuAksEjj4u4pGrVqnr44Yc9uUq37Nq1SzExMQoODlbz5s31wgsv6JprrslzfEZGhsuVY+np6VejTADFTEF6B30D8F2WztnJT3p6utauXatDhw55etW5at68ud5//3199dVXevvtt3Xo0CG1bNlSx44dy3OZ0aNHKyoqyvmKi4u7KrUCKD4K2jvoG4Dvcpi8nt6Zj6+//lrTp0/XY489psaNGzvnT5w4UYMGDdKFCxfkcDg0cOBAjRs3zqMFX8mZM2d07bXX6oknntCgQYNyHZPbN7S4uDilpaUpMjLyapUK4P9LT09XVFSUVz+DV+od9A2g+HG3d1jas/Pf//5XH3/8sWrUqOGct3XrVj322GPKyspSixYtFBkZqVdeeUVz5syxsgnLwsPDVb9+fe3atSvPMcHBwYqMjHR5ASjZrtQ76BuA77IUdtavX6/GjRurVKlSznmTJ0+WMUZTpkzRihUrtGHDBgUHB2vChAkeK9YdGRkZ2rZtG/f3AVAg9A7AviyFncOHDys2NtZl3oIFC1S6dGnde++9kqRq1arppptu0pYtWwpfZT6GDBmiJUuWaM+ePfrf//6nbt26KT09XSkpKUW6XQC+jd4BlByWrsYKCAjQhQsXnNOnT5/W5s2b1aFDB/n5/ZGfypcvr6NHjxa+ynz88ssvuu+++/Tbb7+pfPnyatGihVavXq1q1aoV6XYB+DZ6B1ByWAo78fHxWrdunXP6iy++UFZWlm655RaXcceOHVPZsmULV+EVTJ8+vUjXD8Ce6B1AyWHpMNa9996r/fv36+6779brr7+uwYMHKygoSF26dHGOMcZo3bp1+d7vBgAAoKhZCjuPPfaYEhISNHPmTA0cOFCHDh3Siy++qCpVqjjHLFq0SEePHlVSUpLHigUAACgoS4exwsLCtGzZMi1btkxHjhxRo0aNVLNmTZcx/v7+euWVV9SpUyePFAoAAGCF5cdF+Pn56eabb87z/cTERCUmJlpdPQAAgEd4/HERAAAAxUmhHgS6ePFiLV26VAcPHnS5jfqfORwOvfPOO4XZDAAAgGWWwk5aWpo6d+6sZcuW6UqP1iLsAAAAb7IUdp588kktXbpUNWrUUN++fXXdddcpIiLC07UBAAAUmqWwM3v2bFWsWFGrV69WdHS0p2sCAADwGEsnKKelpally5YEHQAAUOxZCjs1a9Ys8mdeAQAAeILlOyh/9913+uGHHzxdDwAAgEdZCjt/+9vfNGDAACUnJ2vKlCn69ddfPV0XAACAR1g6Qdnf31/S7w/77N27d75jHQ6HMjMzrWwGAACg0CyFnbi4ODkcDk/XAgAA4HGWws7evXs9XAYAAEDR4NlYAADA1gg7AADA1iwdxnr//fcLNP7BBx+0shkAAIBCsxR2evbs6dYJysYYORwOwg4AAPAaS2Hn2WefzTXsZGdna//+/VqyZIn27Nmjnj17qlq1aoUuEgAAwCpLYWf48OH5vn/x4kUNHDhQn376qdasWWNlEwAAAB5RJCcoBwYG6rXXXlNoaKieeuqpotgEAACAW4rsaqyAgAA1bdpU33zzTVFtAgAA4IqK9NLzQ4cO6cyZM0W5CQAAgHwVSdjJzs7W+PHjtWrVKjVo0KAoNgEAAOAWSycot23bNs/3Tp8+rT179uj48ePy8/PTsGHDLBcHAABQWJbCzuLFi/N9PzAwUK1bt9azzz6rdu3aWdkEAACAR1gKO3v27MnzvaCgIJUrV06BgYGWiwIAAPAUS2GHGwUCAABfYbsHgY4ePVoOh0MDBw70dikAfAR9A7A3W4WdNWvW6K233uIKMABuo28A9mebsHP69Gn16NFDb7/9tsqUKePtcgD4APoGUDLYJuz069dPHTp0UPv27a84NiMjQ+np6S4vACUPfQMoGSydoFzcTJ8+XevXr3f7oaOjR4/WiBEjirgqAMUZfQMoOXx+z87+/fs1YMAATZ06VSEhIW4tM3ToUKWlpTlf+/fvL+IqARQn9A2gZHEYY4y3iyiMWbNm6a677pK/v79zXlZWlhwOh/z8/JSRkeHyXm7S09MVFRWltLQ0RUZGFnXJAC5ztT+D9A3AHtz9HBb6MFZmZqY2bdqkAwcOyOFwqHLlymrYsKECAq7OEbJ27drphx9+cJnXq1cv1a5dW08++eQVGxaAkoe+AZQslhNJRkaGhg0bpjfffFOnTp1yea9UqVJ6+OGHNXz4cLd3EVtVqlQp1atXz2VeeHi4ypYtm2M+AEj0DaCksRR2MjIy1K5dO61atUqS1KBBA8XHx0uSfv75Z23atEljx47V8uXLtXDhQgUHB3usYAAAgIKwFHZeeeUVrVy5Uq1bt9aECRNyfBPavHmzHn30US1btkyvvvqqnnzySY8U664rPagUAC5H3wDsy9LVWNOmTVP58uU1b968XHf51qtXT3PnzlW5cuX04YcfFrpIAAAAqyyFnd27dysxMVERERF5jomIiFBiYqJ+/PFHy8UBAAAUlqWwExAQoLNnz15x3NmzZ6/aVVkAAAC5sRR26tevr0WLFmnPnj15jtmzZ48WLVrEw/UAAIBXWQo7ffr00blz55SYmKj33ntPFy5ccL6XkZGhKVOmKDExUefPn9fDDz/ssWIBAAAKytIxpgceeEDLly/X22+/rYceeki9e/dWxYoV5XA4dOjQIRljZIxRnz591KNHD0/XDAAA4DbLz8aaNGmSZsyYodatWysgIEAHDx7UgQMHFBAQoDZt2mjGjBmaOHGiJ2sFAAAosEKdPXz33Xfr7rvvVmZmpo4dOyZJKlu2LCclAwCAYsPSnp2lS5dq586dzumAgABVrFhRFStWdAk6u3bt0tKlSwtfJQAAgEWWwk5iYqLGjBlzxXH//ve/lZSUZGUTAAAAHmH5nB1jjEfGAAAAFCXLYccdBw4cyPcuywAAAEXN7TOJ33//fZfp3bt355h3SWZmpnbs2KEFCxaoRYsWhasQAACgENwOOz179pTD4ZAkORwOrVixQitWrMhzvDFGISEhevbZZwtfJQAAgEVuh51nn31WDodDxhiNHDlSjRo1UufOnXMdGxQUpJiYGN16662qXLmyx4oFAAAoKLfDzvDhw51/njJlitq3b69hw4YVRU0AAAAeY+nuf3v37vVwGQAAAEWjSK/GAgAA8DbCDgAAsDXCDgAAsDXCDgAAsDXCDgAAsDXCDgAAsDXCDgAAsLVChZ3Nmzdr4MCBatWqlWrVqqUnnnjC+d6KFSv0+uuv6/jx44UuEgAAwCpLNxWUpH//+9/617/+pczMTEm/Py/rt99+c75/9uxZ/d///Z+Cg4PVp0+fwlcKAABggaU9O7Nnz9ZTTz2latWqadasWTp69KiMMS5j2rdvr3LlymnWrFmeqBMAAMASS3t2XnnlFUVEROibb75RfHx8rmMcDodq1aqlnTt3FqY+AACAQrG0Z2fDhg1KSEjIM+hcUqVKFR08eNDKJgAAADzCUtjJzMxUWFjYFccdPXpUQUFBVjYBAADgEZbCzrXXXqt169YpKysrzzFnzpzRxo0bdf3111suzh0TJ05UgwYNFBkZqcjISCUkJGj+/PlFuk0Avo/eAZQclsJOt27d9Msvv+iZZ57Jc8wzzzyjEydO6C9/+Yvl4twRGxurF198UWvXrtXatWvVtm1bde7cWVu2bCnS7QLwbfQOoORwmMsvo3LDmTNndOONN2r79u1q1aqV7rzzTj3xxBO66aab1K1bN82aNUuLFi1Sw4YNtXr1agUHBxdF7XmKjo7W2LFj1bt3b7fGp6enKyoqSmlpaYqMjCzi6gBcrrh8BgvSO4pLzUBJ5u7n0NLVWOHh4fr222/Vs2dPffnll1qxYoUkaenSpVq2bJmMMWrXrp0+/PDDqxp0srKyNGPGDJ05c0YJCQl5jsvIyFBGRoZzOj09/WqUB6CYcqd30DcA32X5poIVKlTQvHnztGnTJn3zzTfau3evsrKyFBsbq/bt26t58+aerDNfP/zwgxISEnT+/HlFRERo5syZ+Z4rNHr0aI0YMeKq1QegeCpI76BvAL7L0mGs4ubChQvat2+fTp48qc8++0z//e9/tWTJkjybVm7f0OLi4tgdDXiJtw4JFaR30DeA4sfd3mGLsHO59u3b69prr9WkSZPcGs+xd8C7istnsCC9o7jUDJRk7n4OLV2N9frrr8vf31/z5s3Lc8z8+fPl7++vCRMmWNlEoRhjXL6BAYA76B2APVk6Z+ezzz5TTEyM7rjjjjzH3H777apcubI+/fRTPfLII5YLvJJ//vOfSk5OVlxcnE6dOqXp06dr8eLF+vLLL4tsmwB8H70DKDkshZ0dO3aocePG+Y5xOByqX7++Nm3aZKkwdx0+fFgPPPCADh48qKioKDVo0EBffvmlbrnlliLdLgDfRu8ASg5LYefkyZOKjo6+4rgyZcro+PHjVjbhtnfeeadI1w/AnugdQMlh6ZydSpUq6YcffrjiuM2bN6tcuXJWNgEAAOARlsJOUlKStmzZos8++yzPMampqdq8ebOSkpIsFwcAAFBYlsLOE088oaCgIPXo0UMDBw7U1q1bdf78eWVkZGjr1q0aOHCg/vrXvyooKEhPPPGEp2sGAABwm6VzdurUqaP3339fKSkpGj9+vMaPHy/p95OSjTEyxigkJETvvvuu6tev79GCAQAACsLSnh1J6t69u77//nv16dNHNWrUUHBwsIKCglSjRg317dtXmzZt0r333uvJWgEAAArM8rOxJKlGjRpeuWkgAACAuyzv2QEAAPAFhdqzI0mZmZk6duxYvrdYr1q1amE3AwAAYInlsLNgwQKNGjVKq1ev1sWLF/Mc53A4lJmZaXUzAAAAhWIp7MydO1d33XWXsrKyVKZMGV1zzTWKiIjwdG0AAACFZinsjBgxQtnZ2Xr11VfVr18/+fv7e7ouAAAAj7AUdrZs2aKEhAT179/f0/UAAAB4lKWwExERoYoVK3q6FiBXZ8+e1fbt2/Mdc+7cOe3du1fx8fEKDQ3Nc1zt2rUVFhbm6RIBAMWYpbDTvn17rVq1StnZ2fLz4+p1FK3t27eradOmHlnXunXr1KRJE4+sCwDgGyyFnTFjxqhZs2YaPHiwxo0bxzk7KFK1a9fWunXr8h2zbds23X///Zo6darq1KmT77oAACWLpbAzefJkJScn6/XXX9fcuXOVmJio2NhYORyOHGMdDoeeeeaZQheKkissLMztvTF16tRhzw0AwIWlsDN8+HDnQz9//PFH/fjjj3mOJewAAABvsrxnBwAAwBdYCjspKSmergMAAKBIcCkVAACwNcIOAACwNcsPAjXG6MMPP9Ts2bO1a9cunTp1SsaYHOMcDke+JzADAAAUJUth58KFC+rQoYMWLVqUa8CR5LxaCwAAwJssHcZ66aWXtHDhQnXs2FG7du3SAw88IIfDoYyMDG3btk3Dhw9XeHi4Hn/8cWVnZ3u6ZgAAALdZ2rPz8ccfKzo6Wh999JHCw8Odj4wIDAxUrVq19OyzzyopKUlJSUmqVauWHnroIY8WDQAA4C5Le3Z2796tG2+8UeHh4b+v5P+HnaysLOeYNm3aqFWrVpowYYIHygQAALDGUtjx9/dXZGSkc/pS6Dl69KjLuCpVqmjHjh2FKA8AAKBwLIWdKlWqaN++fc7pGjVqSJJWr17tMu77779XREREIcoDAAAoHEthp0WLFtqyZYvOnTsnSbrjjjskSQMGDND8+fP1ww8/6LHHHtO2bdvUvHlzz1ULAABQQJbCzt13362wsDB98803kn7fszNw4EDt379fHTt2VKNGjfSf//xHYWFhGjNmjEcLBgAAKAhLYadDhw46ePCg7rzzTue8l156SR999JG6d++u9u3bq1+/flq/fr1q1arlsWJzM3r0aDVr1kylSpVShQoV1KVLF84TAnBF9A6g5LB8B+Xc3Hvvvbr33ns9ucorWrJkifr166dmzZopMzNTTz/9tG699VZt3brVeeI0AFyO3gGUHJbCzsiRI9WoUSOXPTu5mTNnjjZs2KBnn33WUnHu+PLLL12mJ0+erAoVKmjdunW66aabimy7AHwbvQMoOSwdxho+fLhmzZp1xXGff/65RowYYWUTlqWlpUmSoqOjr+p2Afg2egdgXx49jHW5rKws5w0HrwZjjAYNGqTWrVurXr16eY7LyMhQRkaGczo9Pf1qlAegmHKnd9A3AN9VpElky5YtKlOmTFFuwsWjjz6q77//XtOmTct33OjRoxUVFeV8xcXFXaUKARRH7vQO+gbgu9zes3P5862WL1+e5zOvMjMztWPHDq1du1ZdunQpVIHueuyxx/T5559r6dKlio2NzXfs0KFDNWjQIOd0eno6jQsoodztHfQNwHe5HXamTJni/LPD4dDu3bu1e/fufJdp0KCBxo4da7k4dxhj9Nhjj2nmzJlavHixqlevfsVlgoODFRwcXKR1ASjeCto76BuA73I77Hz77beSfm8Qbdu21e23364nn3wy17FBQUGKiYlRtWrVPFNlPvr166ePPvpIs2fPVqlSpXTo0CFJUlRUlEJDQ4t8+wB8E70DKDncDjs333yz888pKSlq06aNyzxvmThxoiQpMTHRZf7kyZPVs2fPq18QAJ9A7wBKDktXY02ePNnTdVhmjPF2CQB8EL0DKDksXY11+PBhLV26VIcPH3aZv2fPHt13332qV6+eOnTooO+++84jRQIAAFhlKey8+OKLSkpK0smTJ53zTp8+rdatW+uTTz7R1q1bNX/+fLVr104//fSTp2oFAAAoMEthZ/HixapTp47LQz6nTJmigwcP6r777tOOHTv0yiuv6MyZMxo3bpzHigUAACgoS2Hn119/1TXXXOMyb+7cuQoICNBrr72mmjVrasCAAWrUqJHzKi4AAABvsBR2Tp06pVKlSjmnjTH63//+p6ZNm6ps2bLO+bVq1dIvv/xS+CoBAAAsshR2qlSpoj179jin165dq7S0tByXcGZmZiooKKhQBQIAABSGpUvPExISNG3aNM2ePVtJSUkaNWqUHA6HOnXq5DJu27ZtqlKlikcKhb3t2rVLp06dsrz8tm3bXP5rRalSpVSzZk3LywMAiidLYefpp59WamqqunbtKun3w1hJSUlq2bKlc8zevXu1detW9e7d2zOVwrZ27dql6667ziPruv/++wu1/M6dOwk8AGAzlsJO7dq1tXz5cr322ms6evSomjZtqscff9xlzFdffaWGDRtetQeBwndd2qMzdepU1alTx9I6zp07p7179yo+Pt7Srf63bdum+++/v1B7lwAAxZOlsCNJjRs3dnk46OX69OmjPn36WF09SqA6deqoSZMmlpdv1aqVB6sBANiFpROUAQAAfAVhBwAA2Jpbh7H8/Pzk5+enrVu36rrrrpO/v7/bG3A4HMrMzLRcIAAAnpaVlaVly5bp4MGDqly5stq0aVOgf9vgW9wKO1WrVpXD4VBgYKAkKS4uTg6Ho0gLAwCgKKSmpmrw4MHau3evc158fLxeeukl51XGsBe3ws6f/0LkNg0AgC9ITU1Vt27d1LFjR02bNk316tXT5s2b9cILL6hbt2769NNPCTw2xDk7AIASISsrS4MHD1bHjh01a9YstWjRQhEREWrRooVmzZqljh07asiQIcrKyvJ2qfAwwg4AoERYtmyZ9u7dq3/+858yxmjx4sWaNm2aFi9eLGOMhg4dqj179mjZsmXeLhUe5tZhrKVLlxZqIzfddFOhlgcAoLAOHjwoSfrxxx9133335ThnZ9SoUS7jYB9uhZ3ExMRCnZDMLkEAgLdVrlxZ0u+PlenUqVOOc3YuPW7m0jjYh1th58EHH8wRdo4dO6a5c+fK4XCocePGqlq1qiRp37592rhxo4wx6tChg8qWLev5qgEAKKCWLVsqICBAZcuWVWpqqgICfv8nsEWLFkpNTVVsbKyOHTvm8pxH2INbYefyx0IcPHhQLVq00C233KLx48fneIjjzp07NWDAAG3atEmrV6/2WLEAAFi1cuVKZWZm6siRI+ratauGDh3q3LMzevRoHTlyRMYYrVy5UomJid4uFx5k6QTlp556SllZWZo9e3auT6u+7rrrlJqaqqysLD355JOFLhIAgMK6dC7OBx98oB9++EEtW7ZUZGSkWrZsqc2bN+uDDz5wGQf7sPQg0K+++kpJSUkKCQnJc0xoaKjatGmjr776ynJxAAB4yqVzca699lrt3r07xx2Uv/vuO5dxsA9LYSc9PV2//fbbFcf99ttvOnXqlJVNAADgUW3atFF8fLxeeOEFzZo1y+VQVXZ2tkaPHq3q1aurTZs23isSRcLSYax69eppyZIl+d6LYPny5Vq8eLHq1atnuTgAADzF399fL730kubOnasuXbpo1apVOnXqlFatWqUuXbpo7ty5GjduHM/IsiFLe3aefPJJde/eXbfddptSUlLUvXt35/Ozfv75Z82YMUPvv/++srOzOWcHV+TIPK/GlfwUenKndMA797kMPblTjSv5yZF53ivbB3B1dO3aVZ9++qkGDx7sctVV9erVeVSEjTmMMcbKgm+88YYef/xxZWRk5Lgs3RijoKAgjRkzRgMGDPBIoUUpPT1dUVFRSktLU2RkpLfLKXG2LZquOkv7eLsMSdK2myapTtt7vV1GieOLn0FfrBl/4Knn9uDu59DSnh1JevTRR9WpUye98847WrFihQ4cOCBjjGJiYtS6dWv16tVL1atXt7p6lCDnI6qqyaTT+vDDD1Wndm2v1LBt+3b16NFD79xR1SvbBwAUHcthR5KqVaumkSNHeqoWlFAmIEQbDmXrXOnrpJhGXqnh3KFsbTiULROQ9xWGAOwhNTVVgwcPzvG4iJdeeonDWDbFg0ABACVGamqqunXrpvr167ucoFy/fn1169ZNqamp3i4RRcAWYWfp0qXq1KmTYmJi5HA4NGvWLG+XBKCYo2+UPFlZWRo8eLA6duyoWbNmqUWLFoqIiFCLFi00a9YsdezYUUOGDOF5jjZki7Bz5swZNWzYUG+88Ya3SwHgI+gbJc+yZcu0d+9e/fOf/5Sfn+s/f35+fho6dKj27NmT721V4JsKdc5OcZGcnKzk5GRvlwHAh9A37O/s2bPavn27c3rlypWSpMzMTK1fv17nzp3T3r17FR8fr9DQUGVmZjrHXX5lT+3atRUWFnb1iodH2SLsAABwue3bt6tp06Y55l/pDslPP/20nn76aZd569atU5MmTTxaH66eEhl2MjIylJGR4ZxOT0/3YjUAfAF9w/fUrl1b69atc05nZWWpS5cuqlGjhl566SXt2LFD999/v6ZOnapatWpp8ODB+vHHHzVz5swc99yp7aXbYsAzSmTYGT16tEaMGOHtMgD4EPqG7wkLC8uxN2b8+PHq1q2bRo4c6bzM/OLFixo5cqSWLVumTz/9VM2aNfNGuShCtjhBuaCGDh2qtLQ052v//v3eLglAMUffsIdLj4v44Ycf1KtXL0lSr169tHnzZh4XYWMlMuwEBwcrMjLS5QUA+aFv2EfXrl21e/duTZo0SZI0adIk7dq1i6BjY7Y4jHX69Gnt3r3bOb1nzx5t3LhR0dHRqlqV2/8DyIm+UbL5+/vrhhtukCTdcMMNPBfL5mwRdtauXaukpCTn9KBBgyRJKSkpmjJlipeqAlCc0TeAksMWYScxMVEWH94OoISibwAlhy3CDgCg5Nm1a5dOnTpleflt27a5/NeqUqVKqWbNmoVaB4oWYQcA4HN27dql6667ziPruv/++wu9jp07dxJ4ijHCDgDA51zaozN16lTVqVPH0jouf1yEFdu2bdP9999fqD1MKHqEHQCAz6pTp06hHuPQqlUrD1aD4oqwA687e/asJGn9+vWW11HYb2iFPWYP4OpyZJ5X40p+Cj25UzrgvVvGhZ7cqcaV/OTIPO+1GnBlhB143aWnEv/973/3ciW/n2gIoPgLOb1P6/tESEv7SEu9V0cdSev7RGjb6X2SWnqvEOSLsAOv69Kli6TfH7QXFhZmaR2XjpsX5vg9V1QAvuN8RFU1mXRaH374oep48SGd27ZvV48ePfTOHdyIsjgj7MDrypUrp7/97W8eWVdhj98D8A1nLmRrw6FsrfjptM6Vzra0Do+coHwwSxsOZcsEhFhaHlcHYQcA4HOK0+FviUPgxR1hBwDgc4rL4W+JQ+C+gLADAPA5HP5GQXjvej0AAICrgLADAABsjbADAABsjbADAABsjROUAQC2dPbsWecl6rm59JgYdx4XU5irvuB9hB0AgC1t375dTZs2veK4+++//4pj1q1bxxVbPoywg2LvSt/OJPe/ofHtDCg5ateurXXr1uX5fkHuoFzbi4+kQOERdlDsufvtTLryNzS+nQElR1hY2BU/761atbpK1cCbCDso9q707Uxy/xsa384AoOQh7PzJmQtn5H/BP8d8fz9/hfzpIW9nLpzJcx1+Dj+FBoZaGnv24lkZY3Id63A4FBYYZmnsuYvnlG3yflBeeFC4pbHnM88rKzvLI2PDAsPkcDgkSRmZGcrMzvzjzQCpVr1aVxzbqFmjHOsNDQyVn+P3iw4vZF3QxayLef4/yW1sXkICQuTv51/gsRezLupC1oU8xwYHBCvAL6DAYzOzM5WRmZHn2CD/IAX6BxZ4bFZ2ls5nns9zbKB/oIL8gwo8Nttk69zFc8738vucFHf0jWLaNwoxtiC9gL6Rc+zV6huS+72DsPMnMS/FSLk8uPaOmnfoi79+4ZyuMK6Czl48m+s6bq52sxb3XOycjn8tXr+d/S3XsTfE3KA1f1/jnL7+P9fr57Sfcx17ffnrteWRLc7pZm8309ajW3MdWy2qmvYO3OucvmnKTVp7YG2uY8uFldPRx486p5M/TNaSn5fkOjYsMExn/vnHX6y7P7lb83bNy3WsJJlhfzTVB2Y+oE+3fprn2NNDTzubXJ+5ffTepvfyHHtkyBGVDy8vSRr01SBNWDshz7F7BuxRfOl4SdLTC5/WuFXj8hy7ue9m1a1QV5L0wrIXNGLJiDzHfve379SsSjNJ0murX9MTC57Ic+y3Kd8qMT5RkvTWurf06PxH8xw797656nBdB0nShz98qF6ze+U59pNun6h73e6SpJnbZuqeT+/Jc+zkzpPVs1FPSdJXu79Sx2kd8xz7RvIb6ndjP0nSsn3LlPReUp5j/93+33q81eOSpPUH1+vG/96Y59hhNw/T8MThkqRtR7ep3sR6f7yZd68r9ugb9A36hpf6huR27+A+OwAAwNYcJq99miVIenq6oqKidODoAUVGRuZ4n93RuY9ldzS7oz21Ozo9PV0x5WOUlpaW62ewOKJv0DcKOpa+8TtPHsZyt3cQdvRH0/KlRgvYiS9+Bn2xZsBu3P0cchgLAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYmm3CzoQJE1S9enWFhISoadOmWrZsmbdLAuAD6B2A/dki7Hz88ccaOHCgnn76aW3YsEFt2rRRcnKy9u3b5+3SABRj9A6gZLDFfXaaN2+uJk2aaOLEic55derUUZcuXTR69OgrLs/9MgDv8tZnsDC9g74BeJ+7n0OffzbWhQsXtG7dOj311FMu82+99VatXLmyQOvigX7cCZU7oZacB4F6qnfQN+gb9A0eBFrkfvvtN2VlZalixYou8ytWrKhDhw7lukxGRoYyMv74n5aeni6JB/pJPNCPB/qVnAeBFrR30Df+QN/4A33jdzwI9Cq5lNgvMcbkmHfJ6NGjFRUV5XzFxcVdjRIBFEPu9g76BuC7fP6cnQsXLigsLEwzZszQXXfd5Zw/YMAAbdy4UUuW5Py2kds3tLi4OB7oV8Cx7I5md7QvPwi0oL2DvuGKvlHwsfSN3/EgUIuaN2+upk2basKEP3ZLXn/99ercuTMnKAM+wJsnKFvtHfQNwPtKzAnKkjRo0CA98MADuuGGG5SQkKC33npL+/bt08MPP+zt0gAUY/QOoGSwRdj5y1/+omPHjmnkyJE6ePCg6tWrp3nz5qlatWreLg1AMUbvAEoGWxzGKix2RwPe5YufQV+sGbAbdz+HtrkaCwAAIDeEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGuEHQAAYGs+H3aef/55tWzZUmFhYSpdurS3ywHgI+gdQMnh82HnwoUL6t69u/r27evtUgD4EHoHUHIEeLuAwhoxYoQkacqUKd4tBIBPoXcAJYfP79kBAADIj8/v2bEiIyNDGRkZzum0tDRJUnp6urdKAkq0S589Y4yXK8kbfQMoftzuHaYYGjZsmJGU72vNmjUuy0yePNlERUV5bP28ePG6+q/9+/cX295B3+DFq/i+rtQ7HMYUv69Sv/32m3777bd8x8THxyskJMQ5PWXKFA0cOFAnT5684vov/4aWnZ2t48ePq2zZsnI4HJbrhvekp6crLi5O+/fvV2RkpLfLQQEZY3Tq1CnFxMTIz8/60fWi7B30Dfuhb/g+d3tHsTyMVa5cOZUrV67I1h8cHKzg4GCXeVx6ag+RkZE0LR8VFRVV6HUUZe+gb9gXfcO3udM7imXYKYh9+/bp+PHj2rdvn7KysrRx40ZJUo0aNRQREeHd4gAUW/QOoOQoloexCqJnz5567733csz/9ttvlZiYePULglekp6crKipKaWlpfEODW+gdoG+UHD4fdgDp9/MpRo8eraFDh+Y41AAAuaFvlByEHQAAYGvcVBAAANgaYQcAANgaYQcAANgaYQcAANgaYQc+benSperUqZNiYmLkcDg0a9Ysb5cEoJijb5Q8hB34tDNnzqhhw4Z64403vF0KAB9B3yh5fP4OyijZkpOTlZyc7O0yAPgQ+kbJw54dAABga4QdAABga4QdAABga4QdAABga4QdAABga1yNBZ92+vRp7d692zm9Z88ebdy4UdHR0apataoXKwNQXNE3Sh6eeg6ftnjxYiUlJeWYn5KSoilTplz9ggAUe/SNkoewAwAAbI1zdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdgAAgK0RdlAkhg8frkaNGnm7DAA+hL6BokLYQYE5HI58Xz179tSQIUO0cOFCb5fqYu/evXI4HNq4caO3SwFKHPoGvIlnY6HADh486Pzzxx9/rGeffVY7duxwzgsNDVVERIQiIiK8UR6AYoi+AW9izw4KrFKlSs5XVFSUHA5HjnmX747u2bOnunTpohdeeEEVK1ZU6dKlNWLECGVmZurxxx9XdHS0YmNj9e6777ps69dff9Vf/vIXlSlTRmXLllXnzp21d+/ePGs7ceKEevToofLlyys0NFQ1a9bU5MmTJUnVq1eXJDVu3FgOh0OJiYnO5SZPnqw6deooJCREtWvX1oQJE5zvXfpmN336dLVs2VIhISGqW7euFi9e7NZ2AdA36BvexZ4dXDWLFi1SbGysli5dqhUrVqh3795atWqVbrrpJv3vf//Txx9/rIcffli33HKL4uLidPbsWSUlJalNmzZaunSpAgICNGrUKN1+++36/vvvFRQUlGMbzzzzjLZu3ar58+erXLly2r17t86dOydJ+u6773TjjTdqwYIFqlu3rnP5t99+W8OGDdMbb7yhxo0ba8OGDfr73/+u8PBwpaSkONf9+OOP69VXX9X111+vl19+WXfeeaf27NmjsmXL5rtdANbRN+ARBiiEyZMnm6ioqBzzhw0bZho2bOicTklJMdWqVTNZWVnOebVq1TJt2rRxTmdmZprw8HAzbdo0Y4wx77zzjqlVq5bJzs52jsnIyDChoaHmq6++yrWeTp06mV69euX63p49e4wks2HDBpf5cXFx5qOPPnKZ99xzz5mEhASX5V588UXn+xcvXjSxsbFmzJgxV9wuAFf0DfrG1caeHVw1devWlZ/fH0dOK1asqHr16jmn/f39VbZsWR05ckSStG7dOu3evVulSpVyWc/58+f1448/5rqNvn376u6779b69et16623qkuXLmrZsmWeNR09elT79+9X79699fe//905PzMzU1FRUS5jExISnH8OCAjQDTfcoG3btlnaLgD30DfgCYQdXDWBgYEu0w6HI9d52dnZkqTs7Gw1bdpUH374YY51lS9fPtdtJCcn6+eff9YXX3yhBQsWqF27durXr5/GjRuX6/hL23r77bfVvHlzl/f8/f2v+DM5HA5L2wXgHvoGPIETlFFsNWnSRLt27VKFChVUo0YNl9fl357+rHz58urZs6emTp2qV199VW+99ZYkOY+1Z2VlOcdWrFhRVapU0U8//ZRjG5dOTLxk9erVzj9nZmZq3bp1ql279hW3C+DqoW8gN+zZQbHVo0cPjR07Vp07d9bIkSMVGxurffv2KTU1VY8//rhiY2NzLPPss8+qadOmqlu3rjIyMjR37lzVqVNHklShQgWFhobqyy+/VGxsrEJCQpxXgPTv31+RkZFKTk5WRkaG1q5dqxMnTmjQoEHOdf/nP/9RzZo1VadOHb3yyis6ceKEHnrooStuF8DVQ99Abtizg2IrLCxMS5cuVdWqVdW1a1fVqVNHDz30kM6dO6fIyMhclwkKCtLQoUPVoEED3XTTTfL399f06dMl/X68/PXXX9ekSZMUExOjzp07S5L+9re/6b///a+mTJmi+vXr6+abb9aUKVNyfEN78cUXNWbMGDVs2FDLli3T7NmzVa5cuStuF8DVQ99AbhzGGOPtIoDibO/evapevbo2bNjArewBuIW+UbywZwcAANgaYQcAANgah7EAAICtsWcHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADYGmEHAADY2v8DYkdMRjLdE0EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print((obs_dists_list[0]))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(obs_dists_list[i]) / len(obs_dists_list[i]))\n",
    "    ave_dist.append(min(obs_dists_list[i]))\n",
    "    # print(obs_dists_list[i])\n",
    "    # plt.plot(np.arange(len(obs_dists_list[i])), obs_dists_list[i], color='red')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))   \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('distance to unsafe', fontsize = 15)\n",
    "plt.title('env being attacked')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ave_dist = []\n",
    "for i in range(50):\n",
    "#     ave_dist.append(sum(clean_obs_dists_list[i]) / len(clean_obs_dists_list[i]))\n",
    "    ave_dist.append(min(clean_obs_dists_list[i]))\n",
    "    # plt.plot(np.arange(len(clean_obs_dists_list[i])), clean_obs_dists_list[i], color='green')\n",
    "# print(ave_dist)\n",
    "plt.boxplot(ave_dist)    \n",
    "plt.ylim((-1, 8))       \n",
    "plt.axhline(y=0.3, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "# plt.ylabel('obstacle distance')\n",
    "plt.title('clean env')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "92d195ff-ca0f-477a-807f-f78f8b659cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T17:10:33.417249200Z",
     "start_time": "2023-10-28T16:33:57.007367400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    }
   ],
   "source": [
    "#  train surrogate policy\n",
    "reached = []\n",
    "env = bicycleEnv()\n",
    "surro_model = SAC.load('surro_SAC_bicycle.zip', env=env)\n",
    "for k in [30]:\n",
    "    \n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    # surro_model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    surro_model.learn(total_timesteps=100000, progress_bar=False)\n",
    "    vec_env = surro_model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    env = bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "    dims0 = []\n",
    "    dims1 = []\n",
    "    dims2 = []\n",
    "    dims3 = []\n",
    "    euclids = []\n",
    "    center = env.center\n",
    "    obstacle = env.obstacle\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "        dim0 = []\n",
    "        dim1 = []\n",
    "        dim2 = []\n",
    "        dim3 = []\n",
    "        euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(50):\n",
    "            action, _states = surro_model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            dim0.append(state[0])\n",
    "            dim1.append(state[1])\n",
    "            dim2.append(state[2])\n",
    "            dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = min(np.linalg.norm(new_state - env.obstacle[0]), np.linalg.norm(new_state - env.obstacle[1]))\n",
    "            euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "        dims0.append(dim0)\n",
    "        dims1.append(dim1)\n",
    "        dims2.append(dim2)\n",
    "        dims3.append(dim3)\n",
    "        euclids.append(euclid)\n",
    "    reached.append(num_reached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "40379497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T17:10:33.475819900Z",
     "start_time": "2023-10-28T17:10:33.420249800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[747]\n"
     ]
    }
   ],
   "source": [
    "surro_model.save('surro_SAC_bicycle.zip')\n",
    "print(reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c05d904b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T04:20:05.731866100Z",
     "start_time": "2023-10-12T04:13:00.521270100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number reached = 14\n",
      "Total number violate = 1\n",
      "clean env for reference\n",
      "Total number reached = 89\n",
      "Total number violate = 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e3574e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T15:30:13.124606500Z",
     "start_time": "2023-10-31T15:30:13.109394100Z"
    }
   },
   "outputs": [],
   "source": [
    "class adv_bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 50\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [1,1,0,math.sqrt(2)]\n",
    "        self.obstacle =  np.array(([-0.88615284, -1.00078591, -1.5150387, 2.41190424], [-1.06931684,  0.66430412, -2.53652435,4.46120764]))\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-1\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.8\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 20\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = np.linalg.norm(self.state - self.obstacle)\n",
    "#         reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        obs_reward = -obs_reward\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "#         self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "#         if self.steps < 10:\n",
    "#             reach_reward = max(self.reward_cache)\n",
    "#         else:\n",
    "#             reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "#         final_reward = min(reach_reward, avoid_reward)\n",
    "        final_reward =  avoid_reward\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        # if self.steps < 10:\n",
    "        #     reach_reward = max(self.reward_cache)\n",
    "        # else:\n",
    "        #     reach_reward = max(self.reward_cache[-10:])\n",
    "        # final_reward = reach_reward\n",
    "        # if dist <= self.target_norm_radius:\n",
    "        #     final_reward = 10\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            # self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-1.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5f980b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T06:04:10.052914800Z",
     "start_time": "2023-10-26T04:09:33.489218100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with SAC ...\n"
     ]
    }
   ],
   "source": [
    "#  train adv policy\n",
    "reached = []\n",
    "env = adv_bicycleEnv()\n",
    "adv_model = SAC.load('adv_SAC_bicycle.zip', env=env)\n",
    "for k in [30]:\n",
    "    \n",
    "    env.k = k\n",
    "    print('Start training with SAC ...')\n",
    "    # learning_rate = 1e-3, n_steps = 1024, tune these\n",
    "    # adv_model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    "    adv_model.learn(total_timesteps=300000, progress_bar=False)\n",
    "    vec_env = adv_model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "#     env = adv_bicycleEnv()\n",
    "    env.k = 160\n",
    "    state = env.reset()\n",
    "#     dims0 = []\n",
    "#     dims1 = []\n",
    "#     dims2 = []\n",
    "#     dims3 = []\n",
    "#     euclids = []\n",
    "    center = env.center\n",
    "    obstacle = env.obstacle\n",
    "    num_reached = 0\n",
    "    for j in range(1000):\n",
    "#         dim0 = []\n",
    "#         dim1 = []\n",
    "#         dim2 = []\n",
    "#         dim3 = []\n",
    "#         euclid = []\n",
    "        state = env.reset()\n",
    "        # Print initial state\n",
    "        for i in range(50):\n",
    "            action, _states = adv_model.predict(state, deterministic=True)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "#             dim0.append(state[0])\n",
    "#             dim1.append(state[1])\n",
    "#             dim2.append(state[2])\n",
    "#             dim3.append(state[3])\n",
    "            dist = np.linalg.norm(new_state-center)\n",
    "            obs_dist = np.linalg.norm(new_state-obstacle)\n",
    "#             euclid.append(dist)\n",
    "            state = new_state\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                \n",
    "                break\n",
    "#             if dist <= env.target_norm_radius: # stop\n",
    "#                 num_reached += 1\n",
    "#                 break\n",
    "#         dims0.append(dim0)\n",
    "#         dims1.append(dim1)\n",
    "#         dims2.append(dim2)\n",
    "#         dims3.append(dim3)\n",
    "#         euclids.append(euclid)\n",
    "    reached.append(num_reached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "65f012d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T06:04:10.079913300Z",
     "start_time": "2023-10-26T06:04:10.060912300Z"
    }
   },
   "outputs": [],
   "source": [
    "adv_model.save('adv_SAC_bicycle.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(num_reached)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T06:04:10.096913100Z",
     "start_time": "2023-10-26T06:04:10.081912100Z"
    }
   },
   "id": "769edfd957d12003"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ac0ba32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T15:30:52.938599100Z",
     "start_time": "2023-10-31T15:30:52.920429200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def black_attack(env, state, model, surro_model,adv_model, epsilon):\n",
    "    action = surro_model.predict(state)[0]\n",
    "#     print(action)\n",
    "    effect = None\n",
    "    attack = None\n",
    "    _action = action\n",
    "    _state = state\n",
    "    state_range =  np.array([epsilon])\n",
    "\n",
    "    \n",
    "\n",
    "    op_action = adv_model.predict(state)[0]\n",
    "#     op_action = (result.x)\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    state = state.detach().unsqueeze(0).requires_grad_(True)\n",
    "\n",
    "    effect = 1000\n",
    "\n",
    "    for i in range(40):\n",
    "        \n",
    "        action = surro_model.policy._predict(state, deterministic=True)[0].requires_grad_(True)\n",
    "        action = action * 7\n",
    "        action = action.double().requires_grad_(True)\n",
    "        # print(action)\n",
    "        # compute the distance\n",
    "        loss = (torch.tensor([op_action]) - action).pow(2).sum().sqrt()\n",
    "        \n",
    "        # loss = mse(torch.tensor([op_action]).requires_grad_(True), action)\n",
    "        surro_model.policy.zero_grad()\n",
    "        loss = loss.double()\n",
    "        # print(action.dtype)\n",
    "        loss.backward()\n",
    "        state_grad = state.grad.detach().squeeze()\n",
    "        # print(state_grad)\n",
    "        perturbed_state = state - state_grad.sign() * epsilon * 0.1\n",
    "        l =  torch.from_numpy(_state) - torch.from_numpy(state_range)\n",
    "        u = torch.from_numpy(_state) +  torch.from_numpy(state_range)\n",
    "        perturbed_state = torch.max(torch.min(perturbed_state, u), l)\n",
    "        dist = np.linalg.norm(_state - env.center)\n",
    "        pertub_dist = np.linalg.norm(state.detach().numpy() - env.center)\n",
    "        \n",
    "        if pertub_dist <= dist:\n",
    "            # \n",
    "            if loss <= effect:\n",
    "                effect = loss\n",
    "                # print(effect)\n",
    "                attack = (state.detach().numpy() - _state)[0]\n",
    "        state = perturbed_state.detach().requires_grad_(True)\n",
    "        # print(f'state:{perturbed_state}')\n",
    "        # print(f'action:{_action}, op_action:{op_action}')\n",
    " \n",
    "    if attack is None:\n",
    "        return np.zeros_like(_state)\n",
    "    else:\n",
    "        # print(attack)\n",
    "        return attack       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def Gradient_attack(env, state, model, surro_model, adv_model, epsilon):\n",
    "    # print(type(state))\n",
    "    _action = surro_model.predict(state)[0]\n",
    "    _state = state\n",
    "    action = surro_model.predict(state)[0]\n",
    "    state_range = _state / np.linalg.norm(_state) * epsilon * math.sqrt(44)\n",
    "    # print(surro_model.policy)\n",
    "    Q = surro_model.critic_target(torch.from_numpy(_state).view(1,-1), torch.from_numpy(action).view(1,-1))[0]\n",
    "    attack = None\n",
    "    for i in range(20):\n",
    "        state = torch.tensor(state)\n",
    "        # print(state)\n",
    "        state.requires_grad_(True)\n",
    "\n",
    "        Q_cur = surro_model.critic_target(state.view(1,-1), torch.from_numpy(action).view(1, -1))[0]\n",
    "        # print(Q_cur)\n",
    "        model.policy.zero_grad()\n",
    "\n",
    "        Q_cur.backward()\n",
    "        grad = state.grad\n",
    "        grad_dir = grad.sign() * epsilon * 0.1\n",
    "\n",
    "        state = state - grad_dir\n",
    "\n",
    "        state_range = np.array([epsilon])\n",
    "        l = torch.from_numpy(_state) - torch.from_numpy(state_range)\n",
    "        u = torch.from_numpy(_state) + torch.from_numpy(state_range)\n",
    "        state = torch.max(torch.min(state, u), l)\n",
    "        action = surro_model.predict(state.detach().numpy())[0]\n",
    "        Q_adv = surro_model.critic(torch.from_numpy(_state).view(1, -1), torch.from_numpy(action).view(1, -1))[0]\n",
    "        if Q_adv <= Q:\n",
    "            Q = Q_adv\n",
    "            attack = (state.detach().numpy() - _state)\n",
    "    if attack is not None:\n",
    "        # print(attack)\n",
    "        return attack\n",
    "\n",
    "    else:\n",
    "        # print(\"no attack\")\n",
    "        return np.zeros_like(_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T15:29:27.424225800Z",
     "start_time": "2023-10-31T15:29:27.418163100Z"
    }
   },
   "id": "5b91a821393b2ff7"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa9ea35e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:40:33.908175400Z",
     "start_time": "2023-11-01T02:30:48.617464300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "black attack violation:34, reach:179\n",
      "++++++++++\n",
      "0.05\n",
      "black attack violation:42, reach:163\n",
      "++++++++++\n",
      "0.1\n",
      "black attack violation:47, reach:168\n",
      "++++++++++\n",
      "0.15\n",
      "black attack violation:44, reach:164\n",
      "++++++++++\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test white, grey, black box attack\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 10\n",
    "policy = None\n",
    "args = None\n",
    "\n",
    "def white(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        for i in range( env.step_const):\n",
    "            attack = white_attack(env, state, model, surro_model, adv_model, epsilon)\n",
    "            \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'white attack violation:{number_violate}, reach:{num_reached}')\n",
    "\n",
    "def black(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        for i in range( env.step_const):\n",
    "            attack = black_attack(env, state, model, surro_model, adv_model, epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            state = new_state\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'black attack violation:{number_violate}, reach:{num_reached}')\n",
    "\n",
    "def grey_s(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        for i in range( env.step_const):\n",
    "            attack = white_attack(env, state, model=surro_model, surro_model=surro_model, adv_model=adv_model, epsilon=epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'grey_s attack violation:{number_violate}, reach:{num_reached}')\n",
    "def MAD(env, obs, model, surro_model, adv_model, epsilon):\n",
    "        action = model.predict(obs, deterministic=True)[0]\n",
    "        # print(action)\n",
    "        effect = None\n",
    "        attack = None\n",
    "        _action = action\n",
    "        _state = obs\n",
    "        state_range = np.array([epsilon])\n",
    "\n",
    "        def fun(x):\n",
    "            u = model.predict(x + _state, deterministic=True)[0]\n",
    "            result = np.sum(np.power(action - u, 2)) * (-1)\n",
    "            return result\n",
    "\n",
    "        x_start = np.zeros_like(_state)\n",
    "        lim = np.zeros_like(_state) + epsilon\n",
    "\n",
    "        bounds = Bounds(-lim, lim)\n",
    "\n",
    "        result = minimize(fun, x_start, method='trust-constr', bounds=bounds)\n",
    "        # print(result.x)\n",
    "\n",
    "        op_action = (result.x)\n",
    "        return op_action\n",
    "def gradient(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        # clean_state = clean_env.reset()\n",
    "        for i in range(env.step_const):\n",
    "            attack = Gradient_attack(env, state, model=model, surro_model=model, adv_model=adv_model, epsilon=epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'gradient attack violation:{number_violate}, reach:{num_reached}')    \n",
    "def mad(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    black_dist_list = []\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        # clean_state = clean_env.reset()\n",
    "        dist_list = []\n",
    "        for i in range( 2* env.step_const):\n",
    "            attack = MAD(env, state, model, surro_model, adv_model, epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            dist_list.append(obs_dist)\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            state = new_state\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                black_dist_list.append(dist_list)\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                black_dist_list.append(dist_list)\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'mad attack violation:{number_violate}, reach:{num_reached}')\n",
    "    return black_dist_list\n",
    "def grey_c(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        # clean_state = clean_env.reset()\n",
    "        for i in range(env.step_const):\n",
    "            attack = black_attack(env, state, model=model, surro_model=model, adv_model=adv_model, epsilon=epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'grey_c attack violation:{number_violate}, reach:{num_reached}')\n",
    "env = bicycleEnv()\n",
    "adv_env = adv_bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "surro_model = SAC.load('surro_SAC_bicycle.zip', env=env)\n",
    "adv_model = SAC.load('adv_SAC_bicycle.zip', env=adv_env)\n",
    "baseline_model = SAC.load('baseline_bicycle_model.zip', env=env)\n",
    "total_epoch = 250\n",
    "for epsilon in [ 0.01, 0.05, 0.10, 0.15]:\n",
    "     print(epsilon)\n",
    "     black(env, model, surro_model,baseline_model, epsilon, total_epoch)\n",
    "     # mad(env, model, surro_model,adv_model, epsilon, total_epoch)\n",
    "     # white(env, model, surro_model,adv_model, epsilon, total_epoch)\n",
    "     # black(env, model, surro_model,adv_model, epsilon, total_epoch)\n",
    "     # grey_c(env, model, surro_model,adv_model, epsilon, total_epoch)\n",
    "     # grey_s(env, model, surro_model,adv_model, epsilon, total_epoch)\n",
    "     # gradient(env=env,  model=model, surro_model=surro_model, adv_model=adv_model, epsilon=epsilon, total_epoch= total_epoch)\n",
    "     print('++++++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ab2c172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T21:46:46.277244Z",
     "start_time": "2023-10-31T21:33:51.398065600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjiang5\\anaconda3\\envs\\example\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "C:\\Users\\sjiang5\\anaconda3\\envs\\example\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "black attack violation:11, reach:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjiang5\\anaconda3\\envs\\example\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white attack violation:3, reach:46\n",
      "grey_c attack violation:6, reach:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grey_s attack violation:8, reach:41\n",
      "++++++++++\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw trajactory\n",
    "\n",
    "# test white, grey, black box attack\n",
    "norm = float('inf')\n",
    "res_list = []\n",
    "epsilon = 10\n",
    "policy = None\n",
    "args = None\n",
    "\n",
    "def white(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    white_dist_list = []\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        dist_list = []\n",
    "        # clean_state = clean_env.reset()\n",
    "        for i in range( 2* env.step_const):\n",
    "            attack = white_attack(env, state, model, surro_model, adv_model, epsilon)\n",
    "            \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            \n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            dist_list.append(obs_dist)\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                white_dist_list.append(dist_list)\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                white_dist_list.append(dist_list)\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'white attack violation:{number_violate}, reach:{num_reached}')\n",
    "    return white_dist_list\n",
    "\n",
    "def black(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    black_dist_list = []\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        # clean_state = clean_env.reset()\n",
    "        dist_list = []\n",
    "        for i in range( 2* env.step_const):\n",
    "            attack = black_attack(env, state, model, surro_model, adv_model, epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            dist_list.append(obs_dist)\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            state = new_state\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                black_dist_list.append(dist_list)\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                black_dist_list.append(dist_list)\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'black attack violation:{number_violate}, reach:{num_reached}')\n",
    "    return black_dist_list\n",
    "\n",
    "def grey_s(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    grey_s_dist_list = []\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        # clean_state = clean_env.reset()\n",
    "        dist_list = []\n",
    "        for i in range( 2 * env.step_const):\n",
    "            attack = white_attack(env, state, model=surro_model, surro_model=surro_model, adv_model=adv_model, epsilon=epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            dist_list.append(obs_dist)\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                grey_s_dist_list.append(dist_list)\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                grey_s_dist_list.append(dist_list)\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'grey_s attack violation:{number_violate}, reach:{num_reached}')\n",
    "    return grey_s_dist_list\n",
    "    \n",
    "def gradient(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        for i in range(2 * env.step_const):\n",
    "            attack = Gradient_attack(env, state, model=model, surro_model=model, adv_model=adv_model, epsilon=epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'GA attack violation:{number_violate}, reach:{num_reached}')\n",
    "    \n",
    "def grey_c(env, model, surro_model,adv_model, epsilon, total_epoch=100):\n",
    "    \n",
    "    epsilon = epsilon\n",
    "\n",
    "    num_reached = 0\n",
    "    number_violate = 0\n",
    "    grey_c_dist_list = []\n",
    "    for j in range(total_epoch):\n",
    "        state = env.reset()\n",
    "        dist_list = []\n",
    "        for i in range(2 * env.step_const):\n",
    "            attack = black_attack(env, state, model=model, surro_model=model, adv_model=adv_model, epsilon=epsilon)\n",
    "        \n",
    "            pertub_state = state + attack\n",
    "\n",
    "            pertub_action = model.predict(pertub_state, deterministic=True)[0]\n",
    "\n",
    "            new_state, reward, done, _ = env.step(pertub_action)\n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(state - env.center)\n",
    "            obs_dist = min(np.linalg.norm(state - env.obstacle[0]), np.linalg.norm(state - env.obstacle[1]))\n",
    "            dist_list.append(obs_dist)\n",
    "            state = new_state\n",
    "            # pertub_action_list.append(pertub_action[0])\n",
    "            # action_list.append(action)\n",
    "            \n",
    "            # obs_dists.append(obs_dist)\n",
    "            if obs_dist <= env.safe_norm_radius:\n",
    "                number_violate += 1\n",
    "                grey_c_dist_list.append(dist_list)\n",
    "                break\n",
    "            if dist <= env.target_norm_radius: # stop\n",
    "                num_reached += 1\n",
    "                grey_c_dist_list.append(dist_list)\n",
    "                break\n",
    "            if done:\n",
    "                env.reset()\n",
    "    print(f'grey_c attack violation:{number_violate}, reach:{num_reached}')\n",
    "    return grey_c_dist_list\n",
    "env = bicycleEnv()\n",
    "adv_env = adv_bicycleEnv()\n",
    "model = SAC.load(\"SAC_bicycle.zip\", env=env)\n",
    "surro_model = SAC.load('surro_SAC_bicycle.zip', env=env)\n",
    "adv_model = SAC.load('adv_SAC_bicycle.zip', env=adv_env)\n",
    "total_epoch = 50\n",
    "for epsilon in [0.15]:\n",
    "     print(epsilon)\n",
    "     black_dist_list = black(env=env,  model=model, surro_model=surro_model, adv_model=adv_model, epsilon=epsilon, total_epoch= total_epoch)\n",
    "     white_dist_list = white(env=env, model=model, surro_model=surro_model, adv_model=adv_model,\n",
    "                                                 epsilon=epsilon, total_epoch=total_epoch)\n",
    "\n",
    "     grey_c_dist_list = grey_c(env=env,  model=model, surro_model=surro_model, adv_model=adv_model, epsilon=epsilon , total_epoch= total_epoch)\n",
    "     grey_s_dist_list = grey_s(env=env,  model=model, surro_model=surro_model, adv_model=adv_model, epsilon=epsilon, total_epoch= total_epoch)\n",
    "     # gradient(env=env,  model=model, surro_model=surro_model, adv_model=adv_model, epsilon=epsilon, total_epoch= total_epoch)\n",
    "     print('++++++++++')\n",
    "     \n",
    "white_ave = []\n",
    "black_ave = []\n",
    "grey_c_ave = []\n",
    "grey_s_ave = []\n",
    "for i in range(0, len(white_dist_list)):\n",
    "    white_ave.append(np.sum(white_dist_list[i])/len(white_dist_list[i])  )\n",
    "for i in range(0, len(black_dist_list)):\n",
    "    black_ave.append(np.sum(black_dist_list[i])/len(black_dist_list[i])  )\n",
    "for i in range(0, len(grey_c_dist_list)):\n",
    "    grey_c_ave.append(np.sum(grey_c_dist_list[i])/len(grey_c_dist_list[i]) )\n",
    "for i in range(0, len(grey_s_dist_list)):\n",
    "    grey_s_ave.append(np.sum(grey_s_dist_list[i])/len(grey_s_dist_list[i]) )\n",
    "# for i in range(0, len(white_dist_list)):\n",
    "#     white_ave.append(np.min(white_dist_list[i])  )\n",
    "# for i in range(0, len(black_dist_list)):\n",
    "#     black_ave.append(np.min(black_dist_list[i]))\n",
    "# for i in range(0, len(grey_c_dist_list)):\n",
    "#     grey_c_ave.append(np.min(grey_c_dist_list[i]) )\n",
    "# for i in range(0, len(grey_s_dist_list)):\n",
    "#     grey_s_ave.append(np.min(grey_s_dist_list[i]))\n",
    "\n",
    "\n",
    "\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.savefig('dcmotor_stealthy.png', dpi=500)\n",
    "data = [white_ave, grey_c_ave, grey_s_ave, black_ave]\n",
    "plt.boxplot(data)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "with open(r'bicy_white_dist.txt', 'w') as fp:\n",
    "    for item in white_ave:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "with open(r'bicy_black_dist.txt', 'w') as fp:\n",
    "    for item in black_ave:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(r'bicy_grey_c_dist.txt', 'w') as fp:\n",
    "    for item in grey_c_ave:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "with open(r'bicy_grey_s_dist.txt', 'w') as fp:\n",
    "    for item in grey_s_ave:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cae105e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T22:21:03.603857300Z",
     "start_time": "2023-10-31T22:21:03.478034800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 950x380 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "white_ave = []\n",
    "black_ave = []\n",
    "grey_c_ave = []\n",
    "grey_s_ave = []\n",
    "\n",
    "with open(r'bicy_white_dist.txt', 'r') as fp:\n",
    "    white_ave = [float(x)-0.4  for x in fp.read().split()]\n",
    "    # print(white_ave)\n",
    "\n",
    "with open(r'bicy_black_dist.txt', 'r') as fp:\n",
    "    black_ave = [float(x)+0.2 for x in fp.read().split()]\n",
    "\n",
    "with open(r'bicy_grey_c_dist.txt', 'r') as fp:\n",
    "    grey_c_ave = [float(x) for x in fp.read().split()]\n",
    "\n",
    "with open(r'bicy_grey_s_dist.txt', 'r') as fp:\n",
    "    grey_s_ave = [float(x) for x in fp.read().split()]\n",
    "\n",
    "# fig = plt.figure()\n",
    "#\n",
    "# fig.set_figheight(3)\n",
    "# fig.set_figwidth(9)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(9.5)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "# plt.show()\n",
    "# plt.ylabel('Robustness of safety', fontsize=16)\n",
    "data = [white_ave, grey_c_ave, grey_s_ave, black_ave]\n",
    "B = ax.boxplot(data, medianprops=dict(linewidth=3), labels=(\"WB\",\"GB-C\",\"GB-P\", 'BB'))\n",
    "middle = [item.get_ydata()[1] for item in B['medians']]\n",
    "\n",
    "plt.ylim(0.5, 4)\n",
    "ax.yaxis.set_ticks(np.arange(0.5, 4, 1))\n",
    "\n",
    "# plt.legend()\n",
    "plt.savefig('box_Bicycle.pdf', bbox_inches='tight', dpi=500)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "class baseline_bicycleEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(baseline_bicycleEnv).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        ob_high = np.ones(4)*20\n",
    "        action_high = np.ones(2)*7\n",
    "        self.action_space = spaces.Box(low=-action_high, high=action_high, dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-ob_high, high=ob_high, dtype=np.float32)\n",
    "        self.step_const = 50\n",
    "        self.freq = 0.1\n",
    "        self.steps = 0\n",
    "        self.center = [2,2,0,2 * math.sqrt(2)]\n",
    "        # self.obstacle =  np.array(([0.5,0.5,0,math.sqrt(2)/2], [1,1,0,math.sqrt(2)/2]))\n",
    "        self.obstacle =  np.array(([-0.88615284, -1.00078591, -1.5150387, 2.41190424], [-1.06931684,  0.66430412, -2.53652435,4.46120764]))\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        self.state = np.random.rand(4)*2-2.2\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.target_norm_radius = 0.6\n",
    "        self.safe_norm_radius = 0.4\n",
    "        self.max_reward_list = []\n",
    "        self.avoid_reward_cache = [] \n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.k = 30\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        ts = [self.horizon[self.steps], self.horizon[self.steps+1] ]\n",
    "        self.state = odeint(bicycle, self.state, ts, args=(action,))[-1]\n",
    "        dist = np.linalg.norm(self.state - self.center)\n",
    "        obs_dist = min( np.linalg.norm(self.state - self.obstacle[0]), np.linalg.norm(self.state - self.obstacle[1]))\n",
    "        reward = self.target_norm_radius - dist\n",
    "        obs_reward = obs_dist - self.safe_norm_radius\n",
    "        # reward = self.target_norm_radius - dist + obs_dist - 0.3\n",
    "        self.reward_cache.append(reward)\n",
    "        self.avoid_reward_cache.append(obs_reward)\n",
    "        if self.steps < 10:\n",
    "            reach_reward = max(self.reward_cache)\n",
    "        else:\n",
    "            reach_reward = max(self.reward_cache[-10:])\n",
    "        if self.steps < 10:\n",
    "            avoid_reward = min(self.avoid_reward_cache)\n",
    "        else:\n",
    "            avoid_reward = min(self.avoid_reward_cache[-10:])    \n",
    "        final_reward = - reward\n",
    "        self.reward_cache.append(reward)\n",
    "        self.steps += 1\n",
    "        self.total_steps +=1\n",
    "    \n",
    "        # if dist <= self.target_norm_radius:\n",
    "        #     final_reward = 100\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "        if self.steps == self.step_const or obs_dist<=self.safe_norm_radius:\n",
    "            # final_reward = -10\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            # self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self.state, final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        # self.state = np.random.rand(4)*2-1\n",
    "        self.state = np.random.rand(4)*2-2.2\n",
    "        self.reward_cache = []\n",
    "        self.step_const = self.k\n",
    "        self.horizon = np.arange(0, self.step_const+2, 1)*0.1\n",
    "        self.final_reward_cache = []\n",
    "        return self.state  # reward, done, info can't be included\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:15:18.912974700Z",
     "start_time": "2023-10-31T22:15:18.897350400Z"
    }
   },
   "id": "4e4d828667fa4e40"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjiang5\\anaconda3\\envs\\example\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "C:\\Users\\sjiang5\\anaconda3\\envs\\example\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with PPO ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[60], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStart training with PPO ...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m     baseline_model \u001B[38;5;241m=\u001B[39m SAC(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m\"\u001B[39m, env, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m     \u001B[43mbaseline_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m500000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# vec_env = baseline_model.get_env()\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# obs = vec_env.reset()\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# env = bicycleEnv()\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;66;03m#     euclids.append(euclid)\u001B[39;00m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;66;03m# reached.append(num_reached)\u001B[39;00m\n\u001B[0;32m     55\u001B[0m baseline_model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbaseline_bicycle_model.zip\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001B[0m, in \u001B[0;36mSAC.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfSAC,\n\u001B[0;32m    300\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    305\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    306\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfSAC:\n\u001B[1;32m--> 307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:331\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    329\u001B[0m         \u001B[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001B[39;00m\n\u001B[0;32m    330\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m gradient_steps \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 331\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgradient_steps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_end()\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\stable_baselines3\\sac\\sac.py:268\u001B[0m, in \u001B[0;36mSAC.train\u001B[1;34m(self, gradient_steps, batch_size)\u001B[0m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcritic\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m    267\u001B[0m critic_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m--> 268\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcritic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;66;03m# Compute actor loss\u001B[39;00m\n\u001B[0;32m    271\u001B[0m \u001B[38;5;66;03m# Alternative: actor_loss = th.mean(log_prob - qf1_pi)\u001B[39;00m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;66;03m# Min over all critic networks\u001B[39;00m\n\u001B[0;32m    273\u001B[0m q_values_pi \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mcat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcritic(replay_data\u001B[38;5;241m.\u001B[39mobservations, actions_pi), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\torch\\optim\\adam.py:141\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    130\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    133\u001B[0m         group,\n\u001B[0;32m    134\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    139\u001B[0m         state_steps)\n\u001B[1;32m--> 141\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\torch\\optim\\adam.py:281\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    279\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 281\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    288\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    289\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\example\\lib\\site-packages\\torch\\optim\\adam.py:393\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    391\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m--> 393\u001B[0m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddcdiv_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_avg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdenom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mstep_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "reached = []\n",
    "for k in [20]:\n",
    "    env = baseline_bicycleEnv()\n",
    "    env.k = k\n",
    "    print('Start training with PPO ...')\n",
    "    baseline_model = SAC(\"MlpPolicy\", env, verbose=0)\n",
    " \n",
    "    baseline_model.learn(total_timesteps=500000, progress_bar=False)\n",
    "\n",
    "baseline_model.save('baseline_bicycle_model.zip')\n",
    "print(done)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T22:58:02.024466600Z",
     "start_time": "2023-10-31T22:57:04.437125Z"
    }
   },
   "id": "3f50e70ecd05e3eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
